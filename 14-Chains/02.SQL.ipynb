{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../common\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith 추적이 활성화되었습니다. [프로젝트명: Chains-SQL]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langsmith_tracker import set_tracking\n",
    "\n",
    "# 인스턴스를 생성할 때 필요한 매개변수를 전달합니다.\n",
    "set_tracking(project_name=\"Chains-SQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "`create_sql_query_chain` 을 활용하여 생성한 체인으로 SQL 쿼리를 생성 할 수 있습니다.  \n",
    "  \n",
    "SQL 쿼리를 생성한 후 실행하고 답변을 도출하는 방법입니다.\n",
    "\n",
    "### 1. SQL Database 정보를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# 데이터 베이스 연결\n",
    "db = SQLDatabase.from_uri(\"sqlite:///data/finance.db\")\n",
    "\n",
    "# 데이터베이스 출력\n",
    "print(db.dialect)\n",
    "\n",
    "# 사용 가능한 테이블 이름들 출력\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LLM 과 DB 를 매개변수로 입력하여 chain 을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 은 gpt-3.5-turbo 를 지정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# LLM 과 DB 를 매개변수로 입력하여 chain 을 생성합니다.\n",
    "chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 프롬프트를 작성합니다.\n",
    "\n",
    "내용으로 `table_info`, `column_description` 을 포함하여 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Unless the user specifies in his question a specific number of examples he wishes to obtain, always limit your query to at most {top_k} results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Here is the description of the columns in the tables:\n",
    "`cust`: customer name\n",
    "`prod`: product name\n",
    "`trans`: transaction date\n",
    "\n",
    "Question: {input}\"\"\"\n",
    ").partial(dialect=db.dialect)\n",
    "\n",
    "# model 은 gpt-3.5-turbo 를 지정\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# LLM 과 DB 를 매개변수로 입력하여 chain 을 생성합니다.\n",
    "chain = create_sql_query_chain(llm, db, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. chain 을 실행하면 DB 기반으로 쿼리를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 을 실행하고 결과를 출력합니다.\n",
    "generated_sql_query = chain.invoke({\"question\": \"고객의 이름을 나열하세요\"})\n",
    "\n",
    "# 생성된 쿼리를 출력합니다.\n",
    "print(generated_sql_query.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "# 생성한 쿼리를 실행하기 위한 도구를 생성합니다.\n",
    "execute_query = QuerySQLDataBaseTool(db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "# 도구\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "# SQL 쿼리 생성 체인\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "# 생성한 쿼리를 실행하기 위한 체인을 생성합니다.\n",
    "chain = write_query | execute_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 결과 확인\n",
    "chain.invoke({\"question\": \"***을 조회하세요\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 답변을 LLM 으로 증강-생성\n",
    "\n",
    "이전 단계에서 생성한 chain 을 사용하면 답변이 단답형 형식으로 출력됩니다. 이를 LCEL 문법의 체인으로 좀 더 자연스러운 답변을 받을 수 있도록 조정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "answer = answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 생성한 쿼리를 실행하고 결과를 출력하기 위한 체인을 생성합니다.\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 결과 확인\n",
    "chain.invoke({\"question\": \"*** 를 조회하세요\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "\n",
    "# model 은 gpt-3.5-turbo 를 지정\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# SQLite 데이터베이스에 연결합니다.\n",
    "db = SQLDatabase.from_uri(\"sqlite:///data/finance.db\")\n",
    "\n",
    "# Agent 생성\n",
    "agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 결과 확인\n",
    "agent_executor.invoke(\n",
    "    {\"input\": \"*** 를 조회하세요\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-note-2024-PFhCXHTX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
