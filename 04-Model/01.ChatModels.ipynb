{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../common\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith 추적이 활성화되었습니다. [프로젝트명: 03.Models]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langsmith_tracker import set_tracking\n",
    "from langchain_print import stream_response\n",
    "\n",
    "# 인스턴스를 생성할 때 필요한 매개변수를 전달합니다.\n",
    "set_tracking(project_name=\"03.Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "#### 개요\n",
    "OpenAI는 채팅 전용 Large Language Model (LLM)을 제공합니다. 이 모델을 생성할 때 다양한 옵션을 지정할 수 있으며, 이러한 옵션들은 모델의 동작 방식에 영향을 미칩니다.\n",
    "\n",
    "#### 옵션 상세 설명\n",
    "temperature\n",
    "- 샘플링 온도를 설정하는 옵션입니다. 값은 0과 2 사이에서 선택할 수 있습니다. 높은 값(예: 0.8)은 출력을 더 무작위하게 만들고, 낮은 값(예: 0.2)은 출력을 더 집중되고 결정론적으로 만듭니다.\n",
    "\n",
    "max_tokens\n",
    "- 채팅 완성에서 생성할 토큰의 최대 개수를 지정합니다. 이 옵션은 모델이 한 번에 생성할 수 있는 텍스트의 길이를 제어합니다.\n",
    "\n",
    "model_name\n",
    "- 적용 가능한 모델을 선택하는 옵션입니다. 더 자세한 정보는 OpenAI 모델 문서에서 확인할 수 있습니다.\n",
    "\n",
    "모델 스펙\n",
    "- 링크: https://platform.openai.com/docs/models/gpt-4o\n",
    "\n",
    "| 모델명       | 설명                                                                 | 컨텍스트 길이       | 최대 출력 토큰 | 학습 데이터           |\n",
    "|--------------|----------------------------------------------------------------------|----------------------|----------------|-----------------------|\n",
    "| GPT-4        | 텍스트와 이미지 입력을 모두 처리할 수 있는 다중 모달 모델로, 복잡한 문제 해결에 뛰어난 성능을 보입니다. | 8,192 또는 32,768 토큰 | 4,096 토큰     | 2023년 3월까지의 데이터 |\n",
    "| GPT-4o       | 텍스트, 이미지, 음성 입력을 실시간으로 처리하며, 다중 모달 기능을 통합한 모델입니다. | 128,000 토큰         | 4,096 토큰     | 2024년 5월까지의 데이터 |\n",
    "| GPT-4o mini  | GPT-4o의 경량화 버전으로, 빠른 응답 속도와 비용 효율성을 제공합니다.                          | 65,536 토큰          | 4,096 토큰     | 2024년 7월까지의 데이터 |\n",
    "| o1-preview   | 복잡한 문제 해결을 위해 응답 전에 더 많은 시간을 할애하여 높은 정확도를 제공하는 모델입니다.           | 128,000 토큰         | 32,768 토큰    | 2024년 9월까지의 데이터 |\n",
    "| o1-mini      | o1-preview의 경량화 버전으로, 빠른 응답 속도와 비용 효율성을 제공합니다.                          | 65,536 토큰          | 32,768 토큰    | 2024년 9월까지의 데이터 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비트코인은 블록체인 기술을 기반으로 한 분산형 디지털 화폐입니다."
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "response = llm.stream(\"비트코인이 뭔가요? (50글자 내외로 작성)\")\n",
    "\n",
    "# 답변 출력\n",
    "stream_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthropic\n",
    "\n",
    "- 설립 연도: 2021년\n",
    "- 위치: 미국 샌프란시스코\n",
    "- 창립자: OpenAI 출신 직원들 (Daniela Amodei와 Dario Amodei 등)\n",
    "- 기업 형태: 공익기업(Public Benefit Corporation)으로 등록\n",
    "\n",
    "#### Claude\n",
    "Claude는 Anthropic의 대표적인 대규모 언어 모델(LLM) 제품군입니다.\n",
    "\n",
    "API 키 발급\n",
    "-  https://console.anthropic.com/settings/keys  \n",
    "\n",
    "모델 스펙 \n",
    "- 링크 : https://docs.anthropic.com/en/docs/about-claude/models\n",
    "- AWS 에서 사용하는 Bedrock이 포함되어 있습니다.\n",
    "\n",
    "| 모델명             | 설명                                                                 | 컨텍스트 길이 | 최대 출력 토큰 | 학습 데이터 기준일 |\n",
    "|--------------------|----------------------------------------------------------------------|---------------|----------------|--------------------|\n",
    "| Claude 3.5 Sonnet  | 가장 지능적인 모델로, 텍스트 및 이미지 입력을 처리하며, 복잡한 작업에 최적화되어 있습니다. | 200,000 토큰  | 8,192 토큰     | 2024년 4월         |\n",
    "| Claude 3.5 Haiku   | 가장 빠른 모델로, 텍스트 입력을 처리하며, 빠른 응답이 필요한 작업에 적합합니다.           | 200,000 토큰  | 8,192 토큰     | 2024년 7월         |\n",
    "| Claude 3 Opus      | 고도로 복잡한 작업을 위한 강력한 모델로, 높은 수준의 지능과 유창성을 제공합니다.         | 200,000 토큰  | 4,096 토큰     | 2023년 8월         |\n",
    "| Claude 3 Sonnet    | 지능과 속도의 균형을 이루는 모델로, 다양한 작업에 활용할 수 있습니다.                   | 200,000 토큰  | 4,096 토큰     | 2023년 8월         |\n",
    "| Claude 3 Haiku     | 거의 즉각적인 응답을 위한 가장 빠르고 컴팩트한 모델로, 빠른 응답이 필요한 작업에 적합합니다. | 200,000 토큰  | 4,096 토큰     | 2023년 8월         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# ChatAnthropic 객체 생성\n",
    "llm = ChatAnthropic(model_name=\"claude-3-5-sonnet-20241022\")\n",
    "\n",
    "answer = llm.stream(\"비트코인이 뭔가요? (50글자 내외로 작성)\")\n",
    "\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohere\n",
    "Cohere는 기업용 인공지능 솔루션을 제공하는 선도적인 AI 기업으로, 대규모 언어 모델(LLM)을 개발하여 기업들이 AI 기술을 쉽게 도입하고 활용할 수 있도록 돕고 있습니다.\n",
    "\n",
    "- 설립연도: 2020년\n",
    "- 주요 투자자: Inovia Capital, NVIDIA, Oracle, Salesforce Ventures\n",
    "- 시리즈 C 펀딩: 2억 7000만 달러 유치\n",
    "- 기업 미션: 기업용 AI 플랫폼 제공\n",
    "\n",
    "#### Command R+\n",
    "Command R+는 기업용으로 최적화된 Cohere의 최신 LLM입니다.\n",
    "\n",
    "주요 특징\n",
    "- 긴 컨텍스트 윈도우: 128k 토큰 지원\n",
    "- 고급 RAG 기능: 검색 강화 생성 기능 제공\n",
    "- 다국어 지원: 10개 주요 비즈니스 언어 지원\n",
    "- 자동화 도구 사용 기능: 복잡한 비즈니스 프로세스 자동화\n",
    "\n",
    "#### Aya\n",
    "Aya는 Cohere의 비영리 연구소인 Cohere for AI에서 개발한 오픈소스 다국어 LLM입니다.  \n",
    "  \n",
    "주요 특징\n",
    "- 언어 지원: 101개 언어 지원 (기존 오픈소스 모델의 두 배 이상)\n",
    "- 훈련 데이터셋: 5억 1300만 개의 데이터 포인트 포함하는 대규모 다국어 훈련 데이터셋 공개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "# ChatCohere 객체 생성\n",
    "cohere = ChatCohere(temperature=0)\n",
    "\n",
    "llm = cohere.stream(\"비트코인이 뭔가요? (50글자 내외로 작성)\")\n",
    "\n",
    "stream_response(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upstage\n",
    "Upstage는 인공지능(AI) 기술, 특히 대규모 언어 모델(LLM)과 문서 AI 분야에 특화된 국내 스타트업입니다.\n",
    "\n",
    "#### Solar LLM\n",
    "- Upstage의 주력 대규모 언어 모델로, 빠른 성능과 비용 효율성으로 주목받고 있습니다.\n",
    "- 기술적 접근: Depth-Up Scaling (DUS) 기술을 적용하여 성능을 극대화합니다.\n",
    "- 플랫폼 통합: Amazon SageMaker JumpStart 등 다양한 플랫폼을 통해 API로 통합 제공됩니다.\n",
    "\n",
    "#### Document AI Pack\n",
    "- 기능: OCR 기술을 기반으로 한 문서 처리 솔루션으로, 복잡한 문서에서 필요한 내용을 정확히 추출하고 디지털화합니다.\n",
    "\n",
    "#### AskUp Seargest\n",
    "- 특징: 개인화된 검색 및 추천 서비스를 제공하며, 기존의 ChatGPT 통합 무료 챗봇 AskUp의 업그레이드 버전입니다.\n",
    "\n",
    "API 키 발급\n",
    "- https://console.upstage.ai/dashboard/login?redirect=%2Fapi-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage(temperature=0)\n",
    "\n",
    "llm = cohere.stream(\"비트코인이 뭔가요? (50글자 내외로 작성)\")\n",
    "\n",
    "stream_response(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogicKor\n",
    "LogicKor는 한국어 언어 모델의 다분야 사고력을 평가하기 위해 만들어진 벤치마크 리더보드입니다.\n",
    "\n",
    "#### 목적\n",
    "한국어 언어 모델의 다양한 분야에서의 사고력을 측정하는 벤치마크\n",
    "\n",
    "#### 평가 영역\n",
    "- 한국어 추론\n",
    "- 수학\n",
    "- 글쓰기\n",
    "- 코딩\n",
    "- 이해력\n",
    "\n",
    "주요 특징\n",
    "- 다양한 모델 평가: 국내외 다양한 언어 모델들의 성능을 비교할 수 있음\n",
    "- 객관적 성능 측정: 모델의 실제 성능을 다각도로 평가하여 객관적인 지표 제공\n",
    "- 오픈 소스: 누구나 접근하고 결과를 확인할 수 있는 오픈 플랫폼\n",
    "\n",
    "LogicKor 리더보드는 한국어 AI 모델의 발전을 위한 중요한 도구로 자리잡고 있으며, 지속적인 개선과 발전이 기대되고 있습니다.\n",
    "\n",
    "- 링크: LogicKor 리더보드"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-note-2024-PFhCXHTX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
