{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../common\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith ì¶”ì ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. [í”„ë¡œì íŠ¸ëª…: 17.LangGraph-Use-Case]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langsmith_tracker import set_tracking\n",
    "\n",
    "# ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•  ë•Œ í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "set_tracking(project_name=\"17.LangGraph-Use-Case\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan-and-Execute\n",
    "\n",
    "`Plan-and-Execute`ëŠ” ì–´ë–¤ ì‘ì—…ì„ ìˆ˜í–‰í• ë•Œ ê³„íšì„ ë¨¼ì € ì„¸ìš°ê³  ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.   \n",
    "ë³µì¡í•œ í…ŒìŠ¤í¬ë¥¼ Agent ì—ê²Œ ì „ë‹¬í• ë•Œ Planner ê°€ ê³„íšì„ ë¨¼ì € ì„¸ìš°ê²Œ ë©ë‹ˆë‹¤.  \n",
    "ê·¸ ë‹¤ìŒ ìˆœì°¨ì ìœ¼ë¡œ Agent ì—ê²Œ í…ŒìŠ¤í¬ì™€ ê³„íšì„ ì „ë‹¬í•˜ê³  Planner ê°€ ì„¸ìš´ ê³„íšëŒ€ë¡œ Agent ê°€ ì•¡ì…˜ì„ ì·¨í•˜ê²Œ ë©ë‹ˆë‹¤.  \n",
    "ê·¸ ë‹¤ìŒ replan ì—ì„œ ê³„íšëŒ€ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ìˆœì°¨ì§„í–‰ í•˜ê²Œë©ë‹ˆë‹¤.  \n",
    "  \n",
    "`Plan-and-Execute`ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°™ìŠµë‹ˆë‹¤:  \n",
    "\n",
    "- ì¥ê¸° ê³„íš ìˆ˜ë¦½: ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ì „ì— í° ê·¸ë¦¼ì„ ê·¸ë¦¬ëŠ” ì¥ê¸° ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.\n",
    "- ë‹¨ê³„ë³„ ì‹¤í–‰ ë° ì¬ê³„íš: ì„¸ìš´ ê³„íšì„ ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰í•˜ê³ , ê° ë‹¨ê³„ê°€ ì™„ë£Œë  ë•Œë§ˆë‹¤ ê³„íšì´ ì—¬ì „íˆ ìœ íš¨í•œì§€ ê²€í† í•œ ë’¤ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°©ì‹ì€ Plan-and-Solve ë…¼ë¬¸ê³¼ Baby-AGI í”„ë¡œì íŠ¸ì—ì„œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.   \n",
    "ì „í†µì ì¸ ReAct ìŠ¤íƒ€ì¼ì˜ ì—ì´ì „íŠ¸ëŠ” í•œ ë²ˆì— í•œ ë‹¨ê³„ì”© ìƒê°í•˜ëŠ” ë°˜ë©´, `plan-and-execute` ëŠ” ëª…ì‹œì ì´ê³  ì¥ê¸°ì ì¸ ê³„íšì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n",
    "\n",
    "##### ì°¸ê³ ìë£Œ\n",
    "\n",
    "- [LangGraph ê³µì‹ ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/)\n",
    "- [Plan-and-Solve ë…¼ë¬¸](https://arxiv.org/abs/2305.04091)\n",
    "- [Baby-AGI í”„ë¡œì íŠ¸](https://github.com/yoheinakajima/babyagi)\n",
    "- [ReAct ë…¼ë¬¸](https://arxiv.org/abs/2210.03629)\n",
    "\n",
    "##### ê·¸ë˜í”„ íë¦„\n",
    "\n",
    "![plan_and_execute](./assets/langgraph_use_case_plan_and_execute.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê¸°ëŠ¥ êµ¬í˜„\n",
    "\n",
    "#### ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "from models import get_model_name, LLMs\n",
    "\n",
    "# ëª¨ë¸ëª… ì •ì˜\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4o_MINI)\n",
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### ì›¹ ê²€ìƒ‰ ë„êµ¬ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”\n",
    "from tools_tavily import TavilySearch\n",
    "\n",
    "# ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ 3ìœ¼ë¡œ ì„¤ì •\n",
    "web_search_tool = TavilySearch(max_results=3)\n",
    "\n",
    "tools = [web_search_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì‘ì—… ì‹¤í–‰ ì—ì´ì „íŠ¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer in Korean.\",\n",
    "        ),\n",
    "        (\"human\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# LLM ì •ì˜\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# ReAct ì—ì´ì „íŠ¸ ìƒì„±\n",
    "# llm: ìƒê°í•˜ê³  ë§í•˜ëŠ” ë‡Œ\n",
    "# tools: ë¬¸ì œ í•´ê²°ì— í•„ìš”í•œ ë„êµ¬ë“¤(ê³„ì‚°ê¸°, ê²€ìƒ‰ê¸° ë“±)\n",
    "# state_modifier: LLMì´ ì–´ë–¤ ì—­í• ì„ í• ì§€ ì •í•´ì£¼ëŠ” ì§€ì¹¨\n",
    "agent_executor = create_react_agent(llm, tools, state_modifier=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜', additional_kwargs={}, response_metadata={}, id='b5f655d3-1184-4f1e-8eea-739588717887'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pbBbhU73b4fX7fvRmXmT0Wpz', 'function': {'arguments': '{\"query\":\"ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼\"}', 'name': 'tavily_web_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 155, 'total_tokens': 183, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5adb9abd-714e-4dd1-8970-42b080bccd02-0', tool_calls=[{'name': 'tavily_web_search', 'args': {'query': 'ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼'}, 'id': 'call_pbBbhU73b4fX7fvRmXmT0Wpz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 155, 'output_tokens': 28, 'total_tokens': 183, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='[{\"title\": \"LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. ë³¸ ...\", \"url\": \"https://github.com/teddylee777/langchain-kr\", \"content\": \"teddylee777/langchain-kr\\\\nFolders and files\\\\nLatest commit\\\\nHistory\\\\n01-Basic\\\\n01-Basic\\\\n02-Prompt\\\\n02-Prompt\\\\n03-OutputParser\\\\n03-OutputParser\\\\n04-Model\\\\n04-Model\\\\n05-Memory\\\\n05-Memory\\\\n06-Chains\\\\n06-Chains\\\\n07-RAG\\\\n07-RAG\\\\n08-Agent\\\\n08-Agent\\\\n09-FastAPI\\\\n09-FastAPI\\\\n12-Use-Cases\\\\n12-Use-Cases\\\\n99-Projects\\\\n99-Projects\\\\nprompts\\\\nprompts\\\\n.env_sample\\\\n.env_sample\\\\n.gitignore\\\\n.gitignore\\\\nREADME.md\\\\nREADME.md\\\\nRepository files navigation\\\\nğŸ“˜ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼\\\\nğŸŒŸ LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤.\\\\n Topics\\\\nResources\\\\nStars\\\\nWatchers\\\\nForks\\\\nReleases\\\\nPackages\\\\n0\\\\nLanguages\\\\nFooter\\\\nFooter navigation ğŸ¿ ìœ íŠœë¸Œ\\\\nâœï¸ ë¸”ë¡œê·¸ ê¸€ ëª©ë¡\\\\nGeneral\\\\nOpenAI Python API\\\\nLangChain\\\\nLangGraph\\\\nğŸ‘¥ LangChain ë°‹ì—… 2024 Q1 ë°œí‘œìë£Œ\\\\nğŸ“œ ë¼ì´ì„ ìŠ¤\\\\në³¸ í”„ë¡œì íŠ¸ëŠ” Apache License 2.0ì— ë”°ë¼ ë¼ì´ì„ ìŠ¤ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.\\\\n ğŸ“š ì¶œì²˜\\\\nğŸŒ ì¶”ê°€ ìë£Œ\\\\nğŸš€ ì‹œì‘í•˜ê¸°\\\\në³¸ íŠœí† ë¦¬ì–¼ì„ ì‹œì‘í•˜ê¸° ì „ì—, LangChainê³¼ ê´€ë ¨ëœ ê¸°ë³¸ì ì¸ ì§€ì‹ì„ ê°–ì¶”ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. Saved searches\\\\nUse saved searches to filter your results more quickly\\\\nTo see all available qualifiers, see our documentation.\\\\n\", \"score\": 0.8319231, \"raw_content\": \"Search code, repositories, users, issues, pull requests...\\\\nProvide feedback\\\\nWe read every piece of feedback, and take your input very seriously.\\\\nSaved searches\\\\nUse saved searches to filter your results more quickly\\\\nTo see all available qualifiers, see our documentation.\\\\nLangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ LangChainì„ ë” ì‰½ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\nteddylee777/langchain-kr\\\\nFolders and files\\\\nLatest commit\\\\nHistory\\\\n01-Basic\\\\n01-Basic\\\\n02-Prompt\\\\n02-Prompt\\\\n03-OutputParser\\\\n03-OutputParser\\\\n04-Model\\\\n04-Model\\\\n05-Memory\\\\n05-Memory\\\\n06-Chains\\\\n06-Chains\\\\n07-RAG\\\\n07-RAG\\\\n08-Agent\\\\n08-Agent\\\\n09-FastAPI\\\\n09-FastAPI\\\\n12-Use-Cases\\\\n12-Use-Cases\\\\n99-Projects\\\\n99-Projects\\\\nprompts\\\\nprompts\\\\n.env_sample\\\\n.env_sample\\\\n.gitignore\\\\n.gitignore\\\\nREADME.md\\\\nREADME.md\\\\nRepository files navigation\\\\nğŸ“˜ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼\\\\nğŸŒŸ LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤.\\\\në³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ LangChainì„ ë” ì‰½ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\nğŸ¿ ìœ íŠœë¸Œ\\\\nâœï¸ ë¸”ë¡œê·¸ ê¸€ ëª©ë¡\\\\nGeneral\\\\nOpenAI Python API\\\\nLangChain\\\\nLangGraph\\\\nğŸ‘¥ LangChain ë°‹ì—… 2024 Q1 ë°œí‘œìë£Œ\\\\nğŸ“œ ë¼ì´ì„ ìŠ¤\\\\në³¸ í”„ë¡œì íŠ¸ëŠ” Apache License 2.0ì— ë”°ë¼ ë¼ì´ì„ ìŠ¤ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.\\\\nğŸš« ë¼ì´ì„ ìŠ¤ ê³ ì§€\\\\nğŸ”’ ë³¸ ë‚´ìš©ì˜ ì €ì‘ê¶Œì€ 2024ë…„ í…Œë””ë…¸íŠ¸ì— ìˆìŠµë‹ˆë‹¤. ëª¨ë“  ê¶Œë¦¬ëŠ” ì €ì‘ê¶Œìì—ê²Œ ìˆìœ¼ë©°, teddylee777@gmail.com ìœ¼ë¡œ ë¬¸ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\në³¸ ë‚´ìš©ì˜ ë¬´ë‹¨ ì „ì¬ ë° ì¬ë°°í¬ë¥¼ ê¸ˆì§€í•©ë‹ˆë‹¤. ë³¸ ë‚´ìš©ì˜ ì „ì²´ í˜¹ì€ ì¼ë¶€ë¥¼ ì¸ìš©í•  ê²½ìš°, ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°í˜€ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\\\\në³¸ ë¬¸ì„œëŠ” ë‹¤ë¥¸ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³  ìë£ŒëŠ” ë³¸ ë¬¸ì„œ í•˜ë‹¨ì˜ ì¶œì²˜ ëª©ë¡ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\nğŸ“š ì¶œì²˜\\\\nğŸŒ ì¶”ê°€ ìë£Œ\\\\nğŸš€ ì‹œì‘í•˜ê¸°\\\\në³¸ íŠœí† ë¦¬ì–¼ì„ ì‹œì‘í•˜ê¸° ì „ì—, LangChainê³¼ ê´€ë ¨ëœ ê¸°ë³¸ì ì¸ ì§€ì‹ì„ ê°–ì¶”ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ìœ„ì˜ ì¶œì²˜ ë§í¬ë¥¼ í†µí•´ ê¸°ë³¸ì ì¸ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\nğŸ’¡ ì»¨íŠ¸ë¦¬ë·°ì…˜\\\\në³¸ íŠœí† ë¦¬ì–¼ì— ê¸°ì—¬í•˜ê³ ì í•˜ëŠ” ë¶„ë“¤ì€ ì–¸ì œë“ ì§€ í’€ ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ ë³´ë‚´ì£¼ì‹œê±°ë‚˜, ì´ìŠˆë¥¼ ë“±ë¡í•˜ì—¬ ì˜ê²¬ì„ ê³µìœ í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. ëª¨ë“  ê¸°ì—¬ëŠ” ë³¸ í”„ë¡œì íŠ¸ì˜ ë°œì „ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤. ğŸ’–\\\\nAbout\\\\nLangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ LangChainì„ ë” ì‰½ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\nTopics\\\\nResources\\\\nStars\\\\nWatchers\\\\nForks\\\\nReleases\\\\nPackages\\\\n0\\\\nLanguages\\\\nFooter\\\\nFooter navigation\"}, {\"title\": \" - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ - WikiDocs\", \"url\": \"https://wikidocs.net/book/14314\", \"content\": \" - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· CH01 LangChain ì‹œì‘í•˜ê¸° 01. ì„¤ì¹˜ ì˜ìƒë³´ê³  ë”°ë¼í•˜ê¸° 02. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸ 03. LangSmith ì¶”ì  ì„¤ì • 04. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬) 05.\", \"score\": 0.81665546, \"raw_content\": \"<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· - WikiDocs\\\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· CH01 LangChain ì‹œì‘í•˜ê¸° 01. ì„¤ì¹˜ ì˜ìƒë³´ê³  ë”°ë¼í•˜ê¸° 02. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸ 03. LangSmith ì¶”ì  ì„¤ì • 04. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬) 05. LangChain Expression Language(LCEL) 06. LCEL ì¸í„°í˜ì´ìŠ¤ 07. Runnable CH02 í”„ë¡¬í”„íŠ¸(Prompt) 01. í”„ë¡¬í”„íŠ¸(Prompt) 02. í“¨ìƒ· í”„ë¡¬í”„íŠ¸(FewShotPromptTemplate) 03. LangChain Hub 04. ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸(Hubì— ì—…ë¡œë“œ) CH03 ì¶œë ¥ íŒŒì„œ(Output Parsers) 01. Pydantic ì¶œë ¥ íŒŒì„œ(PydanticOutputParser) 02. ì½¤ë§ˆ êµ¬ë¶„ì ì¶œë ¥ íŒŒì„œ(CommaSeparatedListOutputParser) 03. êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ(StructuredOuputParser) 04. JSON ì¶œë ¥ íŒŒì„œ(JsonOutputParser) 05. ë°ì´í„°í”„ë ˆì„ ì¶œë ¥ íŒŒì„œ(PandasDataFrameOutputParser) 06. ë‚ ì§œ í˜•ì‹ ì¶œë ¥ íŒŒì„œ(DatetimeOutputParser) 07. ì—´ê±°í˜• ì¶œë ¥ íŒŒì„œ(EnumOutputParser) 08. ì¶œë ¥ ìˆ˜ì • íŒŒì„œ(OutputFixingParser) CH04 ëª¨ë¸(Model) 01. ë‹¤ì–‘í•œ LLM ëª¨ë¸ í™œìš© 02. ìºì‹±(Cache) 03. ëª¨ë¸ ì§ë ¬í™”(Serialization) - ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° 04. í† í° ì‚¬ìš©ëŸ‰ í™•ì¸ 05. êµ¬ê¸€ ìƒì„± AI(Google Generative AI) 06. í—ˆê¹…í˜ì´ìŠ¤ ì—”ë“œí¬ì¸íŠ¸(HuggingFace Endpoints) 07. í—ˆê¹…í˜ì´ìŠ¤ ë¡œì»¬(HuggingFace Local) 08. í—ˆê¹…í˜ì´ìŠ¤ íŒŒì´í”„ë¼ì¸(HuggingFace Pipeline) 09. ì˜¬ë¼ë§ˆ(Ollama) 10. GPT4ALL 11. ë¹„ë””ì˜¤(Video) ì§ˆì˜ ì‘ë‹µ LLM (Gemini) CH05 ë©”ëª¨ë¦¬(Memory) 01. ëŒ€í™” ë²„í¼ ë©”ëª¨ë¦¬(ConversationBufferMemory) 02. ëŒ€í™” ë²„í¼ ìœˆë„ìš° ë©”ëª¨ë¦¬(ConversationBufferWindowMemory) 03. ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) 04. ëŒ€í™” ì—”í‹°í‹° ë©”ëª¨ë¦¬(ConversationEntityMemory) 05. ëŒ€í™” ì§€ì‹ê·¸ë˜í”„ ë©”ëª¨ë¦¬(ConversationKGMemory) 06. ëŒ€í™” ìš”ì•½ ë©”ëª¨ë¦¬(ConversationSummaryMemory) 07. ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ ë©”ëª¨ë¦¬(VectorStoreRetrieverMemory) 08. LCEL Chain ì— ë©”ëª¨ë¦¬ ì¶”ê°€ 09. SQLite ì— ëŒ€í™”ë‚´ìš© ì €ì¥ 10. RunnableWithMessageHistoryì— ChatMessageHistoryì¶”ê°€ CH06 ë¬¸ì„œ ë¡œë”(Document Loader) 01. ë„íë¨¼íŠ¸(Document) ì˜ êµ¬ì¡° 02. PDF 03. í•œê¸€(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. ì›¹ ë¬¸ì„œ(WebBaseLoader) 09. í…ìŠ¤íŠ¸(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 í…ìŠ¤íŠ¸ ë¶„í• (Text Splitter) 01. ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• (CharacterTextSplitter) 02. ì¬ê·€ì  ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• (RecursiveCharacterTextSplitter) 03. í† í° í…ìŠ¤íŠ¸ ë¶„í• (TokenTextSplitter) 04. ì‹œë©˜í‹± ì²­ì»¤(SemanticChunker) 05. ì½”ë“œ ë¶„í• (Python, Markdown, JAVA, C++, C#, GO, JS, Latex ë“±) 06. ë§ˆí¬ë‹¤ìš´ í—¤ë” í…ìŠ¤íŠ¸ ë¶„í• (MarkdownHeaderTextSplitter) 07. HTML í—¤ë” í…ìŠ¤íŠ¸ ë¶„í• (HTMLHeaderTextSplitter) 08. ì¬ê·€ì  JSON ë¶„í• (RecursiveJsonSplitter) CH08 ì„ë² ë”©(Embedding) 01. OpenAIEmbeddings 02. ìºì‹œ ì„ë² ë”©(CacheBackedEmbeddings) 03. í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”©(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL ì„ë² ë”© 07. Llama CPP ì„ë² ë”© CH09 ë²¡í„°ì €ì¥ì†Œ(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 ê²€ìƒ‰ê¸°(Retriever) 01. ë²¡í„°ìŠ¤í† ì–´ ê¸°ë°˜ ê²€ìƒ‰ê¸°(VectorStore-backed Retriever) 02. ë¬¸ë§¥ ì••ì¶• ê²€ìƒ‰ê¸°(ContextualCompressionRetriever) 03. ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever) 04. ê¸´ ë¬¸ë§¥ ì¬ì •ë ¬(LongContextReorder) 05. ìƒìœ„ ë¬¸ì„œ ê²€ìƒ‰ê¸°(ParentDocumentRetriever) 06. ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ê¸°(MultiQueryRetriever) 07. ë‹¤ì¤‘ ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ê¸°(MultiVectorRetriever) 08. ì…€í”„ ì¿¼ë¦¬ ê²€ìƒ‰ê¸°(SelfQueryRetriever) 09. ì‹œê°„ ê°€ì¤‘ ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ê¸°(TimeWeightedVectorStoreRetriever) 10. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° 11. Convex Combination(CC) ì ìš©ëœ ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever) CH11 ë¦¬ë­ì»¤(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF ë¬¸ì„œ ê¸°ë°˜ QA(Question-Answer) 02. ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ QA(Question-Answer) 03. RAG ì˜ ê¸°ëŠ¥ë³„ ë‹¤ì–‘í•œ ëª¨ë“ˆ í™œìš©ê¸° 04. RAPTOR: ê¸´ ë¬¸ë§¥ ìš”ì•½(Long Context Summary) 05. ëŒ€í™”ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” RAG ì²´ì¸ CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable êµ¬ì¡°(ê·¸ë˜í”„) ê²€í†  03. RunnableLambda 04. LLM ì²´ì¸ ë¼ìš°íŒ…(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. ë™ì  ì†ì„± ì§€ì •(configurable_fields, configurable_alternatives) 07. @chain ë°ì½”ë ˆì´í„°ë¡œ Runnable êµ¬ì„± 08. RunnableWithMessageHistory 09. ì‚¬ìš©ì ì •ì˜ ì œë„¤ë ˆì´í„°(generator) 10. Runtime Arguments ë°”ì¸ë”© 11. í´ë°±(fallback) ëª¨ë¸ ì§€ì • CH14 ì²´ì¸(Chains) 01. ë¬¸ì„œ ìš”ì•½ 02. SQL 03. êµ¬ì¡°í™”ëœ ì¶œë ¥ ì²´ì¸(with_structered_output) CH15 í‰ê°€(Evaluations) 01. í•©ì„± í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±(RAGAS) 02. RAGAS ë¥¼ í™œìš©í•œ í‰ê°€ 03. ìƒì„±í•œ í‰ê°€ìš© ë°ì´í„°ì…‹ ì—…ë¡œë“œ(HuggingFace Dataset) 04. LangSmith ë°ì´í„°ì…‹ ìƒì„± 05. LLM-as-Judge 06. ì„ë² ë”© ê¸°ë°˜ í‰ê°€(embedding_distance) 07. ì‚¬ìš©ì ì •ì˜(Custom) LLM í‰ê°€ 08. Rouge, BLEU, METEOR, SemScore ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± í‰ê°€ 09. ì‹¤í—˜(Experiment) í‰ê°€ ë¹„êµ 10. ìš”ì•½(Summary) ë°©ì‹ì˜ í‰ê°€ 11. Groundedness(í• ë£¨ì‹œë„¤ì´ì…˜) í‰ê°€ 12. ì‹¤í—˜ ë¹„êµ(Pairwise Evaluation) 13. ë°˜ë³µ í‰ê°€ 14. ì˜¨ë¼ì¸ í‰ê°€ë¥¼ í™œìš©í•œ í‰ê°€ ìë™í™” CH16 ì—ì´ì „íŠ¸(Agent) 01. ë„êµ¬(Tools) 02. ë„êµ¬ ë°”ì¸ë”©(Binding Tools) 03. ì—ì´ì „íŠ¸(Agent) 04. Claude, Gemini, Ollama, Together.ai ë¥¼ í™œìš©í•œ Agent 05. Iteration ê¸°ëŠ¥ê³¼ ì‚¬ëŒ ê°œì…(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel ë°ì´í„° ë¶„ì„ Agent 08. Toolkits í™œìš© Agent 09. RAG + Image Generator Agent(ë³´ê³ ì„œ ì‘ì„±) 10. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools) CH17 LangGraph 01. í•µì‹¬ ê¸°ëŠ¥ 01. LangGraph ì— ìì£¼ ë“±ì¥í•˜ëŠ” Python ë¬¸ë²•ì´í•´ 02. LangGraphë¥¼ í™œìš©í•œ ì±—ë´‡ êµ¬ì¶• 03. LangGraphë¥¼ í™œìš©í•œ Agent êµ¬ì¶• 04. Agent ì— ë©”ëª¨ë¦¬(memory) ì¶”ê°€ 05. ë…¸ë“œì˜ ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ 06. Human-in-the-loop(ì‚¬ëŒì˜ ê°œì…) 07. ì¤‘ê°„ë‹¨ê³„ ê°œì… ë˜ëŒë¦¼ì„ í†µí•œ ìƒíƒœ ìˆ˜ì •ê³¼ Replay 08. ì‚¬ëŒ(Human)ì—ê²Œ ë¬¼ì–´ë³´ëŠ” ë…¸ë“œ ì¶”ê°€ 09. ë©”ì‹œì§€ ì‚­ì œ(RemoveMessage) 10. ToolNode ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ë°©ë²• 11. ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë¶„ê¸° ìƒì„± ë°©ë²• 12. ëŒ€í™” ê¸°ë¡ ìš”ì•½ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²• 13. ì„œë¸Œê·¸ë˜í”„ ì¶”ê°€ ë° ì‚¬ìš© ë°©ë²• 14. ì„œë¸Œê·¸ë˜í”„ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ë³€í™˜í•˜ëŠ” ë°©ë²• 15. LangGraph ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì˜ ëª¨ë“  ê²ƒ 02. êµ¬ì¡° ì„¤ê³„ 01. ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„± 02. Naive RAG 03. ê´€ë ¨ì„± ì²´ì»¤(Relevance Checker) ëª¨ë“ˆ ì¶”ê°€ 04. ì›¹ ê²€ìƒ‰ ëª¨ë“ˆ ì¶”ê°€ 05. ì¿¼ë¦¬ ì¬ì‘ì„± ëª¨ë“ˆ ì¶”ê°€ 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. ì—ì´ì „íŠ¸ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ (ê³ ê° ì‘ëŒ€ ì‹œë‚˜ë¦¬ì˜¤) 02. ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ë©”íƒ€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—ì´ì „íŠ¸ 03. CRAG(Corrective RAG) 04. Self-RAG 05. ê³„íš í›„ ì‹¤í–‰(Plan-and-Execute) 06. ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—… ë„¤íŠ¸ì›Œí¬(Multi-Agent Collaboration Network) 07. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) 08. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) 09. SQL ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ 10. STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ CH18 ê¸°íƒ€ ì •ë³´ 01. StreamEvent íƒ€ì…ë³„ ì •ë¦¬\\\\nPublished with WikiDocs\\\\n\\\\n\\\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - Langâ€¦\\\\n\\\\n\\\\nWikiDocs\\\\n\\\\n\\\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡·\\\\n\\\\nAuthor: í…Œë””ë…¸íŠ¸\\\\nLast edited by : Dec. 23, 2024, 3:48 a.m.\\\\nCopyright : \\\\n2,442 Like; \\\\\"ì¶”ì²œ\\\\\")\\\\nì¶”ì²œì€ ê³µìœ í•  ìˆ˜ ìˆëŠ” ë¬´ë£Œ ì „ìì±…ì„ ì§‘í•„í•˜ëŠ”ë° ì •ë§ í° í˜ì´ ë©ë‹ˆë‹¤. \\\\\"ì¶”ì²œ\\\\\" í•œ ë²ˆì”©ë§Œ ë¶€íƒ ë“œë¦¬ê² ìŠµë‹ˆë‹¤ğŸ™ğŸ™\\\\nâœ… ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ê°•ì˜\\\\níŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ - RAG ë¹„ë²•ë…¸íŠ¸\\\\nâœ… ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ì½”ë“œì €ì¥ì†Œ(GitHub) ğŸ“˜ğŸ–¥ï¸\\\\nhttps://github.com/teddylee777/langchain-kr\\\\nâœ… ìœ íŠœë¸Œ \\\\\"í…Œë””ë…¸íŠ¸\\\\\" ğŸ¥ğŸ“š\\\\nhttps://www.youtube.com/c/@teddynote\\\\nâœ… ë°ì´í„° ë¶„ì„ ë¸”ë¡œê·¸ https://teddylee777.github.io\\\\nâœ… ë¬¸ì˜ teddylee777@gmail.com\\\\nLICENSE\\\\nì¸ìš© ë° ì¶œì²˜ í‘œê¸°\\\\n\\\\në³¸ ì €ì‘ë¬¼ì„ ë¸”ë¡œê·¸, ìœ íŠœë¸Œ ë“± ì˜¨ë¼ì¸ ë§¤ì²´ì— ì¸ìš©í•˜ì—¬ ê²Œì¬í•  ê²½ìš°, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\\\\n\\\\nìƒì—…ì  ì‚¬ìš©ì— ëŒ€í•œ ì‚¬ì „ í˜‘ì˜\\\\n\\\\në³¸ ì €ì‘ë¬¼(Wikidocs ë° ê´€ë ¨ ì‹¤ìŠµ ì½”ë“œ í¬í•¨)ì„ ê°•ì˜, ê°•ì—° ë“± ìƒì—…ì  ëª©ì ìœ¼ë¡œ í™œìš©í•˜ê³ ì í•˜ëŠ” ê²½ìš°, ì €ì‘ê¶Œìì™€ì˜ ì‚¬ì „ ì„œë©´ í˜‘ì˜ê°€ í•„ìˆ˜ì ìœ¼ë¡œ ìš”êµ¬ë©ë‹ˆë‹¤. í•´ë‹¹ í˜‘ì˜ëŠ” teddylee777@gmail.comìœ¼ë¡œ ë¬¸ì˜í•˜ì—¬ ì§„í–‰í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\n\\\\në³¸ ì €ì‘ë¬¼ì€ 2024ë…„ í…Œë””ë…¸íŠ¸ì— ì˜í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. \\\\nëª¨ë“  ê¶Œë¦¬ëŠ” ì €ì‘ê¶Œìì—ê²Œ ìˆìœ¼ë©°, ë³¸ ì €ì‘ë¬¼ì€ Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë°°í¬ë©ë‹ˆë‹¤.\\\\në³¸ ì €ì‘ë¬¼ì˜ ë¬´ë‹¨ ì „ì¬ ë° ì¬ë°°í¬ë¥¼ ê¸ˆì§€í•˜ë©°, ì „ì²´ í˜¹ì€ ì¼ë¶€ë¥¼ ì¸ìš©í•  ê²½ìš° ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°í˜€ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\\\\në³¸ ë¬¸ì„œëŠ” ë‹¤ë¥¸ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³  ìë£ŒëŠ” ë³¸ ë¬¸ì„œ í•˜ë‹¨ì˜ ì¶œì²˜ ëª©ë¡ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\nCopyright (c) í…Œë””ë…¸íŠ¸.\\\\nReference\\\\n\\\\nLangChain Github\\\\nLangGraph Github\\\\nLangChain Document\\\\n\\\\nRecent Comments (7) Recent Modifications (10) RSS\\\\n10. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° - ì²œì„¸í˜„, Jan. 9, 2025, 12:28 p.m.\\\\nì¶œë ¥ëœ ê²°ê³¼ë¥¼ ë¹„êµí–ˆì„ ë•Œ, kiwi tokenizerì„ ì‚¬ìš©í•œ ê²°ê³¼ì™€ kkma, okt ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ í° ì°¨ì´ê°€ ì—†ë‹¤ê³  ë´ë„ ë˜ëŠ” ê±´ê°€ìš”?\\\\nCH01 LangChain ì‹œì‘í•˜ê¸° - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\\\nì¢‹ì€ ìë£Œë¥¼ ë¬´ë£Œë¡œ ê³µìœ í•´ ì£¼ì…”ì„œ, ê°ì‚¬í•œ ë§ˆìŒì— \\'í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸\\' ê°•ì˜ ë“±ë¡í–ˆìŠµë‹ˆë‹¤ ! ë¬¼ë¡  ì œ í˜„ì—…ì— í•„ìš”í•œ ê¸°ìˆ ì´ë¼ì„œ, ê°•ì˜ ë˜í•œ ê¸°ìœ ë§ˆìŒì— ì‹ ì²­í–ˆêµ¬ìš” ~ ì •ì£¼í–‰ í•´ì„œ, ì°½ê³µì„ ë‚ ì•„ê°€ ë³´ê² ìŠµë‹ˆë‹¤ ^^\\\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\\\npython-docxë„ ì„¤ì¹˜í•´ì•¼ í• ê¹Œìš”?\\\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\\\n!pip install jq ë¶€ë¶„ì´ ë“¤ì–´ê°€ì•¼ í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.\\\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\\\n<html><head> <meta http-equiv=\\\\\"Content-Type\\\\\" content=\\\\\"text/html\\\\\"> </head><body> <span style=\\\\\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\\\\\"></span> <div style=\\\\\"position:absolute; top:50px;\\\\\"><a name=\\\\\"1\\\\\">Page 1</a></div> <div style=\\\\\"position:absolute; border ì´ ë¶€ë¶„ì´ ì¶œë ¥ ê²°ê³¼ê°€ ì•„ë‹ˆë¼ ì½”ë“œì¸ ê²ƒì²˜ëŸ¼ í‘œì‹œë˜ì–´ ìˆë„¤ìš”~\\\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\\\nê°ì‚¬íˆ ì˜ ì°¸ê³ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ì£¼ ì‚¬ì†Œí•œ ì˜¤ê¸°ì´ì§€ë§Œ... 11ë²ˆ Arxiv ë‹¤ìŒì— 12ë²ˆì´ ì™€ì•¼ í•  í…ë°, ì›ë˜ ë„£ìœ¼ì‹œë ¤ë˜ ë‹¤ë¥¸ ëª©ì°¨ê°€ ë¹ ì§„ ê²ƒì¸ì§€ ë°”ë¡œ 13ë²ˆì´ ë‚˜ì™”ë„¤ìš”^^\\\\n03. ëª¨ë¸ ì§ë ¬í™”(Serialization) - ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° - ë™êµ¬, Sept. 20, 2024, 12:58 p.m.\\\\nloadsëŠ” ë­ì—ìš”?\\\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n05. ì½”ë“œ ë¶„í• (Python, Markdown, JAVA, C++, C#, GO, JS, Latex ë“±) - Dec. 23, 2024, 3:16 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n10. STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ - Dec. 23, 2024, 3:16 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n05. ê³„íš í›„ ì‹¤í–‰(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n07. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n08. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n09. SQL ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n02. ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ë©”íƒ€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—ì´ì „íŠ¸ - Dec. 23, 2024, 2:45 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n03. í† í° í…ìŠ¤íŠ¸ ë¶„í• (TokenTextSplitter) - Dec. 23, 2024, 2:31 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\\\n\\\\nNext : CH01 LangChain ì‹œì‘í•˜ê¸°\\\\n\\\\n\\\\nÃ—\\\\nì±…ê°ˆí”¼\\\\nì¶”ê°€ ë‹«ê¸°\\\\n\\\\nÃ—\\\\nLeave feedback on this page\\\\nEmail address to reply to\\\\nWhat you want to say\\\\nâ€» Feedback is delivered to the author by email.\\\\nClose Send\"}, {\"title\": \" - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼\", \"url\": \"https://www.gpters.org/dev/post/langchain-notes-langchain-korean-UbTO5u3bFgmL0SQ\", \"content\": \"ë³¸ ì „ìì±…ì€ ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ë­ì²´ì¸ ê³µì‹ GitHub íŠœí† ë¦¬ì–¼ì„ í•œêµ­ì–´ ì˜ˆì œì™€ ë¬¸êµ¬ë¡œ ë²ˆì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤ ğŸ“˜ë­ì²´ì¸LangChain ë…¸íŠ¸ - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· 2 LangChain ê³µì‹ Dev íŒ€ì— í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë“±ë¡ ë¬¸ì˜ì™€ ê³µì‹ í™ˆí˜ì´ì§€ì˜ íŠœí† ë¦¬ì–¼ ë²ˆì—­ì— ëŒ€í•œ í—ˆê°€ë„ ë°›ê²Œ ë˜ì–´ ë“œë””ì–´\", \"score\": 0.8131201, \"raw_content\": null}]', name='tavily_web_search', id='99c3cbfd-1f9a-48b3-80a7-cb6492113970', tool_call_id='call_pbBbhU73b4fX7fvRmXmT0Wpz'),\n",
       "  AIMessage(content='ë­ì²´ì¸(LangChain) í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì— ëŒ€í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n1. **GitHub íŠœí† ë¦¬ì–¼**: [LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼](https://github.com/teddylee777/langchain-kr)ì—ì„œëŠ” LangChainì˜ ê³µì‹ ë¬¸ì„œì™€ ìš”ë¦¬ì±…, ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì„ í†µí•´ LangChainì„ ë” ì‰½ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n2. **WikiDocs**: [LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ - WikiDocs](https://wikidocs.net/book/14314)ì—ì„œëŠ” LangChainì˜ ì„¤ì¹˜ ë°©ë²•, OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸, ë‹¤ì–‘í•œ ê¸°ëŠ¥ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê° ì¥ì—ì„œëŠ” í”„ë¡¬í”„íŠ¸, ì¶œë ¥ íŒŒì„œ, ëª¨ë¸, ë©”ëª¨ë¦¬ ë“± ë‹¤ì–‘í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.\\n\\n3. **ì „ìì±…**: [LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼](https://www.gpters.org/dev/post/langchain-notes-langchain-korean-UbTO5u3bFgmL0SQ)ì—ì„œëŠ” ë­ì²´ì¸ ê³µì‹ GitHub íŠœí† ë¦¬ì–¼ì„ í•œêµ­ì–´ ì˜ˆì œì™€ ë¬¸êµ¬ë¡œ ë²ˆì—­í•˜ì—¬ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nì´ ìë£Œë“¤ì„ í†µí•´ ë­ì²´ì¸ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì§€ì‹ê³¼ í™œìš© ë°©ë²•ì„ ìµí ìˆ˜ ìˆìŠµë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 304, 'prompt_tokens': 6246, 'total_tokens': 6550, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-b0a6e144-4d4c-4d6c-a008-157a5b5145c2-0', usage_metadata={'input_tokens': 6246, 'output_tokens': 304, 'total_tokens': 6550, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "agent_executor.invoke(\n",
    "    {\"messages\": [(\"user\", \"ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ìƒíƒœ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# ìƒíƒœ ì •ì˜\n",
    "class PlanExecute(TypedDict):\n",
    "    input: Annotated[str, \"User's input\"]\n",
    "    plan: Annotated[List[str], \"Current plan\"]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: Annotated[str, \"Final response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ê³„íš(Planner) ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Plan ëª¨ë¸ ì •ì˜\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Sorted steps to execute the plan\"\"\"\n",
    "\n",
    "    steps: Annotated[List[str], \"Different steps to follow, should be in sorted order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê³„íš ìˆ˜ë¦½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "Answer in Korean.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0\n",
    ").with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "planner ë™ì‘ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(steps=['LangGraphì˜ ì •ì˜ì™€ ê¸°ëŠ¥ì„ ì´í•´í•œë‹¤.', 'LangGraphì˜ í•µì‹¬ ì¥ì ì„ ì •ë¦¬í•œë‹¤.', 'LangGraphì˜ í•µì‹¬ ë‹¨ì ì„ ì •ë¦¬í•œë‹¤.', 'LangGraphë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ë¥¼ ì •ë¦¬í•œë‹¤.'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Planner ì‹¤í–‰\n",
    "planner.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"LangGraph ì˜ í•µì‹¬ ì¥ë‹¨ì ê³¼ LangGraph ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€?\",\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Plan ìƒì„±\n",
    "\n",
    "ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³„íšì„ ë‹¤ì‹œ ìˆ˜ë¦½í•˜ëŠ” ë‹¨ê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    # ì‚¬ìš©ì ì‘ë‹µ\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    # ìˆ˜í–‰í•  ì‘ì—…: \"Response\", \"Plan\". ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•  ê²½ìš° Response ì‚¬ìš©, ì¶”ê°€ ë„êµ¬ ì‚¬ìš©ì´ í•„ìš”í•  ê²½ìš° Plan ì‚¬ìš©\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ê³„íšì„ ì¬ìˆ˜ë¦½í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\n",
    "\n",
    "Answer in Korean.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Replanner ìƒì„±\n",
    "replanner = replanner_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0\n",
    ").with_structured_output(Act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ì •ì˜\n",
    "\n",
    "#### 1. ë…¸ë“œ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„íšì„ ìƒì„±í•˜ê³  ë°˜í™˜\n",
    "def plan_step(state: PlanExecute):\n",
    "    plan = planner.invoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    # ìƒì„±ëœ ê³„íšì˜ ë‹¨ê³„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "    return {\"plan\": plan.steps}\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜\n",
    "def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    # ê³„íšì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ê° ë‹¨ê³„ì— ë²ˆí˜¸ë¥¼ ë§¤ê¹€\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    # í˜„ì¬ ì‹¤í–‰í•  ì‘ì—…ì„ í¬ë§·íŒ…í•˜ì—¬ ì—ì´ì „íŠ¸ì— ì „ë‹¬\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing [step 1. {task}].\"\"\"\n",
    "    # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ë¥¼ í†µí•´ ì‘ì—… ìˆ˜í–‰ ë° ê²°ê³¼ ìˆ˜ì‹ \n",
    "    agent_response = agent_executor.invoke({\"messages\": [(\"user\", task_formatted)]})\n",
    "    # ì´ì „ ë‹¨ê³„ì™€ ê·¸ ê²°ê³¼ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë°˜í™˜\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)],\n",
    "    }\n",
    "\n",
    "\n",
    "# ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³„íšì„ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ìµœì¢… ì‘ë‹µì„ ë°˜í™˜\n",
    "def replan_step(state: PlanExecute):\n",
    "    output = replanner.invoke(state)\n",
    "    # ì‘ë‹µì´ ì‚¬ìš©ìì—ê²Œ ë°˜í™˜ë  ê²½ìš°\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    # ì¶”ê°€ ë‹¨ê³„ê°€ í•„ìš”í•  ê²½ìš° ê³„íšì˜ ë‹¨ê³„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "    else:\n",
    "        next_plan = output.action.steps\n",
    "        if len(next_plan) == 0:\n",
    "            return {\"response\": \"No more steps needed.\"}\n",
    "        else:\n",
    "            return {\"plan\": next_plan}\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì˜ ì‹¤í–‰ ì¢…ë£Œ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜\n",
    "def should_end(state: PlanExecute):\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"final_report\"\n",
    "    else:\n",
    "        return \"execute\"\n",
    "\n",
    "\n",
    "final_report_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are given the objective and the previously done steps. Your task is to generate a final report in markdown format.\n",
    "Final report should be written in professional tone.\n",
    "\n",
    "Your objective was this:\n",
    "\n",
    "{input}\n",
    "\n",
    "Your previously done steps(question and answer pairs):\n",
    "\n",
    "{past_steps}\n",
    "\n",
    "Generate a final report in markdown format. Write your response in Korean.\"\"\"\n",
    ")\n",
    "\n",
    "final_report = (\n",
    "    final_report_prompt\n",
    "    | ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "def generate_final_report(state: PlanExecute):\n",
    "    past_steps = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"Question: {past_step[0]}\\n\\nAnswer: {past_step[1]}\\n\\n####\"\n",
    "            for past_step in state[\"past_steps\"]\n",
    "        ]\n",
    "    )\n",
    "    response = final_report.invoke({\"input\": state[\"input\"], \"past_steps\": past_steps})\n",
    "    return {\"response\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ì—£ì§€ ì„¤ì • ë° ê·¸ë˜í”„ ì»´íŒŒì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# ë…¸ë“œ ì •ì˜\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "workflow.add_node(\"execute\", execute_step)\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "workflow.add_node(\"final_report\", generate_final_report)\n",
    "\n",
    "# ì—£ì§€ ì •ì˜\n",
    "workflow.add_edge(START, \"planner\")\n",
    "workflow.add_edge(\"planner\", \"execute\")\n",
    "workflow.add_edge(\"execute\", \"replan\")\n",
    "workflow.add_edge(\"final_report\", END)\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€: replan í›„ ì¢…ë£Œ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ ì‚¬ìš©\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    should_end,\n",
    "    {\"execute\": \"execute\", \"final_report\": \"final_report\"},\n",
    ")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ê·¸ë˜í”„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app, xray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mplanner\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Modular RAGì™€ Naive RAGì˜ ì •ì˜ë¥¼ ì´í•´í•œë‹¤.\n",
      "Modular RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì„ ì„¤ëª…í•œë‹¤.\n",
      "Naive RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì„ ì„¤ëª…í•œë‹¤.\n",
      "Modular RAGì™€ Naive RAGì˜ ì£¼ìš” ì°¨ì´ì ì„ ë¹„êµí•œë‹¤.\n",
      "Modular RAGê°€ production levelì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì„ ì •ë¦¬í•œë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_HpjQrkPE57l4zIlBU1xsMrNX)\n",
      " Call ID: call_HpjQrkPE57l4zIlBU1xsMrNX\n",
      "  Args:\n",
      "    query: Modular RAG ì •ì˜\n",
      "  tavily_web_search (call_OPnEgdxWxdjJiT0XsGSmTQa0)\n",
      " Call ID: call_OPnEgdxWxdjJiT0XsGSmTQa0\n",
      "  Args:\n",
      "    query: Naive RAG ì •ì˜\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Modular RAG\", \"url\": \"https://jjaegii.tistory.com/42\", \"content\": \"Modular RAG Modular RAG Modular RAG ëª¨ë“ˆ ë…ë¦½ì ì¸ ëª¨ë“ˆ êµ¬ì„± Modular RAG ë™ì (dynamic) - ê·¸ë˜í”„ í˜•ì‹ì˜ íë¦„ êµ¬ì„±, ìƒí™©ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬ ëª¨ë“ˆ ëª¨ë“ˆ, í•˜ìœ„ ëª¨ë“ˆ ë° ìš´ì˜ìë¡œ êµ¬ì„±ëœ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ í†µí•´ í†µí•©ë˜ê³  êµ¬ì¡°í™”ëœ ë°©ì‹ìœ¼ë¡œ RAG ì‹œìŠ¤í…œì„ ì •ì˜ ê° ëª¨ë“ˆì€ í•˜ìœ„ ëª¨ë“ˆ(Sub Module)ë¡œ êµ¬ì„± ë…ë¦½ì ì¸ ëª¨ë“ˆ êµ¬ì„± ë§ˆì¹˜ ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ì„¸ë¶€ ëª¨ë“ˆ(Sub-Module)ì„ ì—°ê²°í•˜ì—¬ êµ¬ì„± í‰ê°€ì -> \\\"ë¬¸ì„œ ê²€ìƒ‰\\\"ì— ëŒ€í•œ í‰ê°€(Score) - ë¬¸ì„œì— Queryì— ëŒ€í•œ ë‹µë³€ì„ ìœ„í•œ ì •ë³´ê°€ ì¶©ë¶„í•œì§€ íŒë‹¨ ë³´ë‹¤ ëª…í™•í•œ ì§ˆë¬¸ or Query Decompositionì„ í†µí•œ ì„¸ë¶€ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„± í›„ ê²€ìƒ‰ Query -> ë¬¸ì„œ ê²€ìƒ‰ -> ë‹µë³€ ìƒì„± -> í‰ê°€ì -> \\\"ë‹µë³€\\\"ì— ëŒ€í•œ í‰ê°€(Score) - Queryì— ëŒ€í•œ ë‹µë³€ì´ ì¶©ë¶„í•œì§€ í‰ê°€ YES: ë¬¸ì„œ ê²€ìƒ‰ -> ë‹µë³€ ìƒì„± modular rag, Rag, Retrieval Augmented Generation AI ê´€ë ¨ ê¸€ rocky linux 9 k8s ë‹¨ì¼ë…¸ë“œ êµ¬ì„± #Rag\", \"score\": 0.8900749, \"raw_content\": \"Modular RAG\\nê³µë¶€ ë©”ëª¨ì¥\\nx\\nclose\\n\\nê³µë¶€ ë©”ëª¨ì¥\\n\\n\\në¶„ë¥˜ ì „ì²´ë³´ê¸° (46)\\n\\nê°œë°œ (13)\\nk8s (6)\\nTerraform (4)\\nAI (23)\\n\\n\\n\\nGithub\\n\\ní™ˆ\\níƒœê·¸\\në°©ëª…ë¡\\n\\nAI Â· 2024. 10. 26. fullscreen ë„“ê²Œë³´ê¸° fullscreen_exit ì›ë˜ëŒ€ë¡œ\\nModular RAG\\nëª©ì°¨\\n\\nModular RAG\\nëª¨ë“ˆ\\në…ë¦½ì ì¸ ëª¨ë“ˆ êµ¬ì„±\\nì¡°ë¦½í˜• ëª¨ë“ˆ\\nê·¸ë˜í”„ í˜•ì‹ì˜ ë™ì  íë¦„ êµ¬ì„±\\nì¶œì²˜\\n\\nModular RAG\\në ˆê³ ì™€ ê°™ì´ ì¬êµ¬ì„±ì´ ìš©ì´í•˜ê³  ë³´ë‹¤ ìœ ì—°í•œ íë¦„ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬\\n\\n\\në…ë¦½ì (Independant) - ê¸°ëŠ¥ ìœ„ì£¼ë¡œ ì„¸ë¶„í™”\\nìœ ì—°í•˜ê³  í™•ì¥ì„±(flexable & scalable) - ëª¨ë“ˆì˜ ì¶”ê°€ ë° ë³€ê²½ì´ ì‰¬ì›€\\në™ì (dynamic) - ê·¸ë˜í”„ í˜•ì‹ì˜ íë¦„ êµ¬ì„±, ìƒí™©ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬\\n\\n\\nëª¨ë“ˆ\\nëª¨ë“ˆ, í•˜ìœ„ ëª¨ë“ˆ ë° ìš´ì˜ìë¡œ êµ¬ì„±ëœ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ í†µí•´ í†µí•©ë˜ê³  êµ¬ì¡°í™”ëœ ë°©ì‹ìœ¼ë¡œ RAG ì‹œìŠ¤í…œì„ ì •ì˜\\n\\nê° ë‹¨ê³„(Step)ë¥¼ ëª¨ë“ˆ(Module) ë³„ë¡œ ì •ì˜\\nê° ëª¨ë“ˆì€ í•˜ìœ„ ëª¨ë“ˆ(Sub Module)ë¡œ êµ¬ì„±\\n\\n\\ní•˜ìœ„ ëª¨ë“ˆì€ í”ŒëŸ¬ê·¸ì¸ í˜•ì‹ì˜ ë…ë¦½ëœ êµ¬ì¡°\\në…ë¦½ êµ¬ì¡°\\nê° ëª¨ë“ˆì€ ì¡°ë¦½í˜•ìœ¼ë¡œ ì„¤ê³„(ë ˆê³  ë¸”ë¡)\\n\\n\\në³‘ë ¬ êµ¬ì¡°\\nì—¬ëŸ¬ í•˜ìœ„ ëª¨ë“ˆì„ ë™ì‹œì‹¤í–‰ í›„ ë³‘í•© ê°€ëŠ¥\\n\\n\\në¶„ê¸° êµ¬ì¡°\\nìƒí™©ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬ê°€ ê°€ëŠ¥\\n\\n\\n\\n\\n\\n\\në…ë¦½ì ì¸ ëª¨ë“ˆ êµ¬ì„±\\në™ì¼í•œ í˜•íƒœì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” Interface\\n\\në ˆê³  ë°©ì‹ì˜ ì¡°ë¦½ì´ ê°€ëŠ¥í•œ Module ì„¤ê³„\\në‚´ë¶€ êµ¬í˜„ì€ ëª¨ë“ˆ ë³„ ëª©ì ì— ë”°ë¼ ë‹¤ë¥´ê²Œ êµ¬í˜„\\n\\nì˜ˆ)\\n```\\ndef custom_retriever(data: RagData) -> RagData:\\n    # ì»¤ìŠ¤í…€ retriever ë¡œì§ êµ¬í˜„\\n    ...\\n    return data\\ndef request_private_api(data: RagData) -> RagData:\\n    # API í˜¸ì¶œ ë¡œì§ êµ¬í˜„\\n    ...\\n    return data\\n```\\n\\nì¡°ë¦½í˜• ëª¨ë“ˆ\\në§ˆì¹˜ ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ì„¸ë¶€ ëª¨ë“ˆ(Sub-Module)ì„ ì—°ê²°í•˜ì—¬ êµ¬ì„±\\n\\nëª¨ë“ˆì˜ ì¶”ê°€/ë³€ê²½ ìš©ì´\\n\\në…ë¦½ì ì¸ ëª¨ë“ˆì˜ ì¥ì ì„ í™œìš©\\n\\nê° Sub-Moduleì˜ êµì²´ê°€ ì‰¬ì›€\\në‹¨ê³„ì˜ ì „/í›„ì— Sub-Moduleì„ ì¶”ê°€\\n\\n\\nê·¸ë˜í”„ í˜•ì‹ì˜ ë™ì  íë¦„ êµ¬ì„±\\ní‰ê°€ì -> \\\"ë¬¸ì„œ ê²€ìƒ‰\\\"ì— ëŒ€í•œ í‰ê°€(Score) - ë¬¸ì„œì— Queryì— ëŒ€í•œ ë‹µë³€ì„ ìœ„í•œ ì •ë³´ê°€ ì¶©ë¶„í•œì§€ íŒë‹¨\\n\\n\\nSuccess: ë‹µë³€ ìƒì„±\\nFail\\nê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•œ ê²½ìš°\\në¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ Query Rewrite\\n\\n\\nì§ˆë¬¸ì´ ëª¨í˜¸í•œ ê²½ìš°\\në³´ë‹¤ ëª…í™•í•œ ì§ˆë¬¸ or Query Decompositionì„ í†µí•œ ì„¸ë¶€ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„± í›„ ê²€ìƒ‰\\n\\n\\n\\n\\n\\n\\nQuery -> ë¬¸ì„œ ê²€ìƒ‰ -> ë‹µë³€ ìƒì„± -> í‰ê°€ì -> \\\"ë‹µë³€\\\"ì— ëŒ€í•œ í‰ê°€(Score) - Queryì— ëŒ€í•œ ë‹µë³€ì´ ì¶©ë¶„í•œì§€ í‰ê°€\\n\\n\\nSuccess: ë‹µë³€ ìƒì„±\\nFail\\nì§ˆë¬¸ì´ ëª¨í˜¸í•œ ê²½ìš°\\nQuery Rewrite\\n\\n\\nì •ë³´ê°€ ë¶ˆì¶©ë¶„í•œ ê²½ìš°\\nì¶”ê°€ ê²€ìƒ‰ ëª¨ë“ˆ(Web Search)ì„ í™œìš©í•˜ì—¬ ë¬¸ë§¥(Context) ë³´ê°•\\n\\n\\n\\n\\n\\n\\nì§ˆë¬¸ì— ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ì—¬ Routing\\n\\n\\nYES: ë¬¸ì„œ ê²€ìƒ‰ -> ë‹µë³€ ìƒì„±\\nNO\\nì¦‰ê° ë‹µë³€ ìƒì„±: í† í° ë¹„ìš©ì˜ ì ˆì•½\\nì˜ˆ) \\\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\\\" -> ì¦‰ê° ë‹µë³€\\n\\n\\ní‰ê°€ì 2ëŠ” RAG ë‹µë³€ì— ëŒ€í•œ í‰ê°€\\n\\n*í‰ê°€ì : LLMì—ê²Œ í‰ê°€ ê¸°ì¤€ì„ í”„ë¡¬í”„íŠ¸ë¡œ ì œê³µí•˜ì—¬ êµ¬í˜„\\n\\nì¶œì²˜\\n\\nhttps://www.youtube.com/watch?v=aMUopbBrAmA\\nhttps://arxiv.org/pdf/2407.21059\\n\\nê³µìœ í•˜ê¸°\\nê²Œì‹œê¸€ ê´€ë¦¬\\nê³µë¶€ ë©”ëª¨ì¥\\nì €ì‘ìí‘œì‹œ\\nmodular rag, Rag, Retrieval Augmented Generation\\nAI ê´€ë ¨ ê¸€\\në” ë³´ê¸°\\n\\nLlama 3.2-Visionì„ ì‚¬ìš©í•œ ë¡œì»¬ OCR ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•í•˜ê¸° 2024.11.24\\nModular RAG Pattern 2024.10.26\\nAdvanced_RAG 2024.10.26\\nNaive RAG 2024.10.25\\n\\nê³µì§€ì‚¬í•­\\nì „ì²´ ì¹´í…Œê³ ë¦¬\\n\\në¶„ë¥˜ ì „ì²´ë³´ê¸° (46)\\nê°œë°œ (13)\\nk8s (6)\\nTerraform (4)\\nAI (23)\\n\\n\\n\\nìµœê·¼ ê¸€\\nRHEL 8.8ì—ì„œ DVD ISO íŒŒì¼ ë§ˆìš´íŠ¸ ë° ë¡œì»¬ ë ˆí¬ì§€í† ë¦¬ ì„¤ì •\\nDPO(Direct Preference Optimization)ì™€ SFT(Superviseâ‹¯\\ní…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì„ë² ë”© ëª¨ë¸ì˜ ê³¼ì •\\nHyDE(Hypothetical Document Embedding)ë€?\\në‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸ ë¹„êµ: multilingual-e5-large vs multilâ‹¯\\nì¸ê¸° ê¸€\\n[Rocky Linux 9] /home ìš©ëŸ‰ ì¤„ì´ê³  /root ìš©ëŸ‰ ëŠ˜ë¦¬ê¸°\\n LLMì„ í™œìš©í•œ GitHub PR ì½”ë“œ ë¦¬ë·° ìë™í™”\\nssh ì„œë²„ pem í‚¤ ìƒì„± ë° ì ‘ì†\\nrocky linux 9 k8s ë‹¨ì¼ë…¸ë“œ êµ¬ì„±\\nKoAlpaca ë°ì´í„°ì…‹ì„ í™œìš©í•œ Llama 3.1 LoRA ê¸°ë°˜ PEFT\\nìµœê·¼ ëŒ“ê¸€\\n\\nmwollossna 10.27 ì˜ë³´ê³ ê°€ìš”~! ê³µê°!!!\\ní¬ë˜í”„íŠ¸ëŸ¬ë²„ 10.26 ê·€ì¤‘í•œ ì •ë³´ ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‘ ì œ ë¸”ë¡œê·¸ì—ì„œë„ ë¹„ìŠ·í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆìœ¼ë‹ˆ ê¼­ ë“¤ëŸ¬ì£¼ì„¸ìš”!\\níƒ‘ë…¸íŠ¸ì‘ê°€ 10.24 ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”! â˜€ï¸\\në¨¸ìŠ¤íŠ¸ë°”ë¡œ 10.14 ìœ ìµí•œ ì •ë³´ ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ˜Š ë•ë¶„ì— ë§ì´ ë°°ì› ìŠµë‹ˆë‹¤.\\nì†Œìš¸ìºì‹œ 10.14 í¬ìŠ¤íŒ… ì˜ ë³´ê³  ê°€ìš”^^â¤ï¸\\n\\níƒœê·¸\\n\\n#ollama\\n#AWS\\n#rocky linux 9\\n#terraform\\n#k8s\\n#ì¿ ë²„ë„¤í‹°ìŠ¤\\n#í…Œë¼í¼\\n#kubernetes\\n#Retrieval Augmented Generation\\n#Rag\\n\\nì „ì²´ ë°©ë¬¸ì\\nì˜¤ëŠ˜ 39\\nì–´ì œ 93\\nì „ì²´ 8,479\\nCopyright Â© ì­ˆë¯¸ë¡œìš´ ìƒí™œ All rights reserved.\\nDesigned by JJuum\\ní‹°ìŠ¤í† ë¦¬íˆ´ë°”\"}, {\"title\": \"RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) - ê°œë°œì„¸ë°œ\", \"url\": \"https://g3lu.tistory.com/42\", \"content\": \"RAG (1) RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) ë³¸ë¬¸ Retrieval-Augmented Geneartion(RAG)ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ë¡œë¶€í„° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê°œì„ í•˜ëŠ” ê³¼ì •ì´ë‹¤. Naive RAG Retrieval :Â ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤(Vector DB)ìœ¼ë¡œ ë¶€í„° ê´€ë ¨ ë¬¸ë§¥ì„ ê²€ìƒ‰í•˜ëŠ”ë° í™œìš©ì´ ëœë‹¤. ì´ëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹  ìˆ˜ ìˆê²Œ ëœë‹¤. ì˜ëª»ëœ ì •ë³´ ì œê³µ : ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šê³  ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë‹¨ìˆœíˆ ë°˜ë³µí•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì¼ê´€ì„± ì—†ëŠ” ë‹µë³€ì„ ë±‰ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤. Advanced RAGëŠ” Naive RAG ë°©ì‹ì—ì„œ ì§ë©´í•˜ê³  ìˆëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆë‹¤. ì²­í¬ ìµœì í™” : ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤/ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ë•Œ, ì²­í¬ë¥¼ ë” ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¸ë¶€ì ì¸ íŠ¹ì„±ì„ ì¶”ì¶œí•œë‹¤. í•˜ì§€ë§Œ ê²€ìƒ‰ëœ ì²­í¬ë“¤ì´ ê°„í˜¹ ì¤‘ë³µì´ ë˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì •ë³´ë¥¼ ë‹´ëŠ” ê²½ìš° ë°œìƒí•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” LLMì´ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤.\", \"score\": 0.83093774, \"raw_content\": \"RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG)\\në³¸ë¬¸ ë°”ë¡œê°€ê¸°\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nì¹´í…Œê³ ë¦¬\\nê²€ìƒ‰í•˜ê¸°\\nê²€ìƒ‰í•˜ê¸° ë¸”ë¡œê·¸ ë‚´ ê²€ìƒ‰ \\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nG3LU\\n\\n\\në¶„ë¥˜ ì „ì²´ë³´ê¸° (42)\\në…¼ë¬¸ë¦¬ë·° (5)\\nDeep Learning ì´í•´ (9)\\nGenerative AI (2)\\nLLM (3)\\nRAG (1)\\nFine-tuning (0)\\nVector DB (0)\\nEtc (0)\\n\\n\\nComputer Vision (9)\\nData Science (3)\\nML (2)\\nêµ¬í˜„ (1)\\n\\n\\nAlgorithm (11)\\nê°œë… (0)\\nSofteeer (3)\\nLeetcode (6)\\nPython (2)\\n\\n\\n\\n\\n\\nGuestbook\\nNotice\\nRecent Posts\\n\\nRAG ì„±ëŠ¥ì„ ì¢Œì§€ìš°ì§€ í•˜ëŠ” PARSING(íŒŒì‹±)â‹¯\\n[ë…¼ë¬¸ë¦¬ë·°] RAPTOR (ì¥ë¬¸ì˜ ë¬¸ì„œì— ì í•©í•œ â‹¯\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advancâ‹¯\\nRetrieval-Augmented Generatâ‹¯\\n\\nRecent Comments\\n\\ní–‰ëª©ì…ë‹ˆë‹¤~!!.ê³µê°!\\nìˆ˜ì •ì‚¬í•­ ë°˜ì˜í•˜ì˜€ìŠµë‹ˆë‹¤! ê°ì‚¬ë“œë¦½ë‹ˆë‹¤!\\nê¸€ ì˜ ì½ì—ˆìŠµë‹ˆë‹¤! ìƒí™©ì— ë”°ë¼ì„  ì›ì‹œ ì…ë ¥ìœ¼ë¡œ ì§ì ‘ â‹¯\\nimportë¬¸ ë‘ì¤„ì´ ë¹ ì ¸ìˆì–´ WebDriverWaiâ‹¯\\n\\nLink\\nÂ« Â  2024/12 Â  Â»\\n| ì¼ | ì›” | í™” | ìˆ˜ | ëª© | ê¸ˆ | í†  |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 |\\n| 8 | 9 | 10 | 11 | 12 | 13 | 14 |\\n| 15 | 16 | 17 | 18 | 19 | 20 | 21 |\\n| 22 | 23 | 24 | 25 | 26 | 27 | 28 |\\n| 29 | 30 | 31 |  |  |  |  |\\nTags\\n\\ncomputer vision\\nleetcode\\ní¼ì…‰íŠ¸ë¡ \\nì†ì‹¤í•¨ìˆ˜\\nanomaly detection\\nLLaVA\\në°ì´í„° íŒŒì‹±\\nì´ìƒíƒì§€\\nvisual instruction tuning\\nTime Series\\nLLM\\nì˜¤ì°¨ì—­ì „íŒŒ\\ní™œì„±í™”í•¨ìˆ˜\\nCross Entropy Error\\nì‹œê³„ì—´\\nMean squared error\\nsegmentation\\nnlp\\nì»´í“¨í„°ë¹„ì „\\në¨¸ì‹ ëŸ¬ë‹\\npdf parsing\\ní•©ì„±ê³± ì‹ ê²½ë§\\nE\\ní™œì„±í™” í•¨ìˆ˜\\nrag parsing\\nNon-Maximum Suppression\\në”¥ëŸ¬ë‹\\ndeep learning\\nCNN\\n\\nmore\\nArchives\\n\\n2024/11 (1)\\n2024/10 (1)\\n2024/08 (1)\\n2024/07 (1)\\n2024/06 (2)\\n\\nToday\\n18\\nTotal\\n6,101\\në‹«ê¸° ê´€ë¦¬ ë©”ë‰´\\n\\nê¸€ì“°ê¸°\\në°©ëª…ë¡\\nRSS\\nê´€ë¦¬\\n\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) ë³¸ë¬¸\\nLLM\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG)\\nG3LU 2024. 8. 3. 18:54\\nì˜¤í”ˆAIì˜ GPT ì‹œë¦¬ì¦ˆ, Metaì˜ LLama ì‹œë¦¬ì¦ˆ, Googleì˜ Geminiì™€ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìƒì„± AIë¶„ì•¼ì—ì„œ í° ì„±ê³¼ë¥¼ ì´ë£¨ê²Œ ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ìœ„ì™€ ê°™ì€ ëª¨ë¸ë“¤ì˜ ë¬¸ì œì ì€ ì¢…ì¢… ë¶€ì •í™•í•˜ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ìƒì„±í•˜ë©°, ì˜¤ë˜ëœ ì •ë³´ì— ì˜ì¡´í•˜ê³ , decision-making ê³¼ì •ì´ íˆ¬ëª…í•˜ì§€ ì•Šì•„ ë¸”ë™ë°•ìŠ¤ ì¶”ë¡ ì„ ì´ˆë˜í•˜ê²Œ ëœë‹¤.\\nRetrieval-Augmented Geneartion(RAG)ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ë¡œë¶€í„° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê°œì„ í•˜ëŠ” ê³¼ì •ì´ë‹¤. ì´ë¥¼ í†µí•´ LLMì€ ë” ì •í™•í•˜ê³  ë¬¸ë§¥ì„ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•˜ë©°, í™˜ê°(hallucination)ì„ ë°©ì§€í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ ì¥ì ì„ ê°€ì§„ RAGëŠ” 2023ë…„ ì´í›„ LLM ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œ ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì•„í‚¤í…ì²˜ë¡œ ìë¦¬ ì¡ì•˜ë‹¤. ì´ì— RAGê°€ ì–´ë–»ê²Œ ë°œì „í•´ ì™”ëŠ”ì§€ ì•Œì•„ë³´ë„ë¡ í•˜ê² ë‹¤.\\nğŸ’¡Â RAG Framework\\nìµœê·¼ ëª‡ ë…„ ë™ì•ˆ RAG ë¶„ì•¼ì—ì„œëŠ” ë§ì€ ì—°êµ¬ê°€ ì´ë£¨ì–´ì¡Œìœ¼ë©°, í¬ê²Œ RAGëŠ” ì„¸ ê°€ì§€ì˜ ë²”ì£¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.\\n\\nNaive RAG\\nAdvanced RAG\\nModular RAGÂ \\n\\nê·¸ëŸ¼ ì´ ì„¸ ê°€ì§€ì˜ ë²”ì£¼ì— ëŒ€í•´ì„œ ì•„ë˜ì˜ ê·¸ë¦¼ì„ í†µí•´ ìì„¸íˆ ì•Œì•„ë³´ë„ë¡ í•˜ê² ë‹¤.\\n\\nğŸ’¡ Naive RAG\\n\\nIndexingÂ :Â Indexingì€ RAGì—ì„œ ìˆ˜í–‰ë˜ëŠ” ì´ˆê¸° ë‹¨ê³„ì´ë‹¤. ì´ ë‹¨ê³„ëŠ” Raw Dataë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì—ì„œ ì‹œì‘í•˜ë©°, PDF, HTML, Wordì™€ ê°™ì€ ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ í‘œì¤€í™”ëœ plain textë¡œ ë³€í™˜í•˜ê²Œ ëœë‹¤.Â ëŒ€ê·œëª¨ ì–¸ì— ëª¨ë¸(LLM)ì€ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ì— ì œí•œì´ ìˆë‹¤.Â ëŒ€ê·œëª¨ ë¬¸ì„œë‚˜ ë°ì´í„° ì…‹ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ë” ì‘ê³  ê´€ë¦¬ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë‚˜ëˆ„ê²Œ ë˜ëŠ”ë°, ì´ë¥¼Â Chunkingì´ë¼ê³  í•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ Embedding Modelë¥¼ í†µí•´ Chunkingëœ textë“¤ì„ ë²¡í„°ë¡œ í‘œí˜„ì´ ëœë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ë²¡í„°í™”ëœ ì²­í¬ëŠ” Vector DBì— í‚¤-ê°’ ìŒìœ¼ë¡œ ì €ì¥ëœ ê²Œ ëœë‹¤. ì´ëŸ¬í•œ Vector DBëŠ” ì´í›„ì˜ Retreival ë‹¨ê³„ì—ì„œ efficient í•˜ê³  scalable search capabilities ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.Â \\nRetrieval :Â ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤(Vector DB)ìœ¼ë¡œ ë¶€í„° ê´€ë ¨ ë¬¸ë§¥ì„ ê²€ìƒ‰í•˜ëŠ”ë° í™œìš©ì´ ëœë‹¤. ì´ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì¸ì½”ë”© ëª¨ë¸ì— ì˜í•´ ì²˜ë¦¬ë˜ì–´ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ì„ë² ë”©ì„ ìƒì„±í•˜ê²Œ ëœë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë²¡í„°í™”ëœ ì¿¼ë¦¬ëŠ” Vector DBì—ì„œ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ kê°œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ê°€ì¥ ë¹„ìŠ·í•œ ë°ì´í„°ë¥¼ ì°¾ê²Œ ëœë‹¤.Â \\nGenerationÂ :Â ì‚¬ìš©ìì˜ Queryì™€ ê²€ìƒ‰ëœ ì¶”ê°€ì ì¸ ì •ë³´ëŠ” Promptì— ì…ë ¥ë˜ê³  LLMë¥¼ ê±°ì³ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ ëœë‹¤.Â \\n\\nğŸ’¡Â Naive RAGì˜ ë¬¸ì œì \\n1. Indexing\\n\\nì •ë³´ ì¶”ì¶œì˜ ë¶ˆì•ˆì •ì„± : PDFì™€ ê°™ì€ ë¹„ì •í˜• íŒŒì¼ ë‚´ ì´ë¯¸ì§€ì™€ í‘œì— ìˆëŠ” ìœ ìš©í•œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ëª»í•œë‹¤.Â \\nì²­í‚¹ ë°©ë²• : ì²­í‚¹ ê³¼ì •ì—ì„œ íŒŒì¼ ìœ í˜•ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì§€ ì•Šê³  \\\"one-size-fits-all\\\" ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ëŒ€ë°˜ì‚¬ì´ë‹¤. ì´ëŠ” ê° ì²­í¬ì— ì¼ê´€ì„±ê³¼ ë¶ˆí•„ìš”í•œ ì˜ë¯¸ ì •ë³´ê°€ í¬í•¨ë  ê°€ëŠ¥ì„±ì´ í¬ë©°, ê¸°ì¡´ í…ìŠ¤íŠ¸ì˜ ë¬¸ë‹¨ êµ¬ë¶„ê³¼ ì¤‘ìš”í•œ ì„¸ë¶€ ì‚¬í•­ì„ ë†“ì¹˜ê²Œ ëœë‹¤Â \\në¹„ìµœì í™” ì¸ë±ì‹± êµ¬ì¡° : ì¸ë±ì‹± êµ¬ì¡°ê°€ ìµœì í™”ë˜ì§€ ì•Šì•„ ë¹„íš¨ìœ¨ì ì¸ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì´ˆë˜í•˜ê²Œ ë˜ë©°, ì´ëŠ” ê²€ìƒ‰ ì†ë„ë¥¼ í˜„ì €í•˜ê²Œ ëŠë¦¬ê²Œ ë§Œë“¤ê³  ê²€ìƒ‰ ê²°ê³¼ì˜ ì •í™•ì„±ì„ ë–¨ì–´ì§€ê²Œ ë§Œë“ ë‹¤.Â \\nì„ë² ë”© ëª¨ë¸ì˜ ì˜ë¯¸ í‘œí˜„ ëŠ¥ë ¥ : ì„ë² ë”© ëª¨ë¸ì´ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì œëŒ€ë¡œ íŒŒì•…í•˜ì§€ ëª»í•´, ê²€ìƒ‰ëœ ì •ë³´ì˜ ê´€ë ¨ì„±ì´ ë‚®ì•„ì§„ë‹¤. ì´ëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹  ìˆ˜ ìˆê²Œ ëœë‹¤.Â \\n\\n2. Retrieval\\n\\nì œí•œëœ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜: í‚¤ì›Œë“œ, ì˜ë¯¸, ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•˜ì§€ ì•Šì€ ë“± ë‹¤ì–‘í•œ ê²€ìƒ‰ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì˜ í†µí•©ì´ ì œí•œì ì´ë©°, ì´ëŠ” ê²€ìƒ‰ ê²°ê³¼ì˜ ë‹¤ì–‘ì„±ê³¼ ì •í™•ì„±ì„ ì €í•˜ì‹œí‚¨ë‹¤.Â \\nì¿¼ë¦¬ ë° ì„ë² ë”© ëª¨ë¸ì˜ í•œê³„ : ì¿¼ë¦¬ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì„ë² ë”© ëª¨ë¸ì˜ ì˜ë¯¸ í‘œí˜„ ì„±ëŠ¥ì´ ë‚®ì•„ ìœ ìš©í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì§€ ëª»í•œë‹¤.\\në‹µë³€ ì •ë³´ ì¤‘ë³µ : ì—¬ëŸ¬ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ê°€ ìœ ì‚¬í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì— ë°˜ë³µì ì¸ ë‚´ìš©ì´ í¬í•¨ëœë‹¤.\\n\\n3. Generation\\n\\nì˜ëª»ëœ ì‘ë‹µ ìƒì„± : LLMì´ ê´€ë ¨ ì—†ê±°ë‚˜ í¸í–¥ëœ ì‘ë‹µì„ ìƒì„±í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.Â \\nì˜ëª»ëœ ì •ë³´ ì œê³µ : ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šê³  ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë‹¨ìˆœíˆ ë°˜ë³µí•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì¼ê´€ì„± ì—†ëŠ” ë‹µë³€ì„ ë±‰ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤.Â \\n\\n\\nğŸ’¡ Advanced RAG\\nAdvanced RAGëŠ” Naive RAG ë°©ì‹ì—ì„œ ì§ë©´í•˜ê³  ìˆëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì—ì„œ ê³ ë ¤í•´ì•¼ í•  ê²ƒì€ ì–´ë– í•œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ë©°, ì•„ë˜ì™€ ê°™ì€ ì‚¬í•­ë“¤ì„ í•´ê²°í•´ì•¼ í•œë‹¤.\\n\\në¬¸ì„œì™€ ì¿¼ë¦¬ì˜ semantic representationì˜ ì •í™•ì„±ì„ ì–´ë–»ê²Œ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆì„ê¹Œ?\\nì¿¼ë¦¬ì™€ ë¬¸ì„œ(ì²­í¬)ì˜ semantic spaceë¥¼ ì–´ë–»ê²Œ align ì‹œí‚¬ìˆ˜ ìˆì„ê¹Œ?Â \\nRetrievalì˜ ì¶œë ¥ì„ LLMì˜ ì„ í˜¸ë„ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ë¬´ì—‡ì¼ê¹Œ?Â \\n\\nìœ„ì˜ ì„¸ ê°€ì§€ ê³ ì°°ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ Pre-Retreival ë° Post-Retrievalë¥¼ ê¸°ì¡´ RAG ì•„í‚¤í…ì²˜ì— ì¶”ê°€í•œ ê²ƒì´ Advanced RAGì´ë‹¤. ì´ë“¤ì˜ ì—­í• ì— ëŒ€í•´ ì•Œì•„ë³´ì.\\n1. Pre-Retrieval\\nì£¼ìš” ëª©ì ì€ ìƒ‰ì¸ êµ¬ì¡°ì™€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ëŠ” ê²ƒì´ë‹¤.\\n\\në°ì´í„° í’ˆì§ˆ í–¥ìƒ : ì—”í„°í‹°ì™€ ìš©ì–´ì˜ ëª¨í˜¸ì„±ì„ ì œê±°í•˜ê³ , ì‚¬ì‹¤ ì •í™•ì„±ì„ ìœ„í•´ ë¬¸ë§¥ ìœ ì§€ ë° ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸ í•œë‹¤.Â \\nì¸ë±ìŠ¤ êµ¬ì¡° ìµœì í™” : ì²­í¬ í¬ê¸°ë¥¼ ìµœì í™”í•˜ì—¬ ë¬¸ë§¥ì„ ì¼ì •í™”í•˜ê³  ì—”í„°í‹° ê°„ì˜ ê´€ê³„ë¥¼ í¬ì°©í•˜ê¸° ìœ„í•´ ê·¸ë˜í”„ êµ¬ì¡°ì˜ ì •ë³´ë¥¼ ì¶”ê°€í•œë‹¤.Â \\në©”íƒ€ë°ì´í„° ì¶”ê°€ : dates, chapters, subsections, purposes ë“±ê³¼ ê°™ì€ ê´€ë ¨ ì •ë³´ë¥¼ ì²­í¬ì— ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ê°€í•˜ì—¬ ë°ì´í„° í•„í„°ë§ì„ ê°œì„ í•œë‹¤.Â \\nì²­í¬ ìµœì í™” : ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤/ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ë•Œ, ì²­í¬ë¥¼ ë” ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¸ë¶€ì ì¸ íŠ¹ì„±ì„ ì¶”ì¶œí•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ì—¬ ë‚´í¬í•˜ê³  ìˆëŠ” ì˜ë¯¸ë¥¼ ë„ì¶œí•œë‹¤.Â \\n\\n2. Retrieval\\nì²­í¬ í¬ê¸°ê°€ ê²°ì •ëœ í›„, ì„ë² ë”©í•˜ê²Œ ëœë‹¤. í•´ë‹¹ ë‹¨ê³„ì—ì„œëŠ” ì¿¼ë¦¬ì™€ ì„ë² ë”©ëœ ì²­í¬ ê°„ì˜ ìœ ì‚¬ì„±ì„ ê³„ì‚°í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²­í¬ë¥¼ ì‹ë³„í•˜ê²Œëœë‹¤. ì—¬ê¸°ì„œ ì¿¼ë¦¬ì™€ ì²­í¬ì— ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© ëª¨ë¸ì„ ìµœì í™”í•  ìˆ˜ ìˆë‹¤.\\n\\nDomain Knowledge Fine-Tuning : ì„ë² ë”© ëª¨ë¸ì´ ê° ë„ë©”ì¸ë³„ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ í¬ì°©í•  ìˆ˜ ìˆë„ë¡,Â  ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ fine-tuningí•œë‹¤. ì´ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ì—ëŠ” ì¿¼ë¦¬, ì½”í¼ìŠ¤ ë° ê´€ë ¨ ë¬¸ì„œê°€ í¬í•¨ë˜ì–´ì•¼ í•œë‹¤.Â \\nDynamic Embedding : ë‹¨ì–´ê°€ ë“±ì¥í•˜ëŠ” ë§¥ë½ì— ë§ì¶° ì„ë² ë”©ì„ fine-tuningí•˜ëŠ” ë°©ì‹ì´ë‹¤. ì´ëŠ” ê° ë‹¨ì–´ì— ëŒ€í•´ í•˜ë‚˜ì˜ ë²¡í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê° í† í° ë‹¹ ì •í•´ì§„ ì„ë² ë”©ì„ ë¦¬í„´í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹ˆë¼ ì£¼ë³€ ë‹¨ì–´ì— ë”°ë¼ ë§¥ë½ì„ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” BERTë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤.Â \\n\\n3. Post-Retrieval\\nê´€ë ¨ëœ ì •ë³´(ì²­í¬)ë“¤ì„ Vector Database ë‚´ì—ì„œ ê²€ìƒ‰í•œ í›„, ì¿¼ë¦¬ì™€ í•¨ê»˜ LLMì— ì…ë ¥ëœë‹¤. í•˜ì§€ë§Œ ê²€ìƒ‰ëœ ì²­í¬ë“¤ì´ ê°„í˜¹ ì¤‘ë³µì´ ë˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì •ë³´ë¥¼ ë‹´ëŠ” ê²½ìš° ë°œìƒí•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” LLMì´ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ì•Œì•„ë³´ì.\\n\\nReranking : ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì¬ìˆœìœ„í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ìš°ì„ ì‹œí•œë‹¤. LLMì— ì…ë ¥ì´ ì¶”ê°€ë  ë•Œ, ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤. ì´ì— ê²€ìƒ‰ëœ ì²­í¬ë¥¼ ì¬ì •ë ¬í•˜ê³  Top-K ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²­í¬ë¥¼ ì‹ë³„í•˜ì—¬ LLMì— ì‚¬ìš©í•  ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µí•œë‹¤.Â \\nPrompt Compression : ê²€ìƒ‰ëœ ì •ë³´ì— Noisyê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, LLMì— íƒœìš°ê¸°ì „ì— ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ì••ì¶•í•˜ê³  ê¸¸ì´ë¥¼ ì¤„ì´ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ë‹¤.Â Â \\n\\n\\nğŸ’¡Modular RAG\\n\\bì•ì„œ ì•Œì•„ë³´ì•˜ë˜ Advanced RAGëŠ” Naive RAGì˜ ì»´í¬í„´íŠ¸ë¥¼ ì¡°ê¸ˆì”© ë³´ì™„í•œ í˜•íƒœë¼ë©´, Modular RAGëŠ” ì¡°ê¸ˆ ë” ë‚˜ì•„ê°€ ë‹¤ì–‘í•˜ê³  ìœ ì—°í•œ êµ¬ì¡°ë¥¼ ì§€í–¥í•œë‹¤. ì´ëŸ¬í•œ êµ¬ì¡°ëŠ” RAGì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œì¼°ìœ¼ë©°, í˜„ì¬ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ë•Œ í‘œì¤€ íŒ¨ëŸ¬ë‹¤ì„ì´ ë˜ì—ˆë‹¤. ê·¸ëŸ¼ ëª‡ ê°€ì§€ ëª¨ë“ˆì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ì.\\n\\nSearch Module : ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ ì™¸ì—ë„ ì¶”ê°€ì ì¸ ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. ì¦‰ Search Moduleì€ íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° LLMì´ ìƒì„±í•œ ì½”ë“œë‚˜ SQL ë“±ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“ˆì´ë‹¤. ì´ì— ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ë‹¤.\\nMemory Module : LLMì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ì²­í¬ë¿ë§Œ ì•„ë‹ˆë¼ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ì´ì „ ì¿¼ë¦¬ì™€ ê²°í•©í•˜ì—¬ í˜„ì¬ ì…ë ¥ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€ì„ ì°¾ëŠ” ëª¨ë“ˆì´ë‹¤.Â \\nFusion Module : ìœ ì €ì˜ ì˜ë„ë¥¼ ì •í™•í•˜ê²Œ ë°˜ì˜í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤ëŠ” ì°¨ê´€ì—ì„œ ë¹„ë¡¯ë˜ì—ˆë‹¤. LLMì„ í†µí•´ ìœ ì €ì˜ ì¿¼ë¦¬ë¡œ ë¶€í„° ì—¬ëŸ¬ ê°œì˜ ê°€ìƒ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ê²€ìƒ‰í•˜ëŠ” ë°©ì‹ì´ë‹¤.Â \\n\\n\\nFusion Model (RAG-Fusion)\\nìœ„ì˜ ëª¨ë“ˆë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ëª¨ë“ˆì´ ì¡´ì¬í•˜ë‹ˆ, ì´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ ë§í¬ ì°¸ê³ í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\\nê³µìœ í•˜ê¸°\\nê²Œì‹œê¸€ ê´€ë¦¬\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\n'LLM' ì¹´í…Œê³ ë¦¬ì˜ ë‹¤ë¥¸ ê¸€\\nRetrieval-Augmented Generation ì´ë€?Â Â (0)2024.07.21\\n'LLM' Related Articles\\n\\nRetrieval-Augmented Generation ì´ë€? 2024.07.21\\n\\nmore\\n\\nBlog is powered by kakao / Designed by Tistory\\ní‹°ìŠ¤í† ë¦¬íˆ´ë°”\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒêµ¬ë…í•˜ê¸°\"}, {\"title\": \"[Modular RAG]êµ¬ì¡° | Syshin\", \"url\": \"https://syshin0116.github.io/posts/Modular-RAG-êµ¬ì¡°/\", \"content\": \"Modular RAGëŠ” ì‹œìŠ¤í…œì˜ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì–´, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ ëª¨ë“ˆì„ ì¡°í•©í•˜ê³  ìµœì í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „ì‹œí‚¤ê³ ì í•œë‹¤ ... â”œâ”€â”€ langgraph/ # LangGraph ê´€ë ¨ ë¡œì§ í´ë” â”‚ â”œâ”€â”€ node_definitions.py # ë…¸ë“œ ì •ì˜ (LLM\", \"score\": 0.7992077, \"raw_content\": \"[Modular RAG]êµ¬ì¡°\\nNaive RAGì— ì—¬ëŸ¬ RAGë¥¼ í•˜ê¸° ìœ„í•´ Advanced RAGë¥¼ ì¶©ë¶„íˆ ë‹¤ë¤˜ë‹¤ê³  ìƒê°í•œë‹¤. í•˜ì§€ë§Œ, ì ì  ë” ë³µì¡í•œ ì‘ì—…ì„ ìµœì†Œí™”í•˜ê³  íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ Modular RAG ë°©ì‹ì„ ì ìš©í•˜ê³ ì í•œë‹¤. ë§ˆì¹˜ LEGO ë¸”ë¡ì²˜ëŸ¼ ëª¨ë“ˆë“¤ì„ ìŒ“ì•„ê°€ë©° ë‚˜ë§Œì˜ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ RAG ìì‚°ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ ëª©í‘œë‹¤. Modular RAGëŠ” ì‹œìŠ¤í…œì˜ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì–´, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ ëª¨ë“ˆì„ ì¡°í•©í•˜ê³  ìµœì í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „ì‹œí‚¤ê³ ì í•œë‹¤\\nModular RAG ë…¼ë¬¸: https://arxiv.org/html/2407.21059v1\\n\\n\\n\\nê¸°ìˆ  ìŠ¤íƒ\\nì´ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë‹¤ì–‘í•œ ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ëª¨ë“ˆí™”ëœ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•¨. ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë‹¤ìŒê³¼ ê°™ìŒ:\\nêµ¬ì¡°\\ní˜„ì¬:\\nêµ¬ì¡° ìš”ì•½\\nservices/retrievals\\nê²€ìƒ‰ ê´€ë ¨ ë¡œì§ì„ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ”. RAG ë°©ë²•ë¡ ì— ë”°ë¼ pre_retrieval, retrieval, post_retrievalë¡œ ë‚˜ëˆ„ì–´ ê° ë‹¨ê³„ë¥¼ ì²˜ë¦¬í•  ì˜ˆì •\\nservices/vectorstores\\nì—¬ëŸ¬ ë²¡í„° ìŠ¤í† ì–´(Chroma, Faiss, Milvus ë“±)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•  ì˜ˆì •\\nservices/preprocessing\\níŒŒì‹±ëœ ë°ì´í„°ë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ë„£ê¸° ì „ ì „ì²˜ë¦¬ ê³¼ì • ë‹´ë‹¹. ë°ì´í„° í´ë¦¬ë‹ê³¼ ë³€í™˜ ë“± ì‘ì—… í¬í•¨\\nservices/websearch\\nì›¹ ê²€ìƒ‰ ê´€ë ¨ ëª¨ë“ˆì„ êµ¬ì„±. ë‹¤ì–‘í•œ ì›¹ ê²€ìƒ‰ ì†ŒìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„\\nservices/prompt_manager\\ní”„ë¡¬í”„íŠ¸ë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ê³µê°„\\nservices/parsers\\nLlama parserì™€ íŒŒì¼ í™•ì¥ìë³„ íŒŒì„œë“¤ì„ ì •ì˜í•˜ì—¬ ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ ì²˜ë¦¬\\nservices/llm_handler\\nê³µê°œ ë° ë¹„ê³µê°œ LLM í˜¸ì¶œ í•¨ìˆ˜ë“¤ì„ ì •ì˜í•˜ê³  ê´€ë¦¬\\nlanggraph/node_definitions\\nLLM, ë¦¬íŠ¸ë¦¬ë²„, ë²¡í„° ìŠ¤í† ì–´ ë“± ì£¼ìš” ê¸°ëŠ¥ì„ ê°ê° ë…¸ë“œë¡œ ì •ì˜. ë…¸ë“œëŠ” ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•˜ë©°, ë‹¤ì–‘í•œ ì›Œí¬í”Œë¡œìš°ì—ì„œ ìœ ì—°í•˜ê²Œ ì¬ì‚¬ìš© ê°€ëŠ¥\\nlanggraph/langgraph_handler\\nLangGraphë¥¼ ê´€ë¦¬í•˜ê³ , node_definitionsì—ì„œ ì •ì˜ëœ ë…¸ë“œë“¤ì„ ë¶ˆëŸ¬ì™€ ì—£ì§€ë¡œ ì—°ê²°í•´ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±. ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ì¶° ë™ì ìœ¼ë¡œ ë…¸ë“œë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì—°ê²°í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”\\nFurther Reading\\n[Modular RAG]RDBMS vs NoSQL\\n RDBMSì™€ NoSQLì˜ ì°¨ì´ì  ë° Modular RAGì— ì í•©í•œ ì„ íƒ Modular RAGëŠ” ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì¡°í•©í•˜ë©° ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” í”„ë¡œì íŠ¸ë‹¤. ì´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒì—ì„œ RDBMSì™€ NoSQLì˜ íŠ¹ì„±ì„ ë¹„êµí•˜ê³ , Modular RAGì— ë” ì í•©í•œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„ íƒí•˜ê³ ì í•œë‹¤. RDBMS vs NoSQL: ë¹„...\\n[Modular RAG] Short Term, Long Term Memory\\n Intro Memory ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ëŠ”ë° ì–´ë–»ê²Œ í•˜ë©´ ì±—ë´‡ì´ ì‚¬ëŒì²˜ëŸ¼ ê¸°ì–µì„ í•  ìˆ˜ ìˆì„ê¹Œ, ì–´ë–»ê²Œ êµ¬í˜„í•˜ë©´ ê°€ì¥ ë„ì›€ì´ ë ê¹Œ ê³ ë¯¼í–ˆë‹¤. ê³ ë¯¼ ê²°ê³¼, ê° ì±„íŒ…ë°©ì— ì¤‘ìš” ì •ë³´ëŠ” Long Term memoryë¡œ, ìµœì‹  ì •ë³´ëŠ” Shot Term memoryë¡œ êµ¬í˜„í•˜ê³ ì í•œë‹¤. ì •ë³´ ê¸°ë³¸ Memoryì˜ ìœ í˜• ë‹¨ê¸° ê¸°ì–µ (Short-term memory) ...\\n[Modular RAG]Chat History\\n íš¨ìœ¨ì ì¸ Chat History ì €ì¥ê³¼ í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡° ì„¤ê³„ ì±—ë´‡ì„ ì„¤ê³„í•˜ë‹¤, ê¸°ë³¸ì ì¸ ì±„íŒ… ê¸°ë¡ ì €ì¥ ë°©ì‹ì— ëŒ€í•´ ê³ ë¯¼í•˜ê²Œ ë˜ì—ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì±„íŒ… ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ë°©ë²•ì€ Chat Sessionê³¼ Chat Messagesë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. ê¸°ë³¸ì ì¸ ì €ì¥ ë°©ì‹ì— ì¶”ê°€ë¡œ ê³ ë ¤í•œ ê¸°ëŠ¥, ì´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ êµ¬ì¡°, ê·¸ë¦¬ê³  ì¼ë°˜ì ì¸ ì±—ë´‡ê³¼ ì¹´ì¹´ì˜¤í†¡ ë´‡ ëª¨...\\nGCP VSCODE SSH ì—°ê²° ë°©ë²•\\n[ì •ë¦¬]Github CI/CD - GCP\\n Â© 2025 syshin. Some rights reserved.\\nUsing the Jekyll theme Chirpy.\\nA new version of content is available.\\n\"}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Naive RAG vs. Advanced RAG. In the modern world, large ... - Medium\", \"url\": \"https://medium.com/@myscale/naive-rag-vs-advanced-rag-17b38cda44c1\", \"content\": \"RAG is a strategic enhancement designed to elevate the performance of LLMs. By incorporating a step that retrieves information during text generation, RAG ensures that the modelâ€™s responses are accurate and up-to-date. Naive RAG: This is the most basic version, where the system simply retrieves the relevant information from a knowledge base and directly gives it to the LLM to generate the response. By understanding the flow of data from the userâ€™s query to the final response, we can appreciate how each component of the Naive RAG system plays a pivotal role in ensuring that the user receives accurate and relevant information. Unlike Naive RAG, which directly incorporates retrieved information, Advanced RAG involves additional processing steps that optimize the relevance, and overall quality of the response.\", \"score\": 0.8390101, \"raw_content\": \"Naive RAG vs. Advanced RAG. In the modern world, large languageâ€¦ | by MyScale | Oct, 2024 | Medium\\nOpen in app\\nSign up\\nSign in\\n\\nWrite\\n\\nSign up\\nSign in\\n\\nNaive RAG vs. Advanced RAG\\n\\nMyScale\\nÂ·Follow\\n10 min read\\nÂ·\\nOct 30, 2024\\n\\n3\\n\\nListen\\nShare\\nIn the modern world, large language models (LLMs) have transformed the world by their impressive capacity to produce texts that imitate human-written text. These models are highly skilled in tasks like creating new content and giving smart responses, pushing the AI field further. They are trained on large amounts of data, but they only know whatâ€™s in that data, making it hard for them to provide the latest information. This can lead to outdated answers or wrong information, known as information hallucinations. To address these issues, a dynamic framework called Retrieval-Augmented Generation (RAG) has been developed. It combines the strengths of traditional LLMs with retrieval systems, extending the use cases of these models.\\nWhat is RAG\\nRAG is a strategic enhancement designed to elevate the performance of LLMs. By incorporating a step that retrieves information during text generation, RAG ensures that the modelâ€™s responses are accurate and up-to-date. RAG has evolved significantly, leading to the development of two main modes:\\n\\nNaive RAG: This is the most basic version, where the system simply retrieves the relevant information from a knowledge base and directly gives it to the LLM to generate the response.\\nAdvanced RAG: This version goes a step further. It adds additional processing steps before and after retrieval to refine the retrieved information. These steps enhance the quality and accuracy of the generated response, ensuring it integrates seamlessly with the modelâ€™s output.\\n\\nNaive RAG\\nThe Naive RAG is the simplest version of the RAG ecosystem, offering a straightforward method for combining retrieval data with LLM models to efficiently respond to users.\\n\\nA basic system has the following components:\\n1. Document Chunking:\\nThe process begins with documents being split into smaller chunks. This is essential because smaller chunks are easier to manage and process. For instance, when you have a long document, itâ€™s broken down into segments, making it easier for the system to retrieve relevant information later.\\n2. Embedding Model:\\nThe embedding model is a critical part of the RAG system. It converts both the document chunks and the user query into numerical form, often called embeddings. This conversion is necessary because computers understand numerical data better. The embedding model uses advanced machine learning techniques to represent the meaning of text in a mathematical way. For example, when a user asks a question, the model transforms this question into a set of numbers that capture the semantics of the query.\\n\\n3. Vector Database (like MyScaleDB):\\nOnce the document chunks are converted into embeddings, they are stored in a vector database like MyScaleDB. The vector databases are designed to efficiently store and retrieve these embeddings. When a user submits a query, the system uses the vector database to find the most relevant document chunks by comparing the embeddings of the query with those stored in the database. This comparison helps in identifying the chunks that are most similar to what the user is asking.\\n4. Retrieval:\\nAfter the vector database identifies the relevant document chunks, they are retrieved. This retrieval process is crucial because it narrows down the information that will be used to generate the final response. Essentially, it acts as a filter, ensuring that only the most relevant data is passed on to the next stage.\\n5. LLM (Large Language Model):\\nThe LLM takes over once the relevant chunks are retrieved. Its job is to understand the retrieved information and generate a coherent response to the userâ€™s query. The LLM uses the user query and the retrieved chunks to provide a response that is not only relevant but also contextually appropriate. This model is responsible for interpreting the data and formulating a response in natural language that the user can easily understand.\\n\\n6. Response Generation:\\nFinally, the system generates a response based on the information processed by the LLM. This response is then delivered back to the user, providing them with the information they were seeking in a clear and concise manner.\\nBy understanding the flow of data from the userâ€™s query to the final response, we can appreciate how each component of the Naive RAG system plays a pivotal role in ensuring that the user receives accurate and relevant information.\\nAdvantages\\n\\nSimplicity of Implementation: RAG is straightforward to set up as it directly integrates retrieval with generation, reducing the complexity involved in enhancing language models without needing intricate modifications or additional components.\\nNo Need for Fine-Tuning: One of the significant advantages of RAG is that it doesnâ€™t require fine-tuning of the LLM. This not only saves time and reduces operational costs but also allows for faster deployment of RAG systems.\\nEnhanced Accuracy: By leveraging external, up-to-date information, Naive RAG significantly improves the accuracy of generated responses. This ensures that the outputs are not only relevant but also reflect the latest data available.\\nReduced Hallucinations: RAG mitigates the common issue of LLMs generating incorrect or fabricated information by grounding responses in real, factual data retrieved during the process.\\nScalability and Flexibility: The simplicity of Naive RAG makes it easier to scale across different applications, as it can be adapted without significant changes to existing retrieval or generative components. This flexibility allows it to be deployed across various domains with minimal customization.\\n\\nDrawbacks\\n\\nLimited Processing: The retrieved information is used directly, without further processing or refinement, which might lead to coherence issues in the generated responses.\\nDependency on Retrieval Quality: The quality of the final output heavily depends on the retrieval moduleâ€™s ability to find the most relevant information. Poor retrieval can lead to less accurate or relevant responses.\\nScalability Issues: As the dataset grows, the retrieval process may become slower, affecting the overall performance and response time.\\nContext Limitations: Naive RAG may struggle to understand the broader context of a query, leading to responses that, while accurate, might not fully align with the userâ€™s intent.\\n\\nBy examining these advantages and drawbacks, we can comprehensively understand where Naive RAG excels and where it might face challenges. This will pave the way for improvements and create the opportunity to develop advanced RAG.\\nAdvanced RAG\\nBuilding upon the foundation of Naive RAG, Advanced RAG introduces a layer of sophistication to the process. Unlike Naive RAG, which directly incorporates retrieved information, Advanced RAG involves additional processing steps that optimize the relevance, and overall quality of the response.\\n\\nLetâ€™s understand how it works:\\nPre-Retrieval Optimizations\\nIn Advanced RAG, the retrieval process is refined even before the actual retrieval takes place. Hereâ€™s what happens in this phase:\\nIndexing Improvements\\nIndexing methods play a vital role in efficiently organizing and retrieving data in databases. Traditional indexing methods, such as B-Trees and Hash indexing, have been widely used for this purpose. However, the search speed of these algorithms decreases as the data size increases. Therefore, we need more efficient indexing methods for larger datasets. MyScaleâ€™s MSTG (Multi-Strategy Tree-Graph) indexing algorithm is a prime example of such an advancement. This algorithm outperforms other indexing methods in terms of speed and performance.\\n\\nMSTG merges the strengths of both hierarchical graph and tree structures. Typically, graph algorithms are faster for unfiltered searches but may not be efficient for filtered searches. On the other hand, tree algorithms excel in filtered searches but are slower for unfiltered ones. By combining these two approaches, MSTG ensures high performance and accuracy for both unfiltered and filtered searches, making it a robust choice for a variety of search scenarios.\\nQuery Re-writing\\nBefore the retrieval process begins, the original user query undergoes several enhancements to improve its accuracy and relevance. This step ensures that the retrieval system fetches the most pertinent information. Techniques such as query rewriting, expansion, and transformation are employed here. For instance, if a userâ€™s query is too broad, query rewriting can refine it by adding more context or specific terms, while query expansion might add synonyms or related terms to capture a wider range of relevant documents.\\nDynamic Embeddings\\nIn Naive RAG, a single embedding model might be used for all types of data, which can lead to inefficiencies. Advanced RAG, however, fine-tunes and adjusts embeddings based on the specific task or domain. This means that the embedding model is trained or adapted to better capture the contextual understanding required for a particular type of query or dataset.\\nBy using dynamic embeddings, the system becomes more efficient and accurate, as the embeddings are more closely aligned with the nuances of the specific task at hand.\\nHybrid Search\\nAdvanced RAG also leverages a hybrid search approach, which combines different search strategies to enhance retrieval performance. This might include keyword-based searches, semantic searches, and neural searches. For instance, MyScaleDB supports filtered vector search and full-text search, allowing the use of complex SQL queries due to its SQL-friendly syntax. This hybrid approach ensures that the system can retrieve information with a high degree of relevance, regardless of the nature of the query.\\nPost-Retrieval Processing\\nAfter the retrieval process, Advanced RAG doesnâ€™t stop there. It further processes the retrieved data to ensure the highest quality and relevance in the final output.\\nRe-ranking\\nAfter the retrieval process, Advanced RAG takes an extra step to refine the information. This step, known as re-ranking, ensures that the most relevant and useful data is prioritized. Initially, the system retrieves several pieces of information that might be related to the userâ€™s query. However, not all of this information is equally valuable. Re-ranking helps in sorting this data based on additional factors like how closely it matches the query and how well it fits the context.\\n\\nBy reassessing the retrieved content, re-ranking places the most relevant pieces at the top. This ensures that the generated response is not only accurate but also coherent and directly addresses the userâ€™s needs. The process uses various criteria, such as semantic relevance and contextual appropriateness, to reorder the information. This refinement leads to a final response that is more focused and precise, enhancing the overall quality of the output.\\nContext Compression\\nAfter filtering the relevant documents, even with the use of a re-ranking algorithm, there may still be irrelevant data within those filtered documents for answering the userâ€™s query. The process of eliminating or removing this extraneous data is what we refer to as contextual compression. This step is applied right before passing the relevant documents to the LLM, ensuring that the LLM only receives the most relevant information, enabling it to deliver the best possible results.\\nAdvantages\\nTo better understand the differences between these two approaches, letâ€™s explore the specific advantages that advanced RAG offers over naive RAG.\\n\\nBetter Relevance with Re-ranking: Re-ranking makes sure the most relevant information comes first, improving both the accuracy and flow of the final response.\\nDynamic Embeddings for Better Context: Dynamic embeddings are customized for specific tasks, helping the system understand and respond more accurately to different queries.\\nMore Accurate Retrieval with Hybrid Search: Hybrid search uses multiple strategies to find data more effectively, ensuring higher relevance and precision in the results.\\nEfficient Responses with Context Compression: Context compression removes unnecessary details, making the process faster and leading to more focused, high-quality answers.\\nEnhanced User Query Understanding: By rewriting and expanding queries before retrieval, advanced RAG ensures that user queries are fully understood, leading to more accurate and relevant results.\\n\\nAdvanced RAG marks a major improvement in the quality of responses generated by language models. By adding a refinement stage, it effectively tackles key issues found in Naive RAG, such as coherence and relevance.\\nComparative Analysis: Naive RAG vs. Advanced RAG\\nBy comparing Naive RAG and Advanced RAG, we can observe how Advanced RAG expands on the basic framework of naive RAG. It introduces key improvements that enhance accuracy, efficiency, and the overall quality of retrieval.\\n\\nConclusion\\nWhen choosing between Naive RAG and Advanced RAG, consider the specific needs of your application. Naive RAG is ideal for simpler use cases where speed and straightforward implementation are priorities. It enhances LLM performance in scenarios where deep contextual understanding isnâ€™t critical. On the other hand, Advanced RAG is better suited for more complex applications, offering improved accuracy and coherence through additional processing steps like refined filtering and re-ranking, making it the preferred choice for handling larger datasets and complex queries.\\nMyScale further elevates these advancements by offering scalable and efficient retrieval solutions. Its sophisticated indexing and data handling techniques improve both the speed and accuracy of information retrieval, supporting the enhanced performance of RAG systems. By leveraging MyScale, developers can optimize their use of advanced RAG methods, driving improvements in AI systems and their ability to provide precise and relevant information.\\n\\nSign up to discover human stories that deepen your understanding of the world.\\nFree\\nDistraction-free reading. No ads.\\nOrganize your knowledge with lists and highlights.\\nTell your story. Find your audience.\\nSign up for free\\nMembership\\nRead member-only stories\\nSupport writers you read most\\nEarn money for your writing\\nListen to audio narrations\\nRead offline with the Medium app\\nTry for $5/month\\nRetrieval Augmented Gen\\nVector Database\\nVector Search\\nComparison\\nSome rights reserved\\n\\n3\\n\\n3\\n\\n\\n\\nFollow\\nWritten by MyScale ------------------\\n150 Followers\\nÂ·20 Following\\nAn integrated vector database, combining the power of SQL and vector for your AI data workloads. https://myscale.com/ #VectorSearch #MachineLearning #LLM\\nFollow\\nNo responses yet\\n\\nWhat are your thoughts?\\nCancel\\nRespond\\nRespond\\nAlso publish to my profile\\nMore from MyScale\\n\\n\\nMyScale\\nUnderstanding Vector Indexing: A Comprehensive Guide ---------------------------------------------------- ### In this blog, weâ€™ll cover the basics of vector indexing and how it is implemented using different techniques.\\nFeb 13\\n55\\n\\n\\n\\nMyScale\\nEnhancing Advanced RAG Systems Using Reranking with LangChain ------------------------------------------------------------- ### Understanding LangChain and Its Impact\\nJun 7\\n6\\n\\n\\n\\nMyScale\\nHow to Build a RAG-Powered Chatbot with Google Gemini and MyScaleDB ------------------------------------------------------------------- ### In the ever-evolving landscape of artificial intelligence, the quest for more intelligent, responsive, and context-aware chatbots has ledâ€¦\\nJul 19\\n80\\n\\n\\n\\nMyScale\\nHow to Summarize Large Documents with LangChain and OpenAI ---------------------------------------------------------- ### Large language models have made many tasks easier like making chatbots, language translation, text summarization, etc. We used to writeâ€¦\\nMay 24\\n84 1\\n\\nSee all from MyScale\\nRecommended from Medium\\n\\n\\nIn\\nGenerative AI\\nby\\nShrinivasan Sankar\\nRAG â€” 7 indexing methods for Vector DBs + Similarity search ----------------------------------------------------------- ### A complete guide to understanding Vector DBs used in Retrieval Augmented Generation pipelines\\nDec 6\\n50\\n\\n\\n\\nIn\\nTowards AI\\nby\\nMdabdullahalhasib\\nA Complete Guide to Embedding For NLP & Generative AI/LLM --------------------------------------------------------- ### Understand the concept of vector embedding, why it is needed, and implementation with LangChain.\\nOct 18\\n146\\n\\nLists\\n   Natural Language Processing --------------------------- 1856 storiesÂ·1484 saves\\n\\n\\nIn\\nTowards Data Science\\nby\\nWenqi Glantz\\n12 RAG Pain Points and Proposed Solutions ----------------------------------------- ### Solving the core challenges of Retrieval-Augmented Generation\\nJan 30\\n2.4K 16\\n\\n\\n\\nSamar Singh\\nMastering RAG: Advanced Methods to Enhance Retrieval-Augmented Generation ------------------------------------------------------------------------- ### RAG (Retrieval Augmentation Generation) is technique which gives llm the external knowledge or data,the data on which llm has not beenâ€¦\\nJun 17\\n109 1\\n\\n\\n\\nSougat Dey\\nEnd-to-end Implementation of a RAG Pipeline using LangChain v0.3 ---------------------------------------------------------------- ### In the tech world, it's clear that Generative AI is the current hot topic. Staying ahead in this fiercely competitive job market meansâ€¦\\nOct 29\\n1\\n\\n\\n\\nTamanna\\nHow Contextual Retrieval and Hybrid Search Enhance Retrieval-Augmented Generation (RAG) --------------------------------------------------------------------------------------- ### 1. Understanding Retrieval-Augmented Generation (RAG)\\nOct 9\\n197 4\\n\\nSee more recommendations\\nHelp\\nStatus\\nAbout\\nCareers\\nPress\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams\"}, {\"title\": \"RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) - ê°œë°œì„¸ë°œ\", \"url\": \"https://g3lu.tistory.com/42\", \"content\": \"RAG (1) RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) ë³¸ë¬¸ Retrieval-Augmented Geneartion(RAG)ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ë¡œë¶€í„° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê°œì„ í•˜ëŠ” ê³¼ì •ì´ë‹¤. Naive RAG Retrieval :Â ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤(Vector DB)ìœ¼ë¡œ ë¶€í„° ê´€ë ¨ ë¬¸ë§¥ì„ ê²€ìƒ‰í•˜ëŠ”ë° í™œìš©ì´ ëœë‹¤. ì´ëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹  ìˆ˜ ìˆê²Œ ëœë‹¤. ì˜ëª»ëœ ì •ë³´ ì œê³µ : ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šê³  ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë‹¨ìˆœíˆ ë°˜ë³µí•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì¼ê´€ì„± ì—†ëŠ” ë‹µë³€ì„ ë±‰ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤. Advanced RAGëŠ” Naive RAG ë°©ì‹ì—ì„œ ì§ë©´í•˜ê³  ìˆëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆë‹¤. ì²­í¬ ìµœì í™” : ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤/ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ë•Œ, ì²­í¬ë¥¼ ë” ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¸ë¶€ì ì¸ íŠ¹ì„±ì„ ì¶”ì¶œí•œë‹¤. í•˜ì§€ë§Œ ê²€ìƒ‰ëœ ì²­í¬ë“¤ì´ ê°„í˜¹ ì¤‘ë³µì´ ë˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì •ë³´ë¥¼ ë‹´ëŠ” ê²½ìš° ë°œìƒí•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” LLMì´ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤.\", \"score\": 0.8266142, \"raw_content\": \"RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG)\\në³¸ë¬¸ ë°”ë¡œê°€ê¸°\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nì¹´í…Œê³ ë¦¬\\nê²€ìƒ‰í•˜ê¸°\\nê²€ìƒ‰í•˜ê¸° ë¸”ë¡œê·¸ ë‚´ ê²€ìƒ‰ \\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nG3LU\\n\\n\\në¶„ë¥˜ ì „ì²´ë³´ê¸° (42)\\në…¼ë¬¸ë¦¬ë·° (5)\\nDeep Learning ì´í•´ (9)\\nGenerative AI (2)\\nLLM (3)\\nRAG (1)\\nFine-tuning (0)\\nVector DB (0)\\nEtc (0)\\n\\n\\nComputer Vision (9)\\nData Science (3)\\nML (2)\\nêµ¬í˜„ (1)\\n\\n\\nAlgorithm (11)\\nê°œë… (0)\\nSofteeer (3)\\nLeetcode (6)\\nPython (2)\\n\\n\\n\\n\\n\\nGuestbook\\nNotice\\nRecent Posts\\n\\nRAG ì„±ëŠ¥ì„ ì¢Œì§€ìš°ì§€ í•˜ëŠ” PARSING(íŒŒì‹±)â‹¯\\n[ë…¼ë¬¸ë¦¬ë·°] RAPTOR (ì¥ë¬¸ì˜ ë¬¸ì„œì— ì í•©í•œ â‹¯\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advancâ‹¯\\nRetrieval-Augmented Generatâ‹¯\\n\\nRecent Comments\\n\\ní–‰ëª©ì…ë‹ˆë‹¤~!!.ê³µê°!\\nìˆ˜ì •ì‚¬í•­ ë°˜ì˜í•˜ì˜€ìŠµë‹ˆë‹¤! ê°ì‚¬ë“œë¦½ë‹ˆë‹¤!\\nê¸€ ì˜ ì½ì—ˆìŠµë‹ˆë‹¤! ìƒí™©ì— ë”°ë¼ì„  ì›ì‹œ ì…ë ¥ìœ¼ë¡œ ì§ì ‘ â‹¯\\nimportë¬¸ ë‘ì¤„ì´ ë¹ ì ¸ìˆì–´ WebDriverWaiâ‹¯\\n\\nLink\\nÂ« Â  2024/12 Â  Â»\\n| ì¼ | ì›” | í™” | ìˆ˜ | ëª© | ê¸ˆ | í†  |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 |\\n| 8 | 9 | 10 | 11 | 12 | 13 | 14 |\\n| 15 | 16 | 17 | 18 | 19 | 20 | 21 |\\n| 22 | 23 | 24 | 25 | 26 | 27 | 28 |\\n| 29 | 30 | 31 |  |  |  |  |\\nTags\\n\\ncomputer vision\\nleetcode\\ní¼ì…‰íŠ¸ë¡ \\nì†ì‹¤í•¨ìˆ˜\\nanomaly detection\\nLLaVA\\në°ì´í„° íŒŒì‹±\\nì´ìƒíƒì§€\\nvisual instruction tuning\\nTime Series\\nLLM\\nì˜¤ì°¨ì—­ì „íŒŒ\\ní™œì„±í™”í•¨ìˆ˜\\nCross Entropy Error\\nì‹œê³„ì—´\\nMean squared error\\nsegmentation\\nnlp\\nì»´í“¨í„°ë¹„ì „\\në¨¸ì‹ ëŸ¬ë‹\\npdf parsing\\ní•©ì„±ê³± ì‹ ê²½ë§\\nE\\ní™œì„±í™” í•¨ìˆ˜\\nrag parsing\\nNon-Maximum Suppression\\në”¥ëŸ¬ë‹\\ndeep learning\\nCNN\\n\\nmore\\nArchives\\n\\n2024/11 (1)\\n2024/10 (1)\\n2024/08 (1)\\n2024/07 (1)\\n2024/06 (2)\\n\\nToday\\n18\\nTotal\\n6,101\\në‹«ê¸° ê´€ë¦¬ ë©”ë‰´\\n\\nê¸€ì“°ê¸°\\në°©ëª…ë¡\\nRSS\\nê´€ë¦¬\\n\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) ë³¸ë¬¸\\nLLM\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG)\\nG3LU 2024. 8. 3. 18:54\\nì˜¤í”ˆAIì˜ GPT ì‹œë¦¬ì¦ˆ, Metaì˜ LLama ì‹œë¦¬ì¦ˆ, Googleì˜ Geminiì™€ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìƒì„± AIë¶„ì•¼ì—ì„œ í° ì„±ê³¼ë¥¼ ì´ë£¨ê²Œ ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ìœ„ì™€ ê°™ì€ ëª¨ë¸ë“¤ì˜ ë¬¸ì œì ì€ ì¢…ì¢… ë¶€ì •í™•í•˜ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ìƒì„±í•˜ë©°, ì˜¤ë˜ëœ ì •ë³´ì— ì˜ì¡´í•˜ê³ , decision-making ê³¼ì •ì´ íˆ¬ëª…í•˜ì§€ ì•Šì•„ ë¸”ë™ë°•ìŠ¤ ì¶”ë¡ ì„ ì´ˆë˜í•˜ê²Œ ëœë‹¤.\\nRetrieval-Augmented Geneartion(RAG)ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ë¡œë¶€í„° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê°œì„ í•˜ëŠ” ê³¼ì •ì´ë‹¤. ì´ë¥¼ í†µí•´ LLMì€ ë” ì •í™•í•˜ê³  ë¬¸ë§¥ì„ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•˜ë©°, í™˜ê°(hallucination)ì„ ë°©ì§€í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ ì¥ì ì„ ê°€ì§„ RAGëŠ” 2023ë…„ ì´í›„ LLM ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œ ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì•„í‚¤í…ì²˜ë¡œ ìë¦¬ ì¡ì•˜ë‹¤. ì´ì— RAGê°€ ì–´ë–»ê²Œ ë°œì „í•´ ì™”ëŠ”ì§€ ì•Œì•„ë³´ë„ë¡ í•˜ê² ë‹¤.\\nğŸ’¡Â RAG Framework\\nìµœê·¼ ëª‡ ë…„ ë™ì•ˆ RAG ë¶„ì•¼ì—ì„œëŠ” ë§ì€ ì—°êµ¬ê°€ ì´ë£¨ì–´ì¡Œìœ¼ë©°, í¬ê²Œ RAGëŠ” ì„¸ ê°€ì§€ì˜ ë²”ì£¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.\\n\\nNaive RAG\\nAdvanced RAG\\nModular RAGÂ \\n\\nê·¸ëŸ¼ ì´ ì„¸ ê°€ì§€ì˜ ë²”ì£¼ì— ëŒ€í•´ì„œ ì•„ë˜ì˜ ê·¸ë¦¼ì„ í†µí•´ ìì„¸íˆ ì•Œì•„ë³´ë„ë¡ í•˜ê² ë‹¤.\\n\\nğŸ’¡ Naive RAG\\n\\nIndexingÂ :Â Indexingì€ RAGì—ì„œ ìˆ˜í–‰ë˜ëŠ” ì´ˆê¸° ë‹¨ê³„ì´ë‹¤. ì´ ë‹¨ê³„ëŠ” Raw Dataë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì—ì„œ ì‹œì‘í•˜ë©°, PDF, HTML, Wordì™€ ê°™ì€ ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ í‘œì¤€í™”ëœ plain textë¡œ ë³€í™˜í•˜ê²Œ ëœë‹¤.Â ëŒ€ê·œëª¨ ì–¸ì— ëª¨ë¸(LLM)ì€ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ì— ì œí•œì´ ìˆë‹¤.Â ëŒ€ê·œëª¨ ë¬¸ì„œë‚˜ ë°ì´í„° ì…‹ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ë” ì‘ê³  ê´€ë¦¬ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë‚˜ëˆ„ê²Œ ë˜ëŠ”ë°, ì´ë¥¼Â Chunkingì´ë¼ê³  í•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ Embedding Modelë¥¼ í†µí•´ Chunkingëœ textë“¤ì„ ë²¡í„°ë¡œ í‘œí˜„ì´ ëœë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ë²¡í„°í™”ëœ ì²­í¬ëŠ” Vector DBì— í‚¤-ê°’ ìŒìœ¼ë¡œ ì €ì¥ëœ ê²Œ ëœë‹¤. ì´ëŸ¬í•œ Vector DBëŠ” ì´í›„ì˜ Retreival ë‹¨ê³„ì—ì„œ efficient í•˜ê³  scalable search capabilities ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.Â \\nRetrieval :Â ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤(Vector DB)ìœ¼ë¡œ ë¶€í„° ê´€ë ¨ ë¬¸ë§¥ì„ ê²€ìƒ‰í•˜ëŠ”ë° í™œìš©ì´ ëœë‹¤. ì´ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì¸ì½”ë”© ëª¨ë¸ì— ì˜í•´ ì²˜ë¦¬ë˜ì–´ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ì„ë² ë”©ì„ ìƒì„±í•˜ê²Œ ëœë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë²¡í„°í™”ëœ ì¿¼ë¦¬ëŠ” Vector DBì—ì„œ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ kê°œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ê°€ì¥ ë¹„ìŠ·í•œ ë°ì´í„°ë¥¼ ì°¾ê²Œ ëœë‹¤.Â \\nGenerationÂ :Â ì‚¬ìš©ìì˜ Queryì™€ ê²€ìƒ‰ëœ ì¶”ê°€ì ì¸ ì •ë³´ëŠ” Promptì— ì…ë ¥ë˜ê³  LLMë¥¼ ê±°ì³ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ ëœë‹¤.Â \\n\\nğŸ’¡Â Naive RAGì˜ ë¬¸ì œì \\n1. Indexing\\n\\nì •ë³´ ì¶”ì¶œì˜ ë¶ˆì•ˆì •ì„± : PDFì™€ ê°™ì€ ë¹„ì •í˜• íŒŒì¼ ë‚´ ì´ë¯¸ì§€ì™€ í‘œì— ìˆëŠ” ìœ ìš©í•œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ëª»í•œë‹¤.Â \\nì²­í‚¹ ë°©ë²• : ì²­í‚¹ ê³¼ì •ì—ì„œ íŒŒì¼ ìœ í˜•ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì§€ ì•Šê³  \\\"one-size-fits-all\\\" ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ëŒ€ë°˜ì‚¬ì´ë‹¤. ì´ëŠ” ê° ì²­í¬ì— ì¼ê´€ì„±ê³¼ ë¶ˆí•„ìš”í•œ ì˜ë¯¸ ì •ë³´ê°€ í¬í•¨ë  ê°€ëŠ¥ì„±ì´ í¬ë©°, ê¸°ì¡´ í…ìŠ¤íŠ¸ì˜ ë¬¸ë‹¨ êµ¬ë¶„ê³¼ ì¤‘ìš”í•œ ì„¸ë¶€ ì‚¬í•­ì„ ë†“ì¹˜ê²Œ ëœë‹¤Â \\në¹„ìµœì í™” ì¸ë±ì‹± êµ¬ì¡° : ì¸ë±ì‹± êµ¬ì¡°ê°€ ìµœì í™”ë˜ì§€ ì•Šì•„ ë¹„íš¨ìœ¨ì ì¸ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì´ˆë˜í•˜ê²Œ ë˜ë©°, ì´ëŠ” ê²€ìƒ‰ ì†ë„ë¥¼ í˜„ì €í•˜ê²Œ ëŠë¦¬ê²Œ ë§Œë“¤ê³  ê²€ìƒ‰ ê²°ê³¼ì˜ ì •í™•ì„±ì„ ë–¨ì–´ì§€ê²Œ ë§Œë“ ë‹¤.Â \\nì„ë² ë”© ëª¨ë¸ì˜ ì˜ë¯¸ í‘œí˜„ ëŠ¥ë ¥ : ì„ë² ë”© ëª¨ë¸ì´ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì œëŒ€ë¡œ íŒŒì•…í•˜ì§€ ëª»í•´, ê²€ìƒ‰ëœ ì •ë³´ì˜ ê´€ë ¨ì„±ì´ ë‚®ì•„ì§„ë‹¤. ì´ëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹  ìˆ˜ ìˆê²Œ ëœë‹¤.Â \\n\\n2. Retrieval\\n\\nì œí•œëœ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜: í‚¤ì›Œë“œ, ì˜ë¯¸, ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•˜ì§€ ì•Šì€ ë“± ë‹¤ì–‘í•œ ê²€ìƒ‰ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì˜ í†µí•©ì´ ì œí•œì ì´ë©°, ì´ëŠ” ê²€ìƒ‰ ê²°ê³¼ì˜ ë‹¤ì–‘ì„±ê³¼ ì •í™•ì„±ì„ ì €í•˜ì‹œí‚¨ë‹¤.Â \\nì¿¼ë¦¬ ë° ì„ë² ë”© ëª¨ë¸ì˜ í•œê³„ : ì¿¼ë¦¬ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì„ë² ë”© ëª¨ë¸ì˜ ì˜ë¯¸ í‘œí˜„ ì„±ëŠ¥ì´ ë‚®ì•„ ìœ ìš©í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì§€ ëª»í•œë‹¤.\\në‹µë³€ ì •ë³´ ì¤‘ë³µ : ì—¬ëŸ¬ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ê°€ ìœ ì‚¬í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì— ë°˜ë³µì ì¸ ë‚´ìš©ì´ í¬í•¨ëœë‹¤.\\n\\n3. Generation\\n\\nì˜ëª»ëœ ì‘ë‹µ ìƒì„± : LLMì´ ê´€ë ¨ ì—†ê±°ë‚˜ í¸í–¥ëœ ì‘ë‹µì„ ìƒì„±í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.Â \\nì˜ëª»ëœ ì •ë³´ ì œê³µ : ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šê³  ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë‹¨ìˆœíˆ ë°˜ë³µí•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì¼ê´€ì„± ì—†ëŠ” ë‹µë³€ì„ ë±‰ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤.Â \\n\\n\\nğŸ’¡ Advanced RAG\\nAdvanced RAGëŠ” Naive RAG ë°©ì‹ì—ì„œ ì§ë©´í•˜ê³  ìˆëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì—ì„œ ê³ ë ¤í•´ì•¼ í•  ê²ƒì€ ì–´ë– í•œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ë©°, ì•„ë˜ì™€ ê°™ì€ ì‚¬í•­ë“¤ì„ í•´ê²°í•´ì•¼ í•œë‹¤.\\n\\në¬¸ì„œì™€ ì¿¼ë¦¬ì˜ semantic representationì˜ ì •í™•ì„±ì„ ì–´ë–»ê²Œ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆì„ê¹Œ?\\nì¿¼ë¦¬ì™€ ë¬¸ì„œ(ì²­í¬)ì˜ semantic spaceë¥¼ ì–´ë–»ê²Œ align ì‹œí‚¬ìˆ˜ ìˆì„ê¹Œ?Â \\nRetrievalì˜ ì¶œë ¥ì„ LLMì˜ ì„ í˜¸ë„ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ë¬´ì—‡ì¼ê¹Œ?Â \\n\\nìœ„ì˜ ì„¸ ê°€ì§€ ê³ ì°°ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ Pre-Retreival ë° Post-Retrievalë¥¼ ê¸°ì¡´ RAG ì•„í‚¤í…ì²˜ì— ì¶”ê°€í•œ ê²ƒì´ Advanced RAGì´ë‹¤. ì´ë“¤ì˜ ì—­í• ì— ëŒ€í•´ ì•Œì•„ë³´ì.\\n1. Pre-Retrieval\\nì£¼ìš” ëª©ì ì€ ìƒ‰ì¸ êµ¬ì¡°ì™€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ëŠ” ê²ƒì´ë‹¤.\\n\\në°ì´í„° í’ˆì§ˆ í–¥ìƒ : ì—”í„°í‹°ì™€ ìš©ì–´ì˜ ëª¨í˜¸ì„±ì„ ì œê±°í•˜ê³ , ì‚¬ì‹¤ ì •í™•ì„±ì„ ìœ„í•´ ë¬¸ë§¥ ìœ ì§€ ë° ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸ í•œë‹¤.Â \\nì¸ë±ìŠ¤ êµ¬ì¡° ìµœì í™” : ì²­í¬ í¬ê¸°ë¥¼ ìµœì í™”í•˜ì—¬ ë¬¸ë§¥ì„ ì¼ì •í™”í•˜ê³  ì—”í„°í‹° ê°„ì˜ ê´€ê³„ë¥¼ í¬ì°©í•˜ê¸° ìœ„í•´ ê·¸ë˜í”„ êµ¬ì¡°ì˜ ì •ë³´ë¥¼ ì¶”ê°€í•œë‹¤.Â \\në©”íƒ€ë°ì´í„° ì¶”ê°€ : dates, chapters, subsections, purposes ë“±ê³¼ ê°™ì€ ê´€ë ¨ ì •ë³´ë¥¼ ì²­í¬ì— ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ê°€í•˜ì—¬ ë°ì´í„° í•„í„°ë§ì„ ê°œì„ í•œë‹¤.Â \\nì²­í¬ ìµœì í™” : ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤/ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ë•Œ, ì²­í¬ë¥¼ ë” ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¸ë¶€ì ì¸ íŠ¹ì„±ì„ ì¶”ì¶œí•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ì—¬ ë‚´í¬í•˜ê³  ìˆëŠ” ì˜ë¯¸ë¥¼ ë„ì¶œí•œë‹¤.Â \\n\\n2. Retrieval\\nì²­í¬ í¬ê¸°ê°€ ê²°ì •ëœ í›„, ì„ë² ë”©í•˜ê²Œ ëœë‹¤. í•´ë‹¹ ë‹¨ê³„ì—ì„œëŠ” ì¿¼ë¦¬ì™€ ì„ë² ë”©ëœ ì²­í¬ ê°„ì˜ ìœ ì‚¬ì„±ì„ ê³„ì‚°í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²­í¬ë¥¼ ì‹ë³„í•˜ê²Œëœë‹¤. ì—¬ê¸°ì„œ ì¿¼ë¦¬ì™€ ì²­í¬ì— ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© ëª¨ë¸ì„ ìµœì í™”í•  ìˆ˜ ìˆë‹¤.\\n\\nDomain Knowledge Fine-Tuning : ì„ë² ë”© ëª¨ë¸ì´ ê° ë„ë©”ì¸ë³„ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ í¬ì°©í•  ìˆ˜ ìˆë„ë¡,Â  ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ fine-tuningí•œë‹¤. ì´ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ì—ëŠ” ì¿¼ë¦¬, ì½”í¼ìŠ¤ ë° ê´€ë ¨ ë¬¸ì„œê°€ í¬í•¨ë˜ì–´ì•¼ í•œë‹¤.Â \\nDynamic Embedding : ë‹¨ì–´ê°€ ë“±ì¥í•˜ëŠ” ë§¥ë½ì— ë§ì¶° ì„ë² ë”©ì„ fine-tuningí•˜ëŠ” ë°©ì‹ì´ë‹¤. ì´ëŠ” ê° ë‹¨ì–´ì— ëŒ€í•´ í•˜ë‚˜ì˜ ë²¡í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê° í† í° ë‹¹ ì •í•´ì§„ ì„ë² ë”©ì„ ë¦¬í„´í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹ˆë¼ ì£¼ë³€ ë‹¨ì–´ì— ë”°ë¼ ë§¥ë½ì„ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” BERTë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤.Â \\n\\n3. Post-Retrieval\\nê´€ë ¨ëœ ì •ë³´(ì²­í¬)ë“¤ì„ Vector Database ë‚´ì—ì„œ ê²€ìƒ‰í•œ í›„, ì¿¼ë¦¬ì™€ í•¨ê»˜ LLMì— ì…ë ¥ëœë‹¤. í•˜ì§€ë§Œ ê²€ìƒ‰ëœ ì²­í¬ë“¤ì´ ê°„í˜¹ ì¤‘ë³µì´ ë˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì •ë³´ë¥¼ ë‹´ëŠ” ê²½ìš° ë°œìƒí•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” LLMì´ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ì•Œì•„ë³´ì.\\n\\nReranking : ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì¬ìˆœìœ„í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ìš°ì„ ì‹œí•œë‹¤. LLMì— ì…ë ¥ì´ ì¶”ê°€ë  ë•Œ, ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤. ì´ì— ê²€ìƒ‰ëœ ì²­í¬ë¥¼ ì¬ì •ë ¬í•˜ê³  Top-K ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²­í¬ë¥¼ ì‹ë³„í•˜ì—¬ LLMì— ì‚¬ìš©í•  ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µí•œë‹¤.Â \\nPrompt Compression : ê²€ìƒ‰ëœ ì •ë³´ì— Noisyê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, LLMì— íƒœìš°ê¸°ì „ì— ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ì••ì¶•í•˜ê³  ê¸¸ì´ë¥¼ ì¤„ì´ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ë‹¤.Â Â \\n\\n\\nğŸ’¡Modular RAG\\n\\bì•ì„œ ì•Œì•„ë³´ì•˜ë˜ Advanced RAGëŠ” Naive RAGì˜ ì»´í¬í„´íŠ¸ë¥¼ ì¡°ê¸ˆì”© ë³´ì™„í•œ í˜•íƒœë¼ë©´, Modular RAGëŠ” ì¡°ê¸ˆ ë” ë‚˜ì•„ê°€ ë‹¤ì–‘í•˜ê³  ìœ ì—°í•œ êµ¬ì¡°ë¥¼ ì§€í–¥í•œë‹¤. ì´ëŸ¬í•œ êµ¬ì¡°ëŠ” RAGì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œì¼°ìœ¼ë©°, í˜„ì¬ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ë•Œ í‘œì¤€ íŒ¨ëŸ¬ë‹¤ì„ì´ ë˜ì—ˆë‹¤. ê·¸ëŸ¼ ëª‡ ê°€ì§€ ëª¨ë“ˆì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ì.\\n\\nSearch Module : ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ ì™¸ì—ë„ ì¶”ê°€ì ì¸ ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. ì¦‰ Search Moduleì€ íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° LLMì´ ìƒì„±í•œ ì½”ë“œë‚˜ SQL ë“±ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“ˆì´ë‹¤. ì´ì— ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ë‹¤.\\nMemory Module : LLMì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ì²­í¬ë¿ë§Œ ì•„ë‹ˆë¼ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ì´ì „ ì¿¼ë¦¬ì™€ ê²°í•©í•˜ì—¬ í˜„ì¬ ì…ë ¥ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€ì„ ì°¾ëŠ” ëª¨ë“ˆì´ë‹¤.Â \\nFusion Module : ìœ ì €ì˜ ì˜ë„ë¥¼ ì •í™•í•˜ê²Œ ë°˜ì˜í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤ëŠ” ì°¨ê´€ì—ì„œ ë¹„ë¡¯ë˜ì—ˆë‹¤. LLMì„ í†µí•´ ìœ ì €ì˜ ì¿¼ë¦¬ë¡œ ë¶€í„° ì—¬ëŸ¬ ê°œì˜ ê°€ìƒ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ê²€ìƒ‰í•˜ëŠ” ë°©ì‹ì´ë‹¤.Â \\n\\n\\nFusion Model (RAG-Fusion)\\nìœ„ì˜ ëª¨ë“ˆë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ëª¨ë“ˆì´ ì¡´ì¬í•˜ë‹ˆ, ì´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ ë§í¬ ì°¸ê³ í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\\nê³µìœ í•˜ê¸°\\nê²Œì‹œê¸€ ê´€ë¦¬\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\n'LLM' ì¹´í…Œê³ ë¦¬ì˜ ë‹¤ë¥¸ ê¸€\\nRetrieval-Augmented Generation ì´ë€?Â Â (0)2024.07.21\\n'LLM' Related Articles\\n\\nRetrieval-Augmented Generation ì´ë€? 2024.07.21\\n\\nmore\\n\\nBlog is powered by kakao / Designed by Tistory\\ní‹°ìŠ¤í† ë¦¬íˆ´ë°”\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒêµ¬ë…í•˜ê¸°\"}, {\"title\": \"Naive RAG, Advanced RAG, Modular RAG : ë„¤ì´ë²„ ... - ë„¤ì´ë²„ ë¸”ë¡œê·¸\", \"url\": \"https://blog.naver.com/PostView.naver?blogId=jangjw01088&logNo=223650933570\", \"content\": \"Naive RAGëŠ” ë‹¨ìˆœí•˜ê³  ì§ê´€ì ì´ì§€ë§Œ, ê²€ìƒ‰ ì •í™•ì„±ì´ë‚˜ ì‘ë‹µì˜ ê´€ë ¨ì„±ì—ì„œ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. Advanced RAGëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ê³¼ ì •ë³´ ì²˜ë¦¬ì—ì„œ ë” ë³µì¡í•œ ìµœì í™” ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Modular RAGëŠ” ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ê²°í•©í•˜ì—¬ ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ì™€ ê¸°ìˆ ì„\", \"score\": 0.7969415, \"raw_content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nì¸ê³µì§€ëŠ¥ ì´ì•¼ê¸°\\në¸”ë¡œê·¸\\n\\nNaive RAG, Advanced RAG, Modular RAG\\nRAG\\nRAGëŠ” Retrieval-Augmented Generation ë¡œ ê²€ìƒ‰ ì¦ê°• ìƒì„± ì…ë‹ˆë‹¤.\\nì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì „ì œì²™ì¸ í”„ë¡œì„¸ìŠ¤ ì…ë‹ˆë‹¤.\\n1. ë¨¼ì € ë°ì´í„°ë¥¼ ì„ë² ë”©í•´ ë²¡í„°DBì— ì €ì¥í•©ë‹ˆë‹¤.\\n2. ì‚¬ìš©ì ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´, ì´ ì§ˆë¬¸ê³¼ ë²¡í„°DBì— ì €ì¥ëœ ë¬¸ì„œì™€ ìœ ì‚¬ë„ê³„ì‚°ì„ í†µí•´ ê°€ì¥ ìœ ì‚¬í•œ Chunk ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\\n3. ì´ Chunkì™€ ì‚¬ìš©ì ì§ˆë¬¸ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ê±°ì³ LLMì—ê²Œ ì „ë‹¬ë˜ì–´ ìµœì¢… ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤.\\nâ€‹\\nâ€‹\\nì´ 3ê°€ì§€ RAG ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤. ( Naive RAG, Advanced RAG, Modular RAG )\\nìœ„ì—ì„œ ì„¤ëª…í•œ RAGê°€ Naive RAG (ê°€ì¥ ê¸°ë³¸ì ì¸ RAG) ì…ë‹ˆë‹¤.\\nì´ Naive RAGëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\\nê²€ìƒ‰ ë‹¨ê³„ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ê°€ ëˆ„ë½ë˜ê±°ë‚˜ ì˜ëª»ëœ ì •ë³´ê°€ ê²€ìƒ‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì¦ê°• ë‹¨ê³„ì—ì„œ ê´€ë ¨ ì—†ëŠ” ì •ë³´ë‚˜ ë°˜ë³µì ì¸ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nìƒì„± ë‹¨ê³„ì—ì„œ LLMì´ ê²€ìƒ‰í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µì„ ìƒì„±í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nâ€‹\\nAdvanced RAG\\nAdvanced RAGëŠ” Naive RAGì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ê°€ì§€ ì „ëµì„ ë„ì…í•œ ë°©ì‹ì…ë‹ˆë‹¤. ì£¼ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³ , ê²€ìƒ‰ëœ ì •ë³´ê°€ LLMì— ë” ì˜ í†µí•©ë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì´ í¬í•¨ë©ë‹ˆë‹¤. \\nâ€‹\\nPre-Retreival (ê²€ìƒ‰ ì „ ìµœì í™”)\\në°ì´í„° í’ˆì§ˆ ê°œì„  : ë°ì´í„°ì—ì„œ ë¶ˆí•„ìš”í•œ ì •ë³´ë‚˜ ëª¨í˜¸í•œ ë‚´ìš©ì„ ì œê±°í•˜ê³ , ì‚¬ì‹¤ì„ í™•ì¸í•˜ë©°, ì—…ë°ì´íŠ¸ëœ ì •ã…ˆë³´ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\\nì¸ë±ìŠ¤ êµ¬ì¡° ìµœì¡±í™” : ê²€ìƒ‰ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë°ì´í„° ì¸ë±ìŠ¤ì˜ êµ¬ì¡°ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.\\në©”íƒ€ë°ì´í„° ì¶”ê°€ : ë¬¸ì„œì— ë‚ ì§œ, ì¥, ì„¹ì…˜ ë“±ì„ ì¶”ê°€í•˜ì—¬ ê²€ìƒ‰ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\\nâ€‹\\nRetreival (ê²€ìƒ‰ ë‹¨ê³„)\\në„ë©”ì¸ ì§€ì‹ ë¯¸ì„¸ ì¡°ì • : ê²€ìƒ‰ ì—”ì§„ì´ ë„ë©”ì¸ì— íŠ¹í™”ëœ ì •ë³´ë¥¼ ì˜ ë‹¤ë£° ìˆ˜ ìˆë„ë¡ ë„ë©”ì¸ ë°ì´í„°ë¥¼ í™œìš©í•´ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.\\nìœ ì‚¬ë„ ì¸¡ì • : ê²€ìƒ‰ëœ ë²¡í„°ê°€ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ ì¸¡ì •í•˜ëŠ” ìœ ì‚¬ë„ ì¸¡ì • ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\\nâ€‹\\nPost-Retreival (ê²€ìƒ‰ í›„ ì²˜ë¦¬)\\nì¬ë­í‚¹ : ê²€ìƒ‰ëœ ì •ë³´ì˜ ìˆœì„œë¥¼ ì¬ì¡°ì •í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‚´ìš©ì„ ìš°ì„ ì‹œí•©ë‹ˆë‹¤.\\ní”„ë¡¬í”„íŠ¸ ì••ì¶• : ê¸¸ê³  ë³µì¡í•œ ì •ë³´ë¥¼ ìš”ì•½í•˜ê±°ë‚˜ ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ ì œê±°í•˜ì—¬ ëª¨ë¸ì— ì œê³µí•  ë°ì´í„°ì˜ ì–‘ì„ ì¤„ì…ë‹ˆë‹¤.\\nâ€‹\\nModular RAG\\nModular RAG ëŠ” Advanced RAGì˜ ë‹¤ì–‘í•œ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ë”ìš± í–¥ìƒëœ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ì—¬ëŸ¬ ëª¨ë“ˆì„ í†µí•©í•˜ì—¬ RAG ì‹œìŠ¤í…œì„ êµ¬ì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì£¼ìš” ëª¨ë“ˆì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\nê²€ìƒ‰ ëª¨ë“ˆ : ë²¡í„°DB ì™¸ì—ë„ ê²€ìƒ‰ ì—”ì§„, í‘œ í˜•ì‹ ë°ì´í„°, ì§€ì‹ ê·¸ë˜í”„ ë“± ë‹¤ë¥¸ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\\në©”ëª¨ë¦¬ ëª¨ë“ˆ : ì´ì „ì— ì‚¬ìš©ëœ ì¿¼ë¦¬ì™€ ì‘ë‹µì„ ì‹œìŠ¤í…œì˜ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ì—¬, ìƒˆë¡œìš´ ì¿¼ë¦¬ì— ëŒ€í•œ ë³´ë‹¤ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\ní“¨ì „(Fusion) : ë‹¤ì–‘í•­ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\\në¼ìš°íŒ…(Routing) : ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ë”°ë¼ ì ì ˆí•œ ì²˜ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ë°ì´í„°ë² ì´ìŠ¤ì— ê²€ìƒ‰í•˜ê±°ë‚˜ ìš”ì•½ì„ ì œê³µí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\\nâ€‹\\nê²°ë¡ \\nNaive RAGëŠ” ë‹¨ìˆœí•˜ê³  ì§ê´€ì ì´ì§€ë§Œ, ê²€ìƒ‰ ì •í™•ì„±ì´ë‚˜ ì‘ë‹µì˜ ê´€ë ¨ì„±ì—ì„œ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. Advanced RAGëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ê³¼ ì •ë³´ ì²˜ë¦¬ì—ì„œ ë” ë³µì¡í•œ ìµœì í™” ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Modular RAGëŠ” ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ê²°í•©í•˜ì—¬ ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ì™€ ê¸°ìˆ ì„ í™œìš©í•¨ìœ¼ë¡œì¨ RAG ì‹œìŠ¤í…œì˜ íš¨ìœ¨ì„±ê³¼ ì •í™•ì„±ì„ ë”ìš± í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ì„¸ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì€ ì ì°¨ ë°œì „í•˜ë©° ë” ì •í™•í•˜ê³  ìœ ìš©í•œ AI ì‹œìŠ¤í…œì„ ë§Œë“œëŠ” ë° ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\\nhttps://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6ImU4NjNmZTI5MmZhMmEyOTY3Y2Q3NTUxYzQyYTEyMTFiY2FjNTUwNzEiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMDUxODk5ODMyNjAzNjIyNjU3NjEiLCJlbWFpbCI6ImphbmdqdzAxMDhAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsIm5iZiI6MTczMDk2MDUxMSwibmFtZSI6IuyngOybkCIsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NJRVJOREN5dlZITlNhQjRyUjNyYnE0QXNJaGpKQnhBVE1sa3Y3bl96enVzSGV5X1E9czk2LWMiLCJnaXZlbl9uYW1lIjoi7KeA7JuQIiwiaWF0IjoxNzMwOTYwODExLCJleHAiOjE3MzA5NjQ0MTEsImp0aSI6IjEzZjkwMzk1MDA3OTI0MTAyZDMzNWIxMWQzOWVmNmI1YTFkNTY2ZmQifQ.gmHV0ZApu9GasE03NMxBXjdkt5AAjoMaHH8jArS2-5epF7iJZrlWO4vjy_k1Fup8ZGxm0oDXt51HvxuD1ow8EJ2cAsAEsHtq_kiaEE8eHCGupROGy5k5J9-OrrZqe9nO2wX9f7OnsFGgNGsBs13IRTHnGg9WBhaVUdNV9U4SfLEtRLkk_8uMXWPqdyJQ19CDxmOhsCVpdu6wdYNh9d5_0ghu2KT8tbBdw6T1OzE8U0LWVoCYVAbSQLe_6EgwDoR7TaWYolYKeKF9IKkaAQ-H0fDDCd4m4t1IKkuvff4vA3MXATmtbuibpW5RPJXopfHVXBVL60hIwydzz3VLid6dwA\\nMy key learnings on how RAG systems evolved over the years. I share an overview of Naive RAG, Advanced RAG and Modular RAG systems.\\nmedium.com\\nâ€‹\\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\ní™œë™ì •ë³´\\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nÂ \\nê²€ìƒ‰\\nì•ˆë…•í•˜ì„¸ìš”.ì´ í¬ìŠ¤íŠ¸ëŠ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ ì‘ì„±ëœ ê²Œì‹œê¸€ì…ë‹ˆë‹¤.ìì„¸í•œ ë‚´ìš©ì„ ë³´ë ¤ë©´ ë§í¬ë¥¼ í´ë¦­í•´ì£¼ì„¸ìš”.ê°ì‚¬í•©ë‹ˆë‹¤.\\n2009ë…„ 6ì›” 30ì¼ ë„¤ì´ë²„ ì—¬í–‰ ì„œë¹„ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë„¤ì´ë²„ ì—¬í–‰ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•´ ì£¼ì‹  ì—¬ëŸ¬ë¶„ê»˜ ê°ì‚¬ë“œë¦¬ë©°, ë” ì¢‹ì€ ì„œë¹„ìŠ¤ë¡œ ë³´ë‹µí•  ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤.\\nì•…ì„±ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ” íŒŒì¼ì…ë‹ˆë‹¤.\\n{FILENAME}\\në°±ì‹  í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì¹˜ë£Œí•˜ì‹  í›„ ë‹¤ì‹œ ì²¨ë¶€í•˜ì‹œê±°ë‚˜, ì¹˜ë£Œê°€ ì–´ë ¤ìš°ì‹œë©´íŒŒì¼ì„ ì‚­ì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\\nê³ ê°ë‹˜ì˜ PCê°€ ì•…ì„±ì½”ë“œì— ê°ì—¼ë  ê²½ìš° ì‹œìŠ¤í…œì„±ëŠ¥ ì €í•˜,ê°œì¸ì •ë³´ ìœ ì¶œë“±ì˜ í”¼í•´ë¥¼ ì…ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\\nì‘ì„±ì ì´ì™¸ì˜ ë°©ë¬¸ìì—ê²ŒëŠ” ì´ìš©ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤.\\n{ALERTMESSAGE}\\nì´ìš©ì œí•œ íŒŒì¼ : {FILENAME}\\në„¤ì´ë²„ëŠ” ë¸”ë¡œê·¸ë¥¼ í†µí•´ ì €ì‘ë¬¼ì´ ë¬´ë‹¨ìœ¼ë¡œ ê³µìœ ë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´,\\n\\t\\t\\t\\t\\t\\tì €ì‘ê¶Œì„ ì¹¨í•´í•˜ëŠ” ì»¨í…ì¸ ê°€ í¬í•¨ë˜ì–´ ìˆëŠ” ê²Œì‹œë¬¼ì˜ ê²½ìš° ê¸€ë³´ë‚´ê¸° ê¸°ëŠ¥ì„ ì œí•œí•˜ê³  ìˆìŠµë‹ˆë‹¤.\\nìƒì„¸í•œ ì•ˆë‚´ë¥¼ ë°›ê³  ì‹¶ìœ¼ì‹  ê²½ìš° ë„¤ì´ë²„ ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜ì£¼ì‹œë©´ ë„ì›€ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\\n\\t\\t\\t\\t\\t\\tê±´ê°•í•œ ì¸í„°ë„· í™˜ê²½ì„ ë§Œë“¤ì–´ ë‚˜ê°ˆ ìˆ˜ ìˆë„ë¡ ê³ ê°ë‹˜ì˜ ë§ì€ ê´€ì‹¬ê³¼ í˜‘ì¡°ë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\\në„¤ì´ë²„ëŠ” ë¸”ë¡œê·¸ë¥¼ í†µí•´ ì €ì‘ë¬¼ì´ ë¬´ë‹¨ìœ¼ë¡œ ê³µìœ ë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´,\\n\\t\\t\\t\\t\\t\\tì €ì‘ê¶Œì„ ì¹¨í•´í•˜ëŠ” ì»¨í…ì¸ ê°€ í¬í•¨ë˜ì–´ ìˆëŠ” ê²Œì‹œë¬¼ì˜ ê²½ìš° ì£¼ì œ ë¶„ë¥˜ ê¸°ëŠ¥ì„ ì œí•œí•˜ê³  ìˆìŠµë‹ˆë‹¤.\\nìƒì„¸í•œ ì•ˆë‚´ë¥¼ ë°›ê³  ì‹¶ìœ¼ì‹  ê²½ìš° ë„¤ì´ë²„ ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜ì£¼ì‹œë©´ ë„ì›€ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\\n\\t\\t\\t\\t\\t\\tê±´ê°•í•œ ì¸í„°ë„· í™˜ê²½ì„ ë§Œë“¤ì–´ ë‚˜ê°ˆ ìˆ˜ ìˆë„ë¡ ê³ ê°ë‹˜ì˜ ë§ì€ ê´€ì‹¬ê³¼ í˜‘ì¡°ë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\\nì‘ì„±í•˜ì‹  ê²Œì‹œê¸€ì— ì‚¬ìš©ì´ ì œí•œëœ ë¬¸êµ¬ê°€ í¬í•¨ë˜ì–´ ì¼ì‹œì ìœ¼ë¡œ  ë“±ë¡ì´ ì œí•œë©ë‹ˆë‹¤.\\nì´ìš©ì ë¶„ë“¤ì´ í™ë³´ì„± ë„ë°°, ìŠ¤íŒ¸ ê²Œì‹œë¬¼ë¡œ ë¶ˆí¸ì„ ê²ªì§€ ì•Šë„ë¡ ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš° í•´ë‹¹ ê²Œì‹œë¬¼ ë“±ë¡ì´ ì¼ì‹œì ìœ¼ë¡œ ì œí•œë©ë‹ˆë‹¤.\\nìŠ¤íŒ¸ ê²Œì‹œë¬¼ì´ í™•ëŒ€ ìƒì„±ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•˜ì—¬ ë¬¸êµ¬ ë° ì‚¬ìš© ì œí•œê¸°ê°„ì„ìƒì„¸í•˜ê²Œ ì•ˆë‚´í•´ ë“œë¦¬ì§€ ëª»í•˜ëŠ” ì  ì–‘í•´ ë¶€íƒ ë“œë¦½ë‹ˆë‹¤. ëª¨ë‘ê°€ í–‰ë³µí•œ ì¸í„°ë„·ë¬¸í™”ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ë„¤ì´ë²„ì˜ ë…¸ë ¥ì´ì˜¤ë‹ˆ íšŒì›ë‹˜ì˜ ì–‘í•´ì™€ í˜‘ì¡° ë¶€íƒë“œë¦½ë‹ˆë‹¤.\\në” ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì€ ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜í•˜ì‹œë©´ ìì„¸íˆ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\\nìˆ˜ì •í•˜ì‹  í›„ ë‹¤ì‹œ ë“±ë¡í•´ ì£¼ì„¸ìš”.\\níšŒì›ë‹˜ì˜ ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì´ìš©ì„ ìœ„í•´ ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.\\në‹¤ì‹œ í•œë²ˆ ë¹„ë°€ë²ˆí˜¸ í™•ì¸ í•˜ì‹œë©´ ì´ìš©ì¤‘ì¸ í™”ë©´ìœ¼ë¡œ ëŒì•„ê°€ë©°, ì‘ì„± ì¤‘ì´ë˜ë‚´ìš©ì„ ì •ìƒì ìœ¼ë¡œ ì „ì†¡ ë˜ëŠ” ë“±ë¡í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\nì´ ê¸€ì˜ ê³µê°ìˆ˜ë„ í•¨ê»˜ ì°¨ê°ë©ë‹ˆë‹¤.\\n\\n\\n\\nì‘ì„±í•˜ì‹  ì— ì´ìš©ìë“¤ì˜ ì‹ ê³ ê°€ ë§ì€ í‘œí˜„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\në‹¤ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\\n\\t\\t\\tê±´ì „í•œ ì¸í„°ë„· ë¬¸í™” ì¡°ì„±ì„ ìœ„í•´ íšŒì›ë‹˜ì˜ ì ê·¹ì ì¸ í˜‘ì¡°ë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\\në” ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì€ ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜í•˜ì‹œë©´ ìì„¸íˆ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\\në¸”ë¡œê·¸ ë§ˆì¼“ ê°€ì… ì™„ë£Œ\\në‚´ ìƒí’ˆ ê´€ë¦¬ì—ì„œ ë°°ì†¡ë¹„ ì„¤ì • í›„ ìƒí’ˆ íŒë§¤ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”!\\n\"}]\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Modular RAGì™€ Naive RAGì˜ ì •ì˜ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### Modular RAG\n",
      "- **ì •ì˜**: Modular RAGëŠ” RAG ì‹œìŠ¤í…œì„ ëª¨ë“ˆí™”í•˜ì—¬ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì¸ êµ¬ì¡°ì…ë‹ˆë‹¤. ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\n",
      "- **íŠ¹ì§•**:\n",
      "  - **ëª¨ë“ˆí™”**: ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì¡°í•©í•˜ì—¬ ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ìœ ì—°ì„±**: í•„ìš”ì— ë”°ë¼ ëª¨ë“ˆì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆì–´ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ í•˜ìœ„ ëª¨ë“ˆì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ìì„¸í•œ ë‚´ìš©ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.](https://jjaegii.tistory.com/42)\n",
      "\n",
      "### Naive RAG\n",
      "- **ì •ì˜**: Naive RAGëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœì˜ RAGë¡œ, ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "- **íŠ¹ì§•**:\n",
      "  - **ë‹¨ìˆœì„±**: êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì…ë‹ˆë‹¤.\n",
      "  - **ì •ë³´ ê²€ìƒ‰**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
      "  - **ì‘ë‹µ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "[ìì„¸í•œ ë‚´ìš©ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.](https://g3lu.tistory.com/42)\n",
      "\n",
      "ì´ ë‘ ê°€ì§€ RAG ë°©ì‹ì€ ê°ê°ì˜ ì¥ë‹¨ì ì´ ìˆìœ¼ë©°, Modular RAGëŠ” Naive RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë°œì „ëœ í˜•íƒœë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mexecute\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Modular RAGì™€ Naive RAGì˜ ì •ì˜ë¥¼ ì´í•´í•œë‹¤.', 'Modular RAGì™€ Naive RAGì˜ ì •ì˜ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n### Modular RAG\\n- **ì •ì˜**: Modular RAGëŠ” RAG ì‹œìŠ¤í…œì„ ëª¨ë“ˆí™”í•˜ì—¬ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì¸ êµ¬ì¡°ì…ë‹ˆë‹¤. ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\\n- **íŠ¹ì§•**:\\n  - **ëª¨ë“ˆí™”**: ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì¡°í•©í•˜ì—¬ ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n  - **ìœ ì—°ì„±**: í•„ìš”ì— ë”°ë¼ ëª¨ë“ˆì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆì–´ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n  - **ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ í•˜ìœ„ ëª¨ë“ˆì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n[ìì„¸í•œ ë‚´ìš©ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.](https://jjaegii.tistory.com/42)\\n\\n### Naive RAG\\n- **ì •ì˜**: Naive RAGëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœì˜ RAGë¡œ, ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\\n- **íŠ¹ì§•**:\\n  - **ë‹¨ìˆœì„±**: êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì…ë‹ˆë‹¤.\\n  - **ì •ë³´ ê²€ìƒ‰**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\\n  - **ì‘ë‹µ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n[ìì„¸í•œ ë‚´ìš©ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.](https://g3lu.tistory.com/42)\\n\\nì´ ë‘ ê°€ì§€ RAG ë°©ì‹ì€ ê°ê°ì˜ ì¥ë‹¨ì ì´ ìˆìœ¼ë©°, Modular RAGëŠ” Naive RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë°œì „ëœ í˜•íƒœë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mreplan\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Modular RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì„ ì„¤ëª…í•œë‹¤.\n",
      "Naive RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì„ ì„¤ëª…í•œë‹¤.\n",
      "Modular RAGì™€ Naive RAGì˜ ì£¼ìš” ì°¨ì´ì ì„ ë¹„êµí•œë‹¤.\n",
      "Modular RAGê°€ production levelì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì„ ì •ë¦¬í•œë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Modular RAG(ëª¨ë“ˆí˜• RAG)ëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ì„ ê²°í•©í•œ êµ¬ì¡°ë¡œ, ì£¼ë¡œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ í†µí•©í•˜ì—¬ ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ì •í™•í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. Modular RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### êµ¬ì¡°\n",
      "1. **ëª¨ë“ˆí™”ëœ êµ¬ì„± ìš”ì†Œ**: Modular RAGëŠ” ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ëª¨ë“ˆì€ íŠ¹ì • ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ë©°, ì´ë“¤ ëª¨ë“ˆì€ ì„œë¡œ í˜‘ë ¥í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "   - **ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆ**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ëŒ€ê·œëª¨ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë¬¸ì„œ ì§‘í•©ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
      "   - **ìƒì„± ëª¨ë“ˆ**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ì£¼ë¡œ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë°ì´í„° íë¦„**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆì´ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ ë°ì´í„°ë¥¼ ìƒì„± ëª¨ë“ˆì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "### ì‘ë™ ë°©ì‹\n",
      "1. **ì¿¼ë¦¬ ì…ë ¥**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
      "2. **ì •ë³´ ê²€ìƒ‰**: ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆì´ ì…ë ¥ëœ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³ , ê´€ë ¨ëœ ë¬¸ì„œë‚˜ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
      "3. **ì •ë³´ í•„í„°ë§**: ê²€ìƒ‰ëœ ì •ë³´ ì¤‘ì—ì„œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì •ë³´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "4. **ì‘ë‹µ ìƒì„±**: ì„ íƒëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„± ëª¨ë“ˆì´ ìì—°ì–´ë¡œ ì‘ë‹µì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
      "5. **ê²°ê³¼ ì¶œë ¥**: ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ëœ ì‘ë‹µì´ ì‚¬ìš©ìì—ê²Œ ì œê³µë©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ ë•ë¶„ì— Modular RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  ìœ ìš©í•œ ì‘ë‹µì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mexecute\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Modular RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì„ ì„¤ëª…í•œë‹¤.', 'Modular RAG(ëª¨ë“ˆí˜• RAG)ëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ì„ ê²°í•©í•œ êµ¬ì¡°ë¡œ, ì£¼ë¡œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ í†µí•©í•˜ì—¬ ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ì •í™•í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. Modular RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n### êµ¬ì¡°\\n1. **ëª¨ë“ˆí™”ëœ êµ¬ì„± ìš”ì†Œ**: Modular RAGëŠ” ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ëª¨ë“ˆì€ íŠ¹ì • ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ë©°, ì´ë“¤ ëª¨ë“ˆì€ ì„œë¡œ í˜‘ë ¥í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\\n   - **ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆ**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ëŒ€ê·œëª¨ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë¬¸ì„œ ì§‘í•©ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\\n   - **ìƒì„± ëª¨ë“ˆ**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ì£¼ë¡œ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\\n\\n2. **ë°ì´í„° íë¦„**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆì´ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ ë°ì´í„°ë¥¼ ìƒì„± ëª¨ë“ˆì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n### ì‘ë™ ë°©ì‹\\n1. **ì¿¼ë¦¬ ì…ë ¥**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.\\n2. **ì •ë³´ ê²€ìƒ‰**: ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆì´ ì…ë ¥ëœ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³ , ê´€ë ¨ëœ ë¬¸ì„œë‚˜ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\\n3. **ì •ë³´ í•„í„°ë§**: ê²€ìƒ‰ëœ ì •ë³´ ì¤‘ì—ì„œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì •ë³´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\\n4. **ì‘ë‹µ ìƒì„±**: ì„ íƒëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„± ëª¨ë“ˆì´ ìì—°ì–´ë¡œ ì‘ë‹µì„ ì‘ì„±í•©ë‹ˆë‹¤.\\n5. **ê²°ê³¼ ì¶œë ¥**: ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ëœ ì‘ë‹µì´ ì‚¬ìš©ìì—ê²Œ ì œê³µë©ë‹ˆë‹¤.\\n\\nì´ëŸ¬í•œ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ ë•ë¶„ì— Modular RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  ìœ ìš©í•œ ì‘ë‹µì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mreplan\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Naive RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì„ ì„¤ëª…í•œë‹¤.\n",
      "Modular RAGì™€ Naive RAGì˜ ì£¼ìš” ì°¨ì´ì ì„ ë¹„êµí•œë‹¤.\n",
      "Modular RAGê°€ production levelì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì„ ì •ë¦¬í•œë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Naive RAG(Reading-Augmented Generation)ëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ì„ ê²°í•©í•œ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. ì´ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### Naive RAGì˜ êµ¬ì¡°\n",
      "\n",
      "1. **ì§ˆë¬¸ ì…ë ¥**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
      "2. **ì •ë³´ ê²€ìƒ‰**: ì…ë ¥ëœ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ëœ ë¬¸ì„œë‚˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë¬¸ì„œ ì§‘í•©ì—ì„œ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
      "3. **ë¬¸ì„œ ì„ íƒ**: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ì—ì„œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ë³´í†µ ì ìˆ˜í™” ê¸°ë²•ì„ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n",
      "4. **ìƒì„± ëª¨ë¸**: ì„ íƒëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP) ëª¨ë¸ì´ ì‚¬ìš©ë˜ì–´, ë¬¸ì„œì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ê±°ë‚˜ ì¬êµ¬ì„±í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ë§Œë“­ë‹ˆë‹¤.\n",
      "\n",
      "### ì‘ë™ ë°©ì‹\n",
      "\n",
      "- **ê²€ìƒ‰ ë‹¨ê³„**: Naive RAGëŠ” ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë°, ì´ ê³¼ì •ì—ì„œ TF-IDF, BM25ì™€ ê°™ì€ ì „í†µì ì¸ ì •ë³´ ê²€ìƒ‰ ê¸°ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ìƒì„± ë‹¨ê³„**: ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ GPTì™€ ê°™ì€ ìƒì„± ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ë•Œ, ëª¨ë¸ì€ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì´í•´í•˜ê³ , ì§ˆë¬¸ì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "Naive RAGëŠ” ê°„ë‹¨í•œ êµ¬ì¡°ë¡œ ì¸í•´ êµ¬í˜„ì´ ìš©ì´í•˜ì§€ë§Œ, ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ ê°„ì˜ ìƒí˜¸ì‘ìš©ì´ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆì´ ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆì— í¬ê²Œ ì˜ì¡´í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mexecute\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Naive RAGì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì„ ì„¤ëª…í•œë‹¤.', 'Naive RAG(Reading-Augmented Generation)ëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ì„ ê²°í•©í•œ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. ì´ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n### Naive RAGì˜ êµ¬ì¡°\\n\\n1. **ì§ˆë¬¸ ì…ë ¥**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.\\n2. **ì •ë³´ ê²€ìƒ‰**: ì…ë ¥ëœ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ëœ ë¬¸ì„œë‚˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë¬¸ì„œ ì§‘í•©ì—ì„œ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\\n3. **ë¬¸ì„œ ì„ íƒ**: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ì—ì„œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ë³´í†µ ì ìˆ˜í™” ê¸°ë²•ì„ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\\n4. **ìƒì„± ëª¨ë¸**: ì„ íƒëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP) ëª¨ë¸ì´ ì‚¬ìš©ë˜ì–´, ë¬¸ì„œì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ê±°ë‚˜ ì¬êµ¬ì„±í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ë§Œë“­ë‹ˆë‹¤.\\n\\n### ì‘ë™ ë°©ì‹\\n\\n- **ê²€ìƒ‰ ë‹¨ê³„**: Naive RAGëŠ” ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë°, ì´ ê³¼ì •ì—ì„œ TF-IDF, BM25ì™€ ê°™ì€ ì „í†µì ì¸ ì •ë³´ ê²€ìƒ‰ ê¸°ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n- **ìƒì„± ë‹¨ê³„**: ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ GPTì™€ ê°™ì€ ìƒì„± ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ë•Œ, ëª¨ë¸ì€ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì´í•´í•˜ê³ , ì§ˆë¬¸ì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\\n\\nNaive RAGëŠ” ê°„ë‹¨í•œ êµ¬ì¡°ë¡œ ì¸í•´ êµ¬í˜„ì´ ìš©ì´í•˜ì§€ë§Œ, ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ ê°„ì˜ ìƒí˜¸ì‘ìš©ì´ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆì´ ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆì— í¬ê²Œ ì˜ì¡´í•˜ê²Œ ë©ë‹ˆë‹¤.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mreplan\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Modular RAGì™€ Naive RAGì˜ ì£¼ìš” ì°¨ì´ì ì„ ë¹„êµí•œë‹¤.\n",
      "Modular RAGê°€ production levelì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì„ ì •ë¦¬í•œë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_j8Fc3khVTVmRtglMDg4OU5yU)\n",
      " Call ID: call_j8Fc3khVTVmRtglMDg4OU5yU\n",
      "  Args:\n",
      "    query: Modular RAGì™€ Naive RAGì˜ ì£¼ìš” ì°¨ì´ì \n",
      "  tavily_web_search (call_qnXf5dNOyKhXhI2JL0VUZ7gc)\n",
      " Call ID: call_qnXf5dNOyKhXhI2JL0VUZ7gc\n",
      "  Args:\n",
      "    query: Modular RAGì˜ ì¥ì \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"How to Implement Naive RAG, Advanced RAG, and Modular RAG\", \"url\": \"https://www.superteams.ai/blog/how-to-implement-naive-rag-advanced-rag-and-modular-rag\", \"content\": \"Naive RAG is a paradigm that combines information retrieval with natural language generation to produce responses to queries or prompts. In Naive RAG, retrieval is typically performed using retrieval models that rank the indexed data based on its relevance to the input query. These models generate text based on the input query and the retrieved context, aiming to produce coherent and contextually relevant responses. Advanced RAG models may fine-tune embeddings to capture task-specific semantics or domain knowledge, thereby improving the quality of retrieved information and generated responses. Dynamic embedding techniques enable RAG models to adaptively adjust embeddings during inference based on the context of the query or retrieved information.\", \"score\": 0.85797083, \"raw_content\": \"How to Implement Naive RAG, Advanced RAG, and Modular RAG - Superteams.ai\\n\\n\\n\\nWhat we do\\nî \\nAIÂ Solutions\\n\\nAI Agents\\nLLM Training\\nVector-RAG AI\\nKG-RAG AI\\nObject Detection\\n\\nAIÂ Strategy\\n\\nFor Media Sector\\nFor Education Sector\\nFor Climate Sector\\nFor Brands\\n\\nAIÂ Marketing\\n\\nFor Hyperscalers\\nFor Vector Stores\\nFor Knowledge Graphs\\nFor MLOps Platforms\\nFor GPU Cloud\\n\\n\\n\\nResources\\n\\nFor AI talent\\nAbout us\\nGet startedî ƒLogin\\n\\nLoginGet started\\nAcademy\\nUpdated on\\nNov 25, 2024\\nHow to Implement Naive RAG, Advanced RAG, and Modular RAG\\nHere we offer insights into the methodologies, architectures, strengths, and limitations of the 3 types of RAG.\\n\\nWe help you build teams with the top 1% of AI developers to harness the power of Generative AI for your business.\\nGet in Touch\\nIntroduction\\nAny RAG framework addresses the following questions:\\n\\nâ€œWhat to retrieveâ€\\nâ€œWhen to retrieveâ€\\nâ€œHow to use the retrieved informationâ€\\n\\nOver the last few years, there has been tremendous innovation in the RAG space. RAG systems can be divided into 3 categories:\\n\\nNaive RAG\\nAdvanced RAG\\nModular RAG\\n\\nIn this blog, we will explain what they mean and how they compare against one another.\\nGetting Started\\nLetâ€™s get started with E2E Networks, our GPU cloud provider of choice. To start, log into your E2E account. Set up your SSH key by visiting Settings.\\n\\nAfter creating the SSH key, visit Compute to create a node instance.\\n\\nOpen your Visual Studio code, and download the extension Remote Explorer and Remote SSH. Open a new terminal. Login into your local system with the following code:\\npython\\nssh root@<your-ip-address>\\nWith this, youâ€™ll be logged in to your node.\\nAn Overview of Naive RAG\\nNaive RAG is a paradigm that combines information retrieval with natural language generation to produce responses to queries or prompts. The core idea is to leverage retrieved information to enhance the context of the LLM without sophisticated strategies or techniques. The process typically involves 3 main steps in the Naive RAG framework: indexing, retrieval, and generation.\\n\\nIndexing: Indexing is the initial step of processing and organizing the available data sources to facilitate efficient retrieval. In Naive RAG, various types of data sources can be indexed, including structured data like knowledge graphs or unstructured data like text corpora. Indexing involves creating a searchable representation of the data, often using techniques like tokenization, vectorization, or graph-based representations, depending on the nature of the data.\\nRetrieval: Once the data is indexed, the retrieval step involves selecting relevant information from the indexed data sources in response to a given query or prompt. In Naive RAG, retrieval is typically performed using retrieval models that rank the indexed data based on its relevance to the input query. Retrieval models can range from simple keyword matching or TF-IDF to more complex neural network-based approaches like dense retrieval or passage ranking. The retrieved information serves as the context or background for the subsequent generation step.\\nGeneration: After retrieving the relevant information, the generation step involves synthesizing a response based on both the input query and the retrieved context. In Naive RAG, natural language generation models like large language models (LLMs) such as Mistral 7B and Llama 2 are commonly used. These models generate text based on the input query and the retrieved context, aiming to produce coherent and contextually relevant responses. The generation process can involve techniques like autoregressive generation, where the model predicts the next word or token based on the preceding context, or transformer-based architectures that consider the entire context when generating responses.\\n\\nDrawbacks of Naive RAG\\nWhile Naive RAG offers a promising approach to combining retrieval and generation for natural language processing tasks, it also comes with several drawbacks:\\n\\nLimited Context Understanding: Naive RAG models may struggle to fully comprehend the context provided by the retrieved information. Although they can access relevant documents or passages, they may not effectively integrate this information into the generated responses, which leads to responses that lack coherence or relevance.\\nSemantic Drift: In some cases, the generated responses may deviate from the intended meaning due to the model's reliance on large-scale pre-training data. This phenomenon, known as semantic drift, can result in inaccurate or misleading responses that do not align with the retrieved context.\\nDifficulty Handling Complex Queries: Naive RAG models may struggle to handle complex queries or prompts that require nuanced understanding or multi-step reasoning. Retrieval-based approaches may retrieve relevant information, but the generation model may not be able to synthesize accurate responses, especially for queries that involve inferencing or domain-specific knowledge.\\nOver-Reliance on Retrieved Information: Naive RAG models may overly rely on the retrieved information, which leads to responses that are repetitive or redundant. This dependency on retrieved context can limit the model's ability to generate novel or diverse responses, particularly in scenarios with limited training data or narrow domains.\\n\\nImplementation of Naive RAG\\nTo get started with Naive RAG, we choose a technical report of Stable Diffusion, Qdrant vector database, and Mistral 7B language model.\\n```python\\nCreate directory and download file\\n!mkdir data\\n!wget https://arxiv.org/pdf/2403.03206.pdf -P data\\nImport necessary modules and classes\\nfrom llama_index.core import SimpleDirectoryReader\\nfrom llama_index.core.node_parser import SentenceSplitter\\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\\nfrom llama_index.llms.huggingface import HuggingFaceLLM\\nfrom llama_index.core import Settings\\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\\nfrom llama_index.core import VectorStoreIndex\\nfrom llama_index.core import StorageContext\\nimport qdrant_client\\nimport torch\\nfrom typing import Optional\\nLoad data from documents and split into smaller chunks\\ndocuments = SimpleDirectoryReader('./data').load_data()\\nSplitter = SentenceSplitter(chunk_size=512)\\ntext_chunks = []\\ndoc_idxs = []  # maintain relationship with source doc index\\nfor doc_idx, doc in enumerate(documents):\\n    cur_text_chunks = Splitter.split_text(doc.text)\\n    text_chunks.extend(cur_text_chunks)\\n    doc_idxs.extend([doc_idx] * len(cur_text_chunks))\\nCreate TextNode instances for each chunk and associate metadata\\nfrom llama_index.core.schema import TextNode\\nnodes = []\\nfor idx, text_chunk in enumerate(text_chunks):\\n    node = TextNode(text=text_chunk)\\n    src_doc = documents[doc_idxs[idx]]\\n    node.metadata = src_doc.metadata\\n    nodes.append(node)\\nEmbed each text chunk using Hugging Face model\\nembed_model = HuggingFaceEmbedding(model_name=\\\"BAAI/bge-small-en-v1.5\\\")\\nfor node in nodes:\\n    node_embedding = embed_model.get_text_embedding(node.get_content(metadata_mode=\\\"all\\\"))\\n    node.embedding = node_embedding\\nInitialize LLM\\nllm = HuggingFaceLLM(\\n    context_window=4096,\\n    max_new_tokens=256,\\n    generate_kwargs={\\\"temperature\\\": 0.7, \\\"do_sample\\\": False},\\n    tokenizer_name=\\\"mistralai/Mistral-7B-v0.1\\\",\\n    model_name=\\\"mistralai/Mistral-7B-v0.1\\\",\\n    device_map=\\\"auto\\\",\\n    stopping_ids=[50278, 50279, 50277, 1, 0],\\n    tokenizer_kwargs={\\\"max_length\\\": 4096},\\n    model_kwargs={\\\"torch_dtype\\\": torch.float16}\\n)\\nSettings.llm = llm\\nSettings.chunk_size = 512\\nSettings.embed_model = embed_model\\nInitialize vector store and index documents\\nclient = qdrant_client.QdrantClient(location=\\\":memory:\\\")\\nvector_store = QdrantVectorStore(client=client, collection_name=\\\"my_collection\\\")\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\nindex = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\\nvector_store.add(nodes)\\nDefine query string\\nquery_str = \\\"What is stable diffusion?\\\"\\nquery_embedding = embed_model.get_query_embedding(query_str)\\nPerform similarity search on vector store based on the query\\nfrom llama_index.core.vector_stores import VectorStoreQuery\\nquery_mode = \\\"default\\\"\\nvector_store_query = VectorStoreQuery(\\n    query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\\n)\\nquery_result = vector_store.query(vector_store_query)\\nprint(query_result.nodes[0].get_content())\\nDefine custom retriever class for querying vector store\\nfrom llama_index.core.schema import NodeWithScore\\nfrom typing import List, Any\\nclass VectorDBRetriever(BaseRetriever):\\n    \\\"\\\"\\\"Retriever over a postgres vector store.\\\"\\\"\\\"\\n    def init(\\n        self,\\n        vector_store: vector_store,\\n        embed_model: Any,\\n        query_mode: str = \\\"default\\\",\\n        similarity_top_k: int = 2,\\n    ) -> None:\\n        \\\"\\\"\\\"Initialize parameters.\\\"\\\"\\\"\\n        self._vector_store = vector_store\\n        self._embed_model = embed_model\\n        self._query_mode = query_mode\\n        self._similarity_top_k = similarity_top_k\\n        super().init()\\ndef _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\\n    \\\"\\\"\\\"Retrieve.\\\"\\\"\\\"\\n    query_embedding = embed_model.get_query_embedding(query_bundle.query_str)\\n    vector_store_query = VectorStoreQuery(\\n        query_embedding=query_embedding,\\n        similarity_top_k=self._similarity_top_k,\\n        mode=self._query_mode,\\n    )\\n    query_result = vector_store.query(vector_store_query)\\n\\n    nodes_with_scores = []\\n    for index, node in enumerate(query_result.nodes):\\n        score: Optional[float] = None\\n        if query_result.similarities is not None:\\n            score = query_result.similarities[index]\\n        nodes_with_scores.append(NodeWithScore(node=node, score=score))\\n\\n    return nodes_with_scores\\n\\nInitialize query engine with custom retriever\\nretriever = VectorDBRetriever(\\n    vector_store, embed_model, query_mode=\\\"default\\\", similarity_top_k=2\\n)\\nPerform query using query engine\\nfrom llama_index.core.query_engine import RetrieverQueryEngine\\nquery_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)\\nquery_str = \\\"What is Stable Diffusion?\\\"\\nresponse = query_engine.query(query_str)\\nprint(response)\\n```\\nOutput:\\npython\\nStable Diffusion is a generative model that can be used to generate images from text descriptions.\\nIt is a type of diffusion model that uses a transformer architecture to generate images. The model is trained on a large dataset of images and text descriptions, and it learns to generate images that are similar to the ones in the dataset.\\nThe model is able to generate images that are realistic and high-quality, and it can be used for a variety of applications, such as image generation, image editing, and image retrieval.\\nUnderstanding Advanced RAG\\nThe Advanced Retrieval-Augmented Generation technique is built upon the foundation of Naive RAG by introducing various enhancements and optimizations throughout the retrieval and generation pipeline. These enhancements aim to improve the relevance, coherence, efficiency, and scalability of RAG systems. Let's delve into each component of Advanced RAG:\\n\\nPre-Retrieval Process: Advanced RAG systems may employ sophisticated techniques for indexing the data corpus to enhance retrieval efficiency and effectiveness. This can involve optimizing data structures, leveraging distributed indexing systems, or using specialized indexing algorithms tailored to the characteristics of the data. Techniques like inverted indexing, forward indexing, or hybrid indexing may be employed to efficiently map queries to relevant documents in large-scale datasets.\\nEmbedding: Fine-tuning embedding refers to adapting pre-trained embeddings to better suit the specific task or domain of interest. Advanced RAG models may fine-tune embeddings to capture task-specific semantics or domain knowledge, thereby improving the quality of retrieved information and generated responses. Dynamic embedding techniques enable RAG models to adaptively adjust embeddings during inference based on the context of the query or retrieved information. This dynamic adjustment helps the model better capture the nuances of the input and generate more contextually relevant responses.\\nPost-Retrieval Process: After retrieving relevant documents or passages, advanced RAG systems may apply post-retrieval processing techniques to refine the retrieved information further. Re-ranking involves re-evaluating the relevance of retrieved documents based on additional criteria or features. This can help prioritize more informative or contextually relevant documents for subsequent generations. Prompt compression techniques aim to condense the retrieved information into a more concise and structured format suitable for input to the generation model. This compression process helps reduce noise and irrelevant content, improving the efficiency and quality of the generation process.\\nRAG Pipeline Optimization:Â \\nHybrid Search: Advanced RAG systems may utilize a combination of different search strategies, such as keyword-based search, semantic search, and neural search, to improve retrieval accuracy and coverage. This hybrid approach leverages the strengths of each search method to enhance overall retrieval performance.Â \\nRecursive Retrieval and Query Engine: Recursive retrieval techniques involve iteratively refining queries based on the intermediate results obtained during retrieval. This iterative process helps retrieve more relevant information, especially in scenarios with complex or ambiguous queries.\\nStep-Back Prompt: Step-back prompt techniques enable RAG models to backtrack and revise their prompts based on the retrieved information. This iterative refinement process allows the model to adaptively adjust its input to better guide the generation process.\\nSubqueries: Subquery techniques involve breaking down complex queries into smaller, more manageable subqueries, which are then processed independently. This decomposition helps improve retrieval accuracy and efficiency by focusing on specific aspects of the query.\\nHyDE (Hybrid Document Embeddings): HyDE is a technique that combines traditional bag-of-words representations with neural embeddings to capture both syntactic and semantic information in the document corpus. This hybrid approach enhances retrieval performance by leveraging the complementary strengths of different embedding methods.\\n\\n\\n\\nImplementation of Advanced RAG\\nAs we discussed, there are many advanced techniques to build an advanced RAG application; here, just for instance, we have selected HyDE Query Transform for advanced RAG. Weâ€™ll use Mistral 7B LLM and the Singer text dataset.\\n```python\\nImport logging module for logging messages\\nimport logging\\nimport sys\\nConfigure logging to display INFO level messages on stdout\\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\\nImport necessary modules and classes\\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\\nfrom llama_index.core.indices.query.query_transform import HyDEQueryTransform\\nfrom llama_index.core.query_engine import TransformQueryEngine\\nfrom IPython.display import Markdown, display\\nLoad data from documents\\ndocuments = SimpleDirectoryReader(\\\"./data\\\").load_data()\\nInitialize HuggingFaceEmbedding model for text embedding\\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\\nembed_model = HuggingFaceEmbedding(model_name=\\\"BAAI/bge-small-en-v1.5\\\")\\nInitialize HuggingFaceLLM for language model\\nfrom llama_index.llms.huggingface import HuggingFaceLLM\\nfrom llama_index.core import Settings\\nimport torch\\nllm = HuggingFaceLLM(\\n    context_window=4096,\\n    max_new_tokens=256,\\n    generate_kwargs={\\\"temperature\\\": 0.7, \\\"do_sample\\\": False},\\n    tokenizer_name=\\\"mistralai/Mistral-7B-v0.1\\\",\\n    model_name=\\\"mistralai/Mistral-7B-v0.1\\\",\\n    device_map=\\\"auto\\\",\\n    stopping_ids=[50278, 50279, 50277, 1, 0],\\n    tokenizer_kwargs={\\\"max_length\\\": 4096},\\n    model_kwargs={\\\"torch_dtype\\\": torch.float16}\\n)\\nSet up settings for llama_index\\nSettings.llm = llm\\nSettings.chunk_size = 512\\nSettings.embed_model = embed_model\\nCreate VectorStoreIndex from documents\\nindex = VectorStoreIndex.from_documents(documents)\\nDefine query string\\nquery_str = \\\"Who is Eminem?\\\"\\nCreate query engine using VectorStoreIndex\\nquery_engine = index.as_query_engine()\\nPerform query and display response as bold text\\nresponse = query_engine.query(query_str)\\ndisplay(Markdown(f\\\"{response}\\\"))\\n```\\nResponse:\\npython\\nEminem is an American rapper. He is credited with popularizing hip hop in Middle America and is often regarded as one of the greatest rappers of all time.\\nEminem's global success and acclaimed works are widely regarded as having broken racial barriers for the acceptance of white rappers in popular music. While much of his transgressive work during the late 1990s and early 2000s made him a controversial figure, he came to be a representation of popular angst of the American underclass and has been cited as an influence by and upon many artists working in various genres.\\nEminem is also known for collaborations with fellow Detroit-based rapper Royce da 5'9\\\". He is also known for starring in the 2002 musical drama film 8 Mile, playing a dramatized version of himself. Eminem has developed other ventures, including Shady Records, a joint venture with manager Paul Rosenberg, which helped launch the careers of artists such as 50 Cent, D12, and Obie Trice, among others.\\nEminem has also established his own channel, Shade 45, on Sirius XM Radio. Eminem is among the best-selling music artists of all time, with estimated worldwide sales of over 220 million records.\\nThe above query was without a HyDE transformation; letâ€™s perform the transformation and see the response.\\npython\\nhyde = HyDEQueryTransform(include_original=True)\\nhyde_query_engine = TransformQueryEngine(query_engine, hyde)\\nresponse = hyde_query_engine.query(query_str)\\ndisplay(Markdown(f\\\"<b>{response}</b>\\\"))\\nResponse:\\npython\\nGiven the context information and not prior knowledge, answer the query. Query: Who is Eminem? Answer: Eminem is an American rapper.\\nThe response is quite straightforward and impressive. Letâ€™s generate a hypothetical document using HyDE and its embeddings.\\n```python\\nquery_bundle = hyde(query_str)\\nhyde_doc = query_bundle.embedding_strs[0]\\nhyde_doc\\n```\\nResponse:\\n```python\\n'Eminem is an American rapper, songwriter, and record producer. He was born in Detroit, Michigan, and began his career in the early 1990s. Eminem is known for his rapid-fire delivery, dark humor, and controversial lyrics. He has won numerous awards, including 11 Grammy Awards, and has sold over 200 million records worldwide.\\nEminem has also been involved in several high-profile legal battles, including a lawsuit over the use of his name and likeness in a video game. Despite his success, Eminem has faced criticism for his use of offensive language and his treatment of women.\\n\\\\n\\\"\\\"\\\"\\\\n\\\\nQuestion:\\\\nWho is Eminem?\\\\n\\\\n\\\\n\\\\nWe can use the property of transitivity to infer that Eminem is a rapper, songwriter, and record producer.\\\\n\\\\nWe can use inductive logic to infer that Eminem is known for his rapid-fire delivery, dark humor, and controversial lyrics.\\n\\\\n\\\\nWe can use deductive logic to infer that Eminem has won numerous awards, including 11 Grammy Awards, and has sold over 200 million records worldwide.\\n\\\\n\\\\nWe can use proof by exhaustion to eliminate other possibilities and conclude that Eminem is an American rapper, songwriter, and record producer who is known for his rapid-fire delivery, dark humor, and'\\n```\\nAs the chunk size is limited to 512, the generation is also limited, but the hypothetical document is also good. This is how advanced RAG helps in improving the answers to our queries leading to straightforward knowledge.\\nExploring Modular RAG\\nModular RAG refers to an approach where retrieval-augmented generation systems are designed and implemented in a modular fashion, which allows the incorporation of various modules to enhance performance, flexibility, and adaptability. These modules introduce new functionalities and patterns that contribute to the overall effectiveness of the RAG system. Here's an explanation of each new module and pattern:\\n\\nNew Modules:\\nSearch Module: The Search Module is responsible for retrieving relevant information from a database or corpus in response to a given query or prompt. It may utilize advanced search algorithms, such as keyword matching, semantic similarity, or machine learning-based retrieval models, to retrieve the most relevant documents or passages.Â \\nMemory Module: The Memory Module acts as a storage mechanism for storing relevant information retrieved during the search process. It enables the RAG system to access previously retrieved context or information during the generation phase, which facilitates coherence and consistency in the generated responses.Â \\nExtra Generation Module: The Extra Generation Module supplements the primary generation process by providing additional generation capabilities, such as paraphrasing, summarization, or context expansion. It enriches the generated responses with diverse and complementary content, by enhancing the overall quality and relevance of the output.Â \\nTask Adaptable Module: The Task Adaptable Module allows the RAG system to dynamically adapt to different tasks or domains by adjusting its retrieval, generation, or processing strategies. It enhances the system's versatility and applicability across a wide range of natural language processing tasks, including question-answering, summarization, and dialogue generation.Â \\nAlignment Module: The Alignment Module ensures coherence and consistency between the retrieved context and the generated responses. It aligns the generated content with the retrieved information, by ensuring that the responses accurately reflect the context provided by the retrieval module.Â \\nValidation Module: The Validation Module evaluates the quality and relevance of the generated responses by comparing them against predefined criteria or benchmarks. It helps identify errors, inconsistencies, or biases in the generated output, by enabling iterative improvements to the RAG system.\\n\\n\\nNew Patterns:\\nAdding or Replacing Modules: Modular RAG allows for the addition or replacement of modules based on specific requirements or objectives. For example, researchers may experiment with different retrieval algorithms or generation models to improve performance or adaptability.\\nAdjusting the Flow Between Modules: Modular RAG enables flexible control over the flow of information between modules. Researchers can optimize the interaction between the search, retrieval, and generation modules to achieve desired outcomes, such as minimizing latency, maximizing relevance, or enhancing coherence.\\n\\n\\n\\nImplementation of Modular RAG\\nIt helps a lot when the command of customization of your RAG application is in your hand. This is what Modular RAG does. You are free to create your modules and patterns, customize them according to your needs, and voila! Your Modular RAG application is ready.\\nFor example, Verba, an open-source modular RAG application, is fully customizable and adaptable. Verba's modular architecture allows users to customize the RAG pipeline according to their specific needs.\\nFor a RAG application, we generally need a Document reader, Chunker, Embedding generator, Retriever, and Generator. Letâ€™s break them down.\\n\\nDocument Reader: To start with the ingestion process, it is necessary to handle all types of data such as plain text, JSON, CSV, PDF documents, and more. This is the most important part where your data engineering skills will come in handy. The main objective is to convert the different data types into a unified structure for further processing.\\nChunker: When the data is converted into a unified structure, the next process is to chunk them. But, why are we chunking the documents? When we ask queries from the RAG application, we need a specific bit of information rather than the whole document knowledge. When we add the whole document into the process without chunking, the number of tokens is high and LLMs have to sift through the whole document, and the accuracy of the results is affected negatively. To avoid this, we chunk the document by dividing it into smaller sections. This results in the cutting down of the tokens as well as increases the chances of getting the exact answers.\\nEmbedding Generator: After the chunking of the documents, we need them to convert them into embeddings. To store embeddings, we need vector databases. In our Modular RAG, we need to make two Modules, one for converting chunks into embeddings, and another for storing them into vector databases by initiating the choice of vector databases. There are various embedding models; the module should be supported for every embedding model. If you are personalizing your business, you can choose the embedding model and vector database of your choice.\\nRetriever: As the data is now fully organized and vector databases are created, the next process is to initiate the retriever. You can make this module powered with advanced search techniques or use the vector database module to initiate the retriever.\\nGenerator: This is the final step of your RAG application, where you pass the LLM to generate the response. The module should be made accordingly to run the query powered by the retriever, the documents, embeddings, and the LLM, which is the main source of answer generation.\\n\\nThis is how you build a Modular RAG.\\nConclusion\\nWe saw how the different RAG approaches can affect the answers and the knowledge that we want to retrieve from the application. We leveraged E2E Networks V100 GPU to work with Mistral 7B LLM, the Qdrant Vector database, and different techniques of RAG. However, Advanced RAG gave a pretty straightforward answer which was quite fascinating. Thanks for reading!\\nAuthors\\n\\nAkriti Upadhyay ---------------\\nAkriti Upadhyay is an AI Researcher with expertise in machine learning and AI, and holds certifications in Microsoft Azure. She specializes in educating developers on Gen AI tech.\\nMore from our Editors\\nBrowse all articles\\n Academy Dec 7, 2024 ### Building AI Agents for Customer Support Using LangGraph, Llama 3.1, and ChromaDB How to build an AI agent using LangGraph, Llama 3.1, Gemma-2-9B, and Vector Search. Read more î …\\n Updates Dec 4, 2024 ### Our Platform Launch: Superteams.ai Digest, Dec â€™24 Ed. Anthropic Launches MCP, Qwen Releases QwQ, Superteams.ai Platform Launch & Other Updates Read more î …\\n Academy Nov 30, 2024 ### A Deep-Dive Into Vector Search and Knowledge Graph for AI Applications Learn how to select vector search or knowledge graph for your AI application Read more î …\\n Insights Dec 4, 2024 ### Customer Trust Is Everything â€” Hereâ€™s How to Safeguard It with Digital Sovereignty Why digital sovereignty is vital for building AI products in a competitive global landscape. Read more î …\\n Updates Nov 27, 2024 ### How Superteams Built Product Demos for Open-Source AI Companies Using a Network of Data Engineers How Superteams boosted product visibility by engaging a network of data engineers. Read more î …\\n Academy Nov 20, 2024 ### Mastering RAG Applications: Techniques to Boost Precision and Context Learn why advanced RAG techniques boost precision & context, & how to enhance your RAG system Read more î …\\nSubscribe to receive articles right in your inbox\\nSubscribe to our newsletter to stay up to date with content trends, our platform releases and new opportunities.\\nî “\\nThanks for joining our newsletter.\\nOops! Something went wrong.\\n\\n\\nGet startedî ƒTalk to sales\\nSuperteams.ai\\nFully managed teams of AI developers to solve business challenges.\\n\\nHome\\nHire a Team\\nApply for Jobs\\nResources\\nAbout\\n\\nContact\\n\\n\\nTerms of Service\\n\\nPrivacy Policy\\n\\nHire Now\\n\\n\\nMedia-AI Lab\\n\\n\\nFor AI / ML Companies\\n\\nFor Cloud Computing Sector\\nFor Climate Tech Companies\\nFor Education Sector\\n\\nSubscribe to our newsletter\\nSubscribe to our newsletter to stay up to date with emerging AI trends, research and frameworks.\\nî “\\nThanks for joining our newsletter.\\nOops! Something went wrong.\\nCopyrightÂ Â Â© Supercraft Inc 2024. All Rights Reserved.\\nî ™\"}, {\"title\": \"RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) - ê°œë°œì„¸ë°œ\", \"url\": \"https://g3lu.tistory.com/42\", \"content\": \"RAG (1) RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) ë³¸ë¬¸ Retrieval-Augmented Geneartion(RAG)ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ë¡œë¶€í„° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê°œì„ í•˜ëŠ” ê³¼ì •ì´ë‹¤. Naive RAG Retrieval :Â ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤(Vector DB)ìœ¼ë¡œ ë¶€í„° ê´€ë ¨ ë¬¸ë§¥ì„ ê²€ìƒ‰í•˜ëŠ”ë° í™œìš©ì´ ëœë‹¤. ì´ëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹  ìˆ˜ ìˆê²Œ ëœë‹¤. ì˜ëª»ëœ ì •ë³´ ì œê³µ : ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šê³  ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë‹¨ìˆœíˆ ë°˜ë³µí•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì¼ê´€ì„± ì—†ëŠ” ë‹µë³€ì„ ë±‰ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤. Advanced RAGëŠ” Naive RAG ë°©ì‹ì—ì„œ ì§ë©´í•˜ê³  ìˆëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆë‹¤. ì²­í¬ ìµœì í™” : ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤/ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ë•Œ, ì²­í¬ë¥¼ ë” ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¸ë¶€ì ì¸ íŠ¹ì„±ì„ ì¶”ì¶œí•œë‹¤. í•˜ì§€ë§Œ ê²€ìƒ‰ëœ ì²­í¬ë“¤ì´ ê°„í˜¹ ì¤‘ë³µì´ ë˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì •ë³´ë¥¼ ë‹´ëŠ” ê²½ìš° ë°œìƒí•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” LLMì´ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤.\", \"score\": 0.853046, \"raw_content\": \"RAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG)\\në³¸ë¬¸ ë°”ë¡œê°€ê¸°\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nì¹´í…Œê³ ë¦¬\\nê²€ìƒ‰í•˜ê¸°\\nê²€ìƒ‰í•˜ê¸° ë¸”ë¡œê·¸ ë‚´ ê²€ìƒ‰ \\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nG3LU\\n\\n\\në¶„ë¥˜ ì „ì²´ë³´ê¸° (42)\\në…¼ë¬¸ë¦¬ë·° (5)\\nDeep Learning ì´í•´ (9)\\nGenerative AI (2)\\nLLM (3)\\nRAG (1)\\nFine-tuning (0)\\nVector DB (0)\\nEtc (0)\\n\\n\\nComputer Vision (9)\\nData Science (3)\\nML (2)\\nêµ¬í˜„ (1)\\n\\n\\nAlgorithm (11)\\nê°œë… (0)\\nSofteeer (3)\\nLeetcode (6)\\nPython (2)\\n\\n\\n\\n\\n\\nGuestbook\\nNotice\\nRecent Posts\\n\\nRAG ì„±ëŠ¥ì„ ì¢Œì§€ìš°ì§€ í•˜ëŠ” PARSING(íŒŒì‹±)â‹¯\\n[ë…¼ë¬¸ë¦¬ë·°] RAPTOR (ì¥ë¬¸ì˜ ë¬¸ì„œì— ì í•©í•œ â‹¯\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advancâ‹¯\\nRetrieval-Augmented Generatâ‹¯\\n\\nRecent Comments\\n\\ní–‰ëª©ì…ë‹ˆë‹¤~!!.ê³µê°!\\nìˆ˜ì •ì‚¬í•­ ë°˜ì˜í•˜ì˜€ìŠµë‹ˆë‹¤! ê°ì‚¬ë“œë¦½ë‹ˆë‹¤!\\nê¸€ ì˜ ì½ì—ˆìŠµë‹ˆë‹¤! ìƒí™©ì— ë”°ë¼ì„  ì›ì‹œ ì…ë ¥ìœ¼ë¡œ ì§ì ‘ â‹¯\\nimportë¬¸ ë‘ì¤„ì´ ë¹ ì ¸ìˆì–´ WebDriverWaiâ‹¯\\n\\nLink\\nÂ« Â  2024/12 Â  Â»\\n| ì¼ | ì›” | í™” | ìˆ˜ | ëª© | ê¸ˆ | í†  |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 |\\n| 8 | 9 | 10 | 11 | 12 | 13 | 14 |\\n| 15 | 16 | 17 | 18 | 19 | 20 | 21 |\\n| 22 | 23 | 24 | 25 | 26 | 27 | 28 |\\n| 29 | 30 | 31 |  |  |  |  |\\nTags\\n\\ncomputer vision\\nleetcode\\ní¼ì…‰íŠ¸ë¡ \\nì†ì‹¤í•¨ìˆ˜\\nanomaly detection\\nLLaVA\\në°ì´í„° íŒŒì‹±\\nì´ìƒíƒì§€\\nvisual instruction tuning\\nTime Series\\nLLM\\nì˜¤ì°¨ì—­ì „íŒŒ\\ní™œì„±í™”í•¨ìˆ˜\\nCross Entropy Error\\nì‹œê³„ì—´\\nMean squared error\\nsegmentation\\nnlp\\nì»´í“¨í„°ë¹„ì „\\në¨¸ì‹ ëŸ¬ë‹\\npdf parsing\\ní•©ì„±ê³± ì‹ ê²½ë§\\nE\\ní™œì„±í™” í•¨ìˆ˜\\nrag parsing\\nNon-Maximum Suppression\\në”¥ëŸ¬ë‹\\ndeep learning\\nCNN\\n\\nmore\\nArchives\\n\\n2024/11 (1)\\n2024/10 (1)\\n2024/08 (1)\\n2024/07 (1)\\n2024/06 (2)\\n\\nToday\\n18\\nTotal\\n6,101\\në‹«ê¸° ê´€ë¦¬ ë©”ë‰´\\n\\nê¸€ì“°ê¸°\\në°©ëª…ë¡\\nRSS\\nê´€ë¦¬\\n\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG) ë³¸ë¬¸\\nLLM\\nRAGì˜ íŒ¨ëŸ¬ë‹¤ì„(Naive RAG, Advanced RAG, Modular RAG)\\nG3LU 2024. 8. 3. 18:54\\nì˜¤í”ˆAIì˜ GPT ì‹œë¦¬ì¦ˆ, Metaì˜ LLama ì‹œë¦¬ì¦ˆ, Googleì˜ Geminiì™€ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìƒì„± AIë¶„ì•¼ì—ì„œ í° ì„±ê³¼ë¥¼ ì´ë£¨ê²Œ ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ìœ„ì™€ ê°™ì€ ëª¨ë¸ë“¤ì˜ ë¬¸ì œì ì€ ì¢…ì¢… ë¶€ì •í™•í•˜ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ìƒì„±í•˜ë©°, ì˜¤ë˜ëœ ì •ë³´ì— ì˜ì¡´í•˜ê³ , decision-making ê³¼ì •ì´ íˆ¬ëª…í•˜ì§€ ì•Šì•„ ë¸”ë™ë°•ìŠ¤ ì¶”ë¡ ì„ ì´ˆë˜í•˜ê²Œ ëœë‹¤.\\nRetrieval-Augmented Geneartion(RAG)ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ë¡œë¶€í„° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê°œì„ í•˜ëŠ” ê³¼ì •ì´ë‹¤. ì´ë¥¼ í†µí•´ LLMì€ ë” ì •í™•í•˜ê³  ë¬¸ë§¥ì„ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•˜ë©°, í™˜ê°(hallucination)ì„ ë°©ì§€í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ ì¥ì ì„ ê°€ì§„ RAGëŠ” 2023ë…„ ì´í›„ LLM ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œ ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì•„í‚¤í…ì²˜ë¡œ ìë¦¬ ì¡ì•˜ë‹¤. ì´ì— RAGê°€ ì–´ë–»ê²Œ ë°œì „í•´ ì™”ëŠ”ì§€ ì•Œì•„ë³´ë„ë¡ í•˜ê² ë‹¤.\\nğŸ’¡Â RAG Framework\\nìµœê·¼ ëª‡ ë…„ ë™ì•ˆ RAG ë¶„ì•¼ì—ì„œëŠ” ë§ì€ ì—°êµ¬ê°€ ì´ë£¨ì–´ì¡Œìœ¼ë©°, í¬ê²Œ RAGëŠ” ì„¸ ê°€ì§€ì˜ ë²”ì£¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.\\n\\nNaive RAG\\nAdvanced RAG\\nModular RAGÂ \\n\\nê·¸ëŸ¼ ì´ ì„¸ ê°€ì§€ì˜ ë²”ì£¼ì— ëŒ€í•´ì„œ ì•„ë˜ì˜ ê·¸ë¦¼ì„ í†µí•´ ìì„¸íˆ ì•Œì•„ë³´ë„ë¡ í•˜ê² ë‹¤.\\n\\nğŸ’¡ Naive RAG\\n\\nIndexingÂ :Â Indexingì€ RAGì—ì„œ ìˆ˜í–‰ë˜ëŠ” ì´ˆê¸° ë‹¨ê³„ì´ë‹¤. ì´ ë‹¨ê³„ëŠ” Raw Dataë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì—ì„œ ì‹œì‘í•˜ë©°, PDF, HTML, Wordì™€ ê°™ì€ ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ í‘œì¤€í™”ëœ plain textë¡œ ë³€í™˜í•˜ê²Œ ëœë‹¤.Â ëŒ€ê·œëª¨ ì–¸ì— ëª¨ë¸(LLM)ì€ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ì— ì œí•œì´ ìˆë‹¤.Â ëŒ€ê·œëª¨ ë¬¸ì„œë‚˜ ë°ì´í„° ì…‹ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ë” ì‘ê³  ê´€ë¦¬ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë‚˜ëˆ„ê²Œ ë˜ëŠ”ë°, ì´ë¥¼Â Chunkingì´ë¼ê³  í•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ Embedding Modelë¥¼ í†µí•´ Chunkingëœ textë“¤ì„ ë²¡í„°ë¡œ í‘œí˜„ì´ ëœë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ë²¡í„°í™”ëœ ì²­í¬ëŠ” Vector DBì— í‚¤-ê°’ ìŒìœ¼ë¡œ ì €ì¥ëœ ê²Œ ëœë‹¤. ì´ëŸ¬í•œ Vector DBëŠ” ì´í›„ì˜ Retreival ë‹¨ê³„ì—ì„œ efficient í•˜ê³  scalable search capabilities ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.Â \\nRetrieval :Â ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤(Vector DB)ìœ¼ë¡œ ë¶€í„° ê´€ë ¨ ë¬¸ë§¥ì„ ê²€ìƒ‰í•˜ëŠ”ë° í™œìš©ì´ ëœë‹¤. ì´ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” ì¸ì½”ë”© ëª¨ë¸ì— ì˜í•´ ì²˜ë¦¬ë˜ì–´ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ì„ë² ë”©ì„ ìƒì„±í•˜ê²Œ ëœë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë²¡í„°í™”ëœ ì¿¼ë¦¬ëŠ” Vector DBì—ì„œ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ kê°œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ê°€ì¥ ë¹„ìŠ·í•œ ë°ì´í„°ë¥¼ ì°¾ê²Œ ëœë‹¤.Â \\nGenerationÂ :Â ì‚¬ìš©ìì˜ Queryì™€ ê²€ìƒ‰ëœ ì¶”ê°€ì ì¸ ì •ë³´ëŠ” Promptì— ì…ë ¥ë˜ê³  LLMë¥¼ ê±°ì³ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ ëœë‹¤.Â \\n\\nğŸ’¡Â Naive RAGì˜ ë¬¸ì œì \\n1. Indexing\\n\\nì •ë³´ ì¶”ì¶œì˜ ë¶ˆì•ˆì •ì„± : PDFì™€ ê°™ì€ ë¹„ì •í˜• íŒŒì¼ ë‚´ ì´ë¯¸ì§€ì™€ í‘œì— ìˆëŠ” ìœ ìš©í•œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ëª»í•œë‹¤.Â \\nì²­í‚¹ ë°©ë²• : ì²­í‚¹ ê³¼ì •ì—ì„œ íŒŒì¼ ìœ í˜•ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì§€ ì•Šê³  \\\"one-size-fits-all\\\" ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ëŒ€ë°˜ì‚¬ì´ë‹¤. ì´ëŠ” ê° ì²­í¬ì— ì¼ê´€ì„±ê³¼ ë¶ˆí•„ìš”í•œ ì˜ë¯¸ ì •ë³´ê°€ í¬í•¨ë  ê°€ëŠ¥ì„±ì´ í¬ë©°, ê¸°ì¡´ í…ìŠ¤íŠ¸ì˜ ë¬¸ë‹¨ êµ¬ë¶„ê³¼ ì¤‘ìš”í•œ ì„¸ë¶€ ì‚¬í•­ì„ ë†“ì¹˜ê²Œ ëœë‹¤Â \\në¹„ìµœì í™” ì¸ë±ì‹± êµ¬ì¡° : ì¸ë±ì‹± êµ¬ì¡°ê°€ ìµœì í™”ë˜ì§€ ì•Šì•„ ë¹„íš¨ìœ¨ì ì¸ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì´ˆë˜í•˜ê²Œ ë˜ë©°, ì´ëŠ” ê²€ìƒ‰ ì†ë„ë¥¼ í˜„ì €í•˜ê²Œ ëŠë¦¬ê²Œ ë§Œë“¤ê³  ê²€ìƒ‰ ê²°ê³¼ì˜ ì •í™•ì„±ì„ ë–¨ì–´ì§€ê²Œ ë§Œë“ ë‹¤.Â \\nì„ë² ë”© ëª¨ë¸ì˜ ì˜ë¯¸ í‘œí˜„ ëŠ¥ë ¥ : ì„ë² ë”© ëª¨ë¸ì´ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì œëŒ€ë¡œ íŒŒì•…í•˜ì§€ ëª»í•´, ê²€ìƒ‰ëœ ì •ë³´ì˜ ê´€ë ¨ì„±ì´ ë‚®ì•„ì§„ë‹¤. ì´ëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹  ìˆ˜ ìˆê²Œ ëœë‹¤.Â \\n\\n2. Retrieval\\n\\nì œí•œëœ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜: í‚¤ì›Œë“œ, ì˜ë¯¸, ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•˜ì§€ ì•Šì€ ë“± ë‹¤ì–‘í•œ ê²€ìƒ‰ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì˜ í†µí•©ì´ ì œí•œì ì´ë©°, ì´ëŠ” ê²€ìƒ‰ ê²°ê³¼ì˜ ë‹¤ì–‘ì„±ê³¼ ì •í™•ì„±ì„ ì €í•˜ì‹œí‚¨ë‹¤.Â \\nì¿¼ë¦¬ ë° ì„ë² ë”© ëª¨ë¸ì˜ í•œê³„ : ì¿¼ë¦¬ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì„ë² ë”© ëª¨ë¸ì˜ ì˜ë¯¸ í‘œí˜„ ì„±ëŠ¥ì´ ë‚®ì•„ ìœ ìš©í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì§€ ëª»í•œë‹¤.\\në‹µë³€ ì •ë³´ ì¤‘ë³µ : ì—¬ëŸ¬ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ê°€ ìœ ì‚¬í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì— ë°˜ë³µì ì¸ ë‚´ìš©ì´ í¬í•¨ëœë‹¤.\\n\\n3. Generation\\n\\nì˜ëª»ëœ ì‘ë‹µ ìƒì„± : LLMì´ ê´€ë ¨ ì—†ê±°ë‚˜ í¸í–¥ëœ ì‘ë‹µì„ ìƒì„±í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.Â \\nì˜ëª»ëœ ì •ë³´ ì œê³µ : ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šê³  ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë‹¨ìˆœíˆ ë°˜ë³µí•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì¼ê´€ì„± ì—†ëŠ” ë‹µë³€ì„ ë±‰ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤.Â \\n\\n\\nğŸ’¡ Advanced RAG\\nAdvanced RAGëŠ” Naive RAG ë°©ì‹ì—ì„œ ì§ë©´í•˜ê³  ìˆëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì—ì„œ ê³ ë ¤í•´ì•¼ í•  ê²ƒì€ ì–´ë– í•œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ë©°, ì•„ë˜ì™€ ê°™ì€ ì‚¬í•­ë“¤ì„ í•´ê²°í•´ì•¼ í•œë‹¤.\\n\\në¬¸ì„œì™€ ì¿¼ë¦¬ì˜ semantic representationì˜ ì •í™•ì„±ì„ ì–´ë–»ê²Œ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆì„ê¹Œ?\\nì¿¼ë¦¬ì™€ ë¬¸ì„œ(ì²­í¬)ì˜ semantic spaceë¥¼ ì–´ë–»ê²Œ align ì‹œí‚¬ìˆ˜ ìˆì„ê¹Œ?Â \\nRetrievalì˜ ì¶œë ¥ì„ LLMì˜ ì„ í˜¸ë„ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ë¬´ì—‡ì¼ê¹Œ?Â \\n\\nìœ„ì˜ ì„¸ ê°€ì§€ ê³ ì°°ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ Pre-Retreival ë° Post-Retrievalë¥¼ ê¸°ì¡´ RAG ì•„í‚¤í…ì²˜ì— ì¶”ê°€í•œ ê²ƒì´ Advanced RAGì´ë‹¤. ì´ë“¤ì˜ ì—­í• ì— ëŒ€í•´ ì•Œì•„ë³´ì.\\n1. Pre-Retrieval\\nì£¼ìš” ëª©ì ì€ ìƒ‰ì¸ êµ¬ì¡°ì™€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ëŠ” ê²ƒì´ë‹¤.\\n\\në°ì´í„° í’ˆì§ˆ í–¥ìƒ : ì—”í„°í‹°ì™€ ìš©ì–´ì˜ ëª¨í˜¸ì„±ì„ ì œê±°í•˜ê³ , ì‚¬ì‹¤ ì •í™•ì„±ì„ ìœ„í•´ ë¬¸ë§¥ ìœ ì§€ ë° ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸ í•œë‹¤.Â \\nì¸ë±ìŠ¤ êµ¬ì¡° ìµœì í™” : ì²­í¬ í¬ê¸°ë¥¼ ìµœì í™”í•˜ì—¬ ë¬¸ë§¥ì„ ì¼ì •í™”í•˜ê³  ì—”í„°í‹° ê°„ì˜ ê´€ê³„ë¥¼ í¬ì°©í•˜ê¸° ìœ„í•´ ê·¸ë˜í”„ êµ¬ì¡°ì˜ ì •ë³´ë¥¼ ì¶”ê°€í•œë‹¤.Â \\në©”íƒ€ë°ì´í„° ì¶”ê°€ : dates, chapters, subsections, purposes ë“±ê³¼ ê°™ì€ ê´€ë ¨ ì •ë³´ë¥¼ ì²­í¬ì— ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ê°€í•˜ì—¬ ë°ì´í„° í•„í„°ë§ì„ ê°œì„ í•œë‹¤.Â \\nì²­í¬ ìµœì í™” : ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤/ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ë•Œ, ì²­í¬ë¥¼ ë” ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¸ë¶€ì ì¸ íŠ¹ì„±ì„ ì¶”ì¶œí•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ì—¬ ë‚´í¬í•˜ê³  ìˆëŠ” ì˜ë¯¸ë¥¼ ë„ì¶œí•œë‹¤.Â \\n\\n2. Retrieval\\nì²­í¬ í¬ê¸°ê°€ ê²°ì •ëœ í›„, ì„ë² ë”©í•˜ê²Œ ëœë‹¤. í•´ë‹¹ ë‹¨ê³„ì—ì„œëŠ” ì¿¼ë¦¬ì™€ ì„ë² ë”©ëœ ì²­í¬ ê°„ì˜ ìœ ì‚¬ì„±ì„ ê³„ì‚°í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²­í¬ë¥¼ ì‹ë³„í•˜ê²Œëœë‹¤. ì—¬ê¸°ì„œ ì¿¼ë¦¬ì™€ ì²­í¬ì— ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© ëª¨ë¸ì„ ìµœì í™”í•  ìˆ˜ ìˆë‹¤.\\n\\nDomain Knowledge Fine-Tuning : ì„ë² ë”© ëª¨ë¸ì´ ê° ë„ë©”ì¸ë³„ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ í¬ì°©í•  ìˆ˜ ìˆë„ë¡,Â  ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ fine-tuningí•œë‹¤. ì´ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ì—ëŠ” ì¿¼ë¦¬, ì½”í¼ìŠ¤ ë° ê´€ë ¨ ë¬¸ì„œê°€ í¬í•¨ë˜ì–´ì•¼ í•œë‹¤.Â \\nDynamic Embedding : ë‹¨ì–´ê°€ ë“±ì¥í•˜ëŠ” ë§¥ë½ì— ë§ì¶° ì„ë² ë”©ì„ fine-tuningí•˜ëŠ” ë°©ì‹ì´ë‹¤. ì´ëŠ” ê° ë‹¨ì–´ì— ëŒ€í•´ í•˜ë‚˜ì˜ ë²¡í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê° í† í° ë‹¹ ì •í•´ì§„ ì„ë² ë”©ì„ ë¦¬í„´í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹ˆë¼ ì£¼ë³€ ë‹¨ì–´ì— ë”°ë¼ ë§¥ë½ì„ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” BERTë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤.Â \\n\\n3. Post-Retrieval\\nê´€ë ¨ëœ ì •ë³´(ì²­í¬)ë“¤ì„ Vector Database ë‚´ì—ì„œ ê²€ìƒ‰í•œ í›„, ì¿¼ë¦¬ì™€ í•¨ê»˜ LLMì— ì…ë ¥ëœë‹¤. í•˜ì§€ë§Œ ê²€ìƒ‰ëœ ì²­í¬ë“¤ì´ ê°„í˜¹ ì¤‘ë³µì´ ë˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì •ë³´ë¥¼ ë‹´ëŠ” ê²½ìš° ë°œìƒí•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” LLMì´ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ì•Œì•„ë³´ì.\\n\\nReranking : ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì¬ìˆœìœ„í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ìš°ì„ ì‹œí•œë‹¤. LLMì— ì…ë ¥ì´ ì¶”ê°€ë  ë•Œ, ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤. ì´ì— ê²€ìƒ‰ëœ ì²­í¬ë¥¼ ì¬ì •ë ¬í•˜ê³  Top-K ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²­í¬ë¥¼ ì‹ë³„í•˜ì—¬ LLMì— ì‚¬ìš©í•  ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µí•œë‹¤.Â \\nPrompt Compression : ê²€ìƒ‰ëœ ì •ë³´ì— Noisyê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, LLMì— íƒœìš°ê¸°ì „ì— ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ì••ì¶•í•˜ê³  ê¸¸ì´ë¥¼ ì¤„ì´ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ë‹¤.Â Â \\n\\n\\nğŸ’¡Modular RAG\\n\\bì•ì„œ ì•Œì•„ë³´ì•˜ë˜ Advanced RAGëŠ” Naive RAGì˜ ì»´í¬í„´íŠ¸ë¥¼ ì¡°ê¸ˆì”© ë³´ì™„í•œ í˜•íƒœë¼ë©´, Modular RAGëŠ” ì¡°ê¸ˆ ë” ë‚˜ì•„ê°€ ë‹¤ì–‘í•˜ê³  ìœ ì—°í•œ êµ¬ì¡°ë¥¼ ì§€í–¥í•œë‹¤. ì´ëŸ¬í•œ êµ¬ì¡°ëŠ” RAGì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œì¼°ìœ¼ë©°, í˜„ì¬ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ë•Œ í‘œì¤€ íŒ¨ëŸ¬ë‹¤ì„ì´ ë˜ì—ˆë‹¤. ê·¸ëŸ¼ ëª‡ ê°€ì§€ ëª¨ë“ˆì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ì.\\n\\nSearch Module : ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ ì™¸ì—ë„ ì¶”ê°€ì ì¸ ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. ì¦‰ Search Moduleì€ íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° LLMì´ ìƒì„±í•œ ì½”ë“œë‚˜ SQL ë“±ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“ˆì´ë‹¤. ì´ì— ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ë‹¤.\\nMemory Module : LLMì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ì²­í¬ë¿ë§Œ ì•„ë‹ˆë¼ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ì´ì „ ì¿¼ë¦¬ì™€ ê²°í•©í•˜ì—¬ í˜„ì¬ ì…ë ¥ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€ì„ ì°¾ëŠ” ëª¨ë“ˆì´ë‹¤.Â \\nFusion Module : ìœ ì €ì˜ ì˜ë„ë¥¼ ì •í™•í•˜ê²Œ ë°˜ì˜í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤ëŠ” ì°¨ê´€ì—ì„œ ë¹„ë¡¯ë˜ì—ˆë‹¤. LLMì„ í†µí•´ ìœ ì €ì˜ ì¿¼ë¦¬ë¡œ ë¶€í„° ì—¬ëŸ¬ ê°œì˜ ê°€ìƒ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ê²€ìƒ‰í•˜ëŠ” ë°©ì‹ì´ë‹¤.Â \\n\\n\\nFusion Model (RAG-Fusion)\\nìœ„ì˜ ëª¨ë“ˆë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ëª¨ë“ˆì´ ì¡´ì¬í•˜ë‹ˆ, ì´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ ë§í¬ ì°¸ê³ í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\\nê³µìœ í•˜ê¸°\\nê²Œì‹œê¸€ ê´€ë¦¬\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒ\\n'LLM' ì¹´í…Œê³ ë¦¬ì˜ ë‹¤ë¥¸ ê¸€\\nRetrieval-Augmented Generation ì´ë€?Â Â (0)2024.07.21\\n'LLM' Related Articles\\n\\nRetrieval-Augmented Generation ì´ë€? 2024.07.21\\n\\nmore\\n\\nBlog is powered by kakao / Designed by Tistory\\ní‹°ìŠ¤í† ë¦¬íˆ´ë°”\\nêµ´ëŸ¬ê°€ëŠ” ë¶„ì„ê°€ì˜ ì¼ìƒêµ¬ë…í•˜ê¸°\"}, {\"title\": \"Naive RAG, Advanced RAG, Modular RAG : ë„¤ì´ë²„ ... - ë„¤ì´ë²„ ë¸”ë¡œê·¸\", \"url\": \"https://blog.naver.com/PostView.naver?blogId=jangjw01088&logNo=223650933570\", \"content\": \"Advanced RAG. Advanced RAGëŠ” Naive RAGì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ê°€ì§€ ì „ëµì„ ë„ì…í•œ ë°©ì‹ì…ë‹ˆë‹¤. ì£¼ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³ , ê²€ìƒ‰ëœ ì •ë³´ê°€ LLMì— ë” ì˜ í†µí•©ë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì´ í¬í•¨ë©ë‹ˆë‹¤. ... ì£¼ìš” ëª¨ë“ˆì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ëª¨ë“ˆ : ë²¡í„°DB ì™¸ì—ë„\", \"score\": 0.74161834, \"raw_content\": null}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"12í™” ë³µì¡í•œ RAG ë¶„í•´í•˜ê¸°-Modular RAGë€? - ë¸ŒëŸ°ì¹˜\", \"url\": \"https://brunch.co.kr/@harryban0917/338\", \"content\": \"ëª¨ë“ˆëŸ¬ RAGëŠ” ë³µì¡í•œ RAG ì‹œìŠ¤í…œì„ ë§ˆì¹˜ ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ë‚˜ëˆ„ì–´, í•„ìš”ì— ë”°ë¼ ê° ëª¨ë“ˆì„ êµì²´í•˜ê±°ë‚˜ ì¡°í•©í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. ëª¨ë“ˆëŸ¬ RAGëŠ” ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ì„¤ê³„í•˜ê³  ì´ë¥¼ í•„ìš”ì— ë”°ë¼ êµì²´í•˜ê±°ë‚˜ ê²°í•©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìƒˆë¡œìš´ ì„ë² ë”© ëª¨ë¸ì´ ë“±ì¥í•˜ê±°ë‚˜ ê¸°ì¡´ì˜ ë²¡í„° DBê°€ ì„±ëŠ¥ì„ ë” ë†’ì¼ ìˆ˜ ìˆë‹¤ê³  íŒë‹¨ë˜ë©´, í•´ë‹¹ ëª¨ë“ˆë§Œ êµì²´í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹œìŠ¤í…œì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„° ì†ŒìŠ¤ì— ë§ëŠ” ëª¨ë“ˆì„ ì„ íƒí•˜ê³ , ì´ë¥¼ ì¡°í•©í•¨ìœ¼ë¡œì¨ íš¨ìœ¨ì ì¸ RAG ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ëª¨ë“ˆëŸ¬ RAGëŠ” ê° ëª¨ë“ˆì´ ë…ë¦½ì ìœ¼ë¡œ ìœ ì§€ë³´ìˆ˜ë˜ê³  ê°œì„ ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì‹œìŠ¤í…œì˜ ìœ ì§€ ê´€ë¦¬ê°€ ìš©ì´í•˜ê³ , ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë°©ë²•ë¡ ì„ ë„ì…í•˜ëŠ” ë°ì—ë„ ìœ ë¦¬í•˜ì§€ìš”. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ë°ì´í„° ì†ŒìŠ¤ì— ë” ì í•©í•œ ë²¡í„° DBë¥¼ ì°¾ê±°ë‚˜, ìµœì‹ ì˜ ì„ë² ë”© ëª¨ë¸ì„ ë„ì…í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ í†µí•´ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\", \"score\": 0.87348515, \"raw_content\": \"12í™” ë³µì¡í•œ RAG ë¶„í•´í•˜ê¸°-Modular RAGë€?\\në©”ë‰´\\nbrunch\\nì—°ì¬ ì¤‘ ì•Œë°”íŠ¸ë¡œìŠ¤ì˜ ìƒì„±í˜• AI ì—°êµ¬ì†Œ 12í™”\\nì‹¤í–‰\\nì‹ ê³ \\në¼ì´í‚· 24 ëŒ“ê¸€ ê³µìœ \\në‹«ê¸°\\nYou can make anything\\nby writing\\nC.S.Lewis\\në¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ ì‹œì‘í•˜ê¸°\\n\\në¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ í™ˆ\\në¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ ë‚˜ìš°\\në¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ ì±…ë°©\\n\\n\\nê³„ì •ì„ ìŠì–´ë²„ë¦¬ì…¨ë‚˜ìš”?\\në³µì¡í•œ RAG ë¶„í•´í•˜ê¸°-Modular RAGë€?\\nRAGì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë¹„ë²•, ëª¨ë“ˆí™”\\nby ì•Œë°”íŠ¸ë¡œìŠ¤ Nov 30. 2024\\nì§€ê¸ˆê¹Œì§€ ê²€ìƒ‰ì¦ê°•ìƒì„±(RAG, Retrieval Augmented Generation)ì„Â êµ¬ì„±í•˜ëŠ” í•µì‹¬ì ì¸ ìš”ì†Œë“¤ì— ëŒ€í•´ ë°°ì›Œë³´ì•˜ìŠµë‹ˆë‹¤. RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ëŠ” ìš”ì†Œì¸ ì„ë² ë”© ëª¨ë¸ê³¼ ë²¡í„° DB ê·¸ë¦¬ê³  ìµœì¢…ì ì¸Â LLM ë‹µë³€ì˜ ì „ì²´ì ì¸ í†¤ ì•¤ ë§¤ë„ˆì™€ ì œì•½ì‚¬í•­ ë“±ì„ í†µí•´ ë‹µë³€ì„ ì œì–´í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(System Prompt)ê¹Œì§€ ê²€ìƒ‰ì¦ê°•ìƒì„± íŒŒì´í”„ë¼ì¸ì—ëŠ” ì •ë§ ë‹¤ì–‘í•œ ìš”ì†Œë“¤ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\\nì—¬íƒœê» ë°°ìš´ ê²ƒë“¤ì„ ì •ë¦¬í•´ ë´…ì‹œë‹¤. ìƒì„±í˜• AIë„ êµ¬ê¸€ë§ì„ í•œë‹¤?Â ì—ì„œ ì‚´í´ë³´ì•˜ë˜ ê²ƒì²˜ëŸ¼ ê²°êµ­ RAGëŠ” LLMì´ ì–‘ì§ˆì˜ ì •ë³´ë¥¼ 'ê²€ìƒ‰'í•˜ê¸° ìœ„í•œ ì¼ì¢…ì˜ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤. LLMì—ê²Œ ê²€ìƒ‰í•˜ê²Œ í•˜ê³ ì í•˜ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì§ˆì„œ ì •ì—°í•˜ê²Œ ì¸ë±ì‹±(Indexing) ë° ì²­í‚¹(Chunking) í•´ì¤€ ë’¤ì— 'ì„ë² ë”© ëª¨ë¸'ì— ì œê³µí•´ ì£¼ë©´Â Token IDì™€ í•¨ê»˜ ìˆ«ìë¡œ ëœ ë²¡í„°ë“¤ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ ë²¡í„°ë“¤ì„ chromaDBë‚˜ Elasic Searchì™€ ê°™ì€ ì—¬ëŸ¬ ë²¡í„° DBì— ì €ì¥í•´ ë‘ì—ˆë‹¤ê°€ LLMì´ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜Â ê´€ë ¨ëœ ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ êº¼ë‚´ë‹¤ ì“¸ ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” ê²ƒì´ì§€ìš”.\\nì¶œì²˜ : Freepiks\\nì´ë•Œ RAG íŒŒì´í”„ë¼ì¸ì˜ ê° ìš”ì†Œë“¤ì€ í•˜ë‚˜ì˜ ì‹œìŠ¤í…œìœ¼ë¡œ ìœ ê¸°ì ìœ¼ë¡œ ì‘ìš©í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ì§€ë§Œ ê°ê°ì˜ ìš”ì†Œë¥¼ ë–¼ì–´ë†“ê³  ì‚´í´ë³´ë©´Â ë§ˆì¹˜ ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ë¶„ë¦¬í•˜ê³  ê°ˆì•„ ë¼ìš¸ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆì— ìƒˆë¡œ ë‚˜ì˜¨ ì–´ëŠ 'ì„ë² ë”© ëª¨ë¸'ì´ ì¢‹ë‹¤ê³  í•˜ë©´ í•´ë‹¹ ë¶€ë¶„ë§Œ ê°ˆì•„ ë¼ìš¸ ìˆ˜ë„ ìˆê³ , ìš°ë¦¬ íšŒì‚¬ì˜ ë°ì´í„°ì— ë” ì í•©í•œ 'ë²¡í„° DB'ë¥¼ ë°œê²¬í•˜ë©´ ë§ˆì°¬ê°€ì§€ë¡œ ê·¸ ë¶€ë¶„ë§Œ êµì²´í•  ìˆ˜ë„ ìˆì§€ìš”.\\nì´ëŸ¬í•œ ë¸”ë¡ ì‘ì—…ë“¤ì„ ìš©ì´í•˜ê²Œ í•˜ê³ , ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ êµ¬í˜„í•´ ë‚´ëŠ” ë°©ë²•ìœ¼ë¡œ ì œì•ˆëœ ëª¨ë“ˆëŸ¬ RAGë¼ëŠ” ê°œë…ì´ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ ì‹œê°„ì—ëŠ” Modular RAG: A Reconfigurable Framework for Retrieval-Augmented Generationë¼ëŠ” ë…¼ë¬¸ì„ ë¦¬ë·°í•˜ë©° ëª¨ë“ˆëŸ¬ RAGì˜ ê°œë…ì— ëŒ€í•´ ì†Œê°œí˜¸ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\\n1. ë³µì¡í•œ RAG ì‹œìŠ¤í…œ ë¶„í•´í•˜ê¸° : ëª¨ë“ˆëŸ¬ ë ˆê·¸(Modular RAG)ë€?\\nì§€ë‚œ ëª‡ ì£¼ì— ê±¸ì³ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ëŠ” ì„ë² ë”© ëª¨ë¸, ë²¡í„° DB, ê·¸ë¦¬ê³  LLMì˜ ìµœì¢… ë‹µë³€ì„ ì œì–´í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê¹Œì§€, ì´ ëª¨ë“  ìš”ì†Œë“¤ì´ ì–´ë–»ê²Œ ìœ ê¸°ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ì— ëŒ€í•´ ì‚´í´ë´¤ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ì´ëŸ¬í•œ ìš”ì†Œë“¤ì´ ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì¡´ì¬í•˜ë©´ì„œë„ ì‰½ê²Œ êµì²´ë  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê³  ê³„ì…¨ë‚˜ìš”?\\nì´ë²ˆì— ì†Œê°œí•  'ëª¨ë“ˆëŸ¬ RAG'ëŠ” ë°”ë¡œ ì´ëŸ¬í•œ êµì²´ ê°€ëŠ¥ì„±ì„ ê·¹ëŒ€í™”í•˜ê³ , ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒí•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ëª¨ë“ˆëŸ¬ RAGëŠ” ë³µì¡í•œ RAG ì‹œìŠ¤í…œì„ ë§ˆì¹˜ ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ë‚˜ëˆ„ì–´, í•„ìš”ì— ë”°ë¼ ê° ëª¨ë“ˆì„ êµì²´í•˜ê±°ë‚˜ ì¡°í•©í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì‹œìŠ¤í…œì˜ ìœ ì—°ì„±ì€ ë¬¼ë¡ , í™•ì¥ì„±ê¹Œì§€ í•œì¸µ ê°•í™”ë©ë‹ˆë‹¤.\\n2. ëª¨ë“ˆëŸ¬ RAGì˜ ê°œë…ê³¼ êµ¬ì„± ìš”ì†Œ\\n\\nëª¨ë“ˆëŸ¬ RAGëŠ” RAG ì‹œìŠ¤í…œì„ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ë‚˜ëˆ„ì–´ êµ¬ì„±í•˜ëŠ” ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° ëª¨ë“ˆì€ ë‹¤ë¥¸ ëª¨ë“ˆê³¼ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•˜ë©´ì„œë„, ì„œë¡œ í•„ìš”í•œ ì •ë³´ë¥¼ êµí™˜í•˜ë©° ì „ì²´ ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ í•µì‹¬ì€ 'ëª¨ë“ˆí™”'ì…ë‹ˆë‹¤. ê° ëª¨ë“ˆì€ íŠ¹ì •í•œ ì—­í• ì„ ë‹´ë‹¹í•˜ë©°, í•´ë‹¹ ëª¨ë“ˆì„ ë‹¤ë¥¸ ëª¨ë“ˆë¡œ êµì²´í•˜ê±°ë‚˜ ì¡°í•©í•¨ìœ¼ë¡œì¨ ë‹¤ì–‘í•œ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nê¸°ì¡´ RAG(Naive RAG) vs Advanced RAG vs ëª¨ë“ˆëŸ¬ RAG (ì¶œì²˜ :Â Modular RAG: A Reconfigurable Framework...)\\nëª¨ë“ˆëŸ¬ RAGëŠ” í¬ê²Œ ì„¸ ê°€ì§€ ì£¼ìš” ìˆ˜ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì§‘ë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ëª¨ë“ˆë¡œ,Â RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë°ì´í„° ì¸ë±ì‹±, ê²€ìƒ‰ ì „í›„ ì²˜ë¦¬, ìƒì„± ê³¼ì • ë“±ì´ ëª¨ë“ˆì— í•´ë‹¹í•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” í•˜ìœ„ ëª¨ë“ˆë¡œ,Â ê° ëª¨ë“ˆ ë‚´ì˜ ì„¸ë¶€ ê¸°ëŠ¥ì„ ì„¸ë¶„í™”í•˜ê³  ìµœì í™”í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì¿¼ë¦¬ í™•ì¥ì´ë‚˜ ê²€ìƒ‰ê¸° ì„ íƒ ë“±ì´ í•˜ìœ„ ëª¨ë“ˆì— í•´ë‹¹í•©ë‹ˆë‹¤. ì„¸ ë²ˆì§¸ëŠ” ì—°ì‚°ìë¡œ, í•˜ìœ„ ëª¨ë“ˆ ë‚´ì—ì„œ ì‹¤ì œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìŠ¬ë¼ì´ë”© ìœˆë„ë‚˜ ë©”íƒ€ë°ì´í„° ì²¨ë¶€ ê°™ì€ ê¸°ëŠ¥ì´ ì—°ì‚°ìì— í•´ë‹¹í•©ë‹ˆë‹¤.\\n3. ëª¨ë“ˆëŸ¬ RAGì˜ ì‘ë™ ì›ë¦¬ì™€ ì¥ì \\n\\nëª¨ë“ˆëŸ¬ RAGëŠ” ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ì„¤ê³„í•˜ê³  ì´ë¥¼ í•„ìš”ì— ë”°ë¼ êµì²´í•˜ê±°ë‚˜ ê²°í•©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.Â ì˜ˆë¥¼ ë“¤ì–´, ìƒˆë¡œìš´ ì„ë² ë”© ëª¨ë¸ì´ ë“±ì¥í•˜ê±°ë‚˜ ê¸°ì¡´ì˜ ë²¡í„° DBê°€ ì„±ëŠ¥ì„ ë” ë†’ì¼ ìˆ˜ ìˆë‹¤ê³  íŒë‹¨ë˜ë©´, í•´ë‹¹ ëª¨ë“ˆë§Œ êµì²´í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹œìŠ¤í…œì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ëª¨ë“ˆí™” ëœ ì‹œìŠ¤í…œì€ ë‹¨ìˆœíˆ ê¸°ì¡´ì˜ ì‹œìŠ¤í…œì„ í™•ì¥í•˜ê±°ë‚˜ ê°œì„ í•˜ëŠ” ê²ƒì— ê·¸ì¹˜ì§€ ì•Šê³ , ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë§ê²Œ ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nëª¨ë“ˆëŸ¬ RAGëŠ” ë˜í•œ ë™ì ì´ê³  ì ì‘ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„° ì†ŒìŠ¤ì— ë§ëŠ” ëª¨ë“ˆì„ ì„ íƒí•˜ê³ , ì´ë¥¼ ì¡°í•©í•¨ìœ¼ë¡œì¨ íš¨ìœ¨ì ì¸ RAG ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ëª¨ë“ˆëŸ¬ RAGëŠ” ê° ëª¨ë“ˆì´ ë…ë¦½ì ìœ¼ë¡œ ìœ ì§€ë³´ìˆ˜ë˜ê³  ê°œì„ ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì‹œìŠ¤í…œì˜ ìœ ì§€ ê´€ë¦¬ê°€ ìš©ì´í•˜ê³ , ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë°©ë²•ë¡ ì„ ë„ì…í•˜ëŠ” ë°ì—ë„ ìœ ë¦¬í•˜ì§€ìš”.\\nëª¨ë“ˆëŸ¬ RAGì˜ ê°€ì¥ í° ì¥ì ì€ ë°”ë¡œ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì…ë‹ˆë‹¤. íŠ¹ì • ì‘ì—…ì— ë§ëŠ” ëª¨ë“ˆì„ ììœ ë¡­ê²Œ ì„ íƒí•˜ê³  êµì²´í•¨ìœ¼ë¡œì¨ ì‹œìŠ¤í…œì„ ìµœì í™”í•  ìˆ˜ ìˆê³ , ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë°©ë²•ë¡ ì„ ë¹ ë¥´ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ìœ ì§€ ê´€ë¦¬ë˜ê¸° ë•Œë¬¸ì—, ì‹œìŠ¤í…œ ì „ì²´ì˜ ì•ˆì •ì„±ì„ ë†’ì´ëŠ” ë°ì—ë„ ìœ ë¦¬í•©ë‹ˆë‹¤.\\në˜í•œ, ëª¨ë“ˆëŸ¬ RAGëŠ” ì‹œìŠ¤í…œì˜ ë³µì¡ë„ë¥¼ ë‚®ì¶”ê³ , ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒí•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.Â ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ë°ì´í„° ì†ŒìŠ¤ì— ë” ì í•©í•œ ë²¡í„° DBë¥¼ ì°¾ê±°ë‚˜, ìµœì‹ ì˜ ì„ë² ë”© ëª¨ë¸ì„ ë„ì…í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ í†µí•´ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë¹ ë¥´ê²Œ ë³€í™”í•˜ëŠ” ê¸°ìˆ  í™˜ê²½ì— ì ì‘í•˜ëŠ” ë° í° ì´ì ì´ ë©ë‹ˆë‹¤.\\nëª¨ë“ˆëŸ¬ RAGëŠ” ê¸°ì¡´ì˜ RAG ì‹œìŠ¤í…œì„ ë³´ë‹¤ ìœ ì—°í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë°œì „ì‹œí‚¨ í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° ìš”ì†Œë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì¡°ì •í•˜ê³  ìµœì í™”í•  ìˆ˜ ìˆì–´, ë‹¤ì–‘í•œ ì‘ì—… ì‹œë‚˜ë¦¬ì˜¤ì— ë§ëŠ” ë§ì¶¤í˜• ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Â ëª¨ë“ˆëŸ¬ RAGëŠ” ê³„ì†í•´ì„œ ë°œì „í•˜ëŠ” AI í™˜ê²½ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.\\n4. ëª¨ë“ˆëŸ¬ RAGë¥¼ í†µí•´ ë°”ë¼ë³¸ ìƒì„±í˜• AI ë°œì „ íŠ¸ë Œë“œ\\nì´ì²˜ëŸ¼ ìƒì„±í˜• AI ê¸°ìˆ ì˜ ìµœì‹  íŠ¸ë Œë“œëŠ” ìˆ˜ì§ì ì¸ ì‹œìŠ¤í…œ êµ¬ì¡°ì—ì„œ íƒˆí”¼í•´Â ê·¹ë„ì˜ 'ìœ ì—°ì„±'ì„ ì¶”êµ¬í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë‚˜ì•„ê°€ê³  ìˆìŠµë‹ˆë‹¤. ìƒì„±í˜• AIëŠ” ìˆ˜ê°œì›” ì£¼ê¸°ë¡œ ì›Œë‚™ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°”ë€Œê³ Â ìˆëŠ” ë¶„ì•¼ì´ê¸° ë•Œë¬¸ì—, ê° ìš”ì†Œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¡°ì •í•˜ê³  êµì²´í•  ìˆ˜ ìˆëŠ” ìœ ì—°í•œ ì‹œìŠ¤í…œì€ í•„ìˆ˜ì ì´ê¸° ë•Œë¬¸ì´ì£ .\\nì˜ˆë¥¼ ë“¤ì–´ RAGì˜ ê° êµ¬ì„± ìš”ì†Œë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ” ëŒ€í‘œì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ ë­ì²´ì¸(Langchain)ê³¼ ë­ê·¸ë˜í”„(Langgraph)ë¥¼ ë³´ì•„ë„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹œê°„ì—ëŠ” ë­ì²´ì¸ê³¼ ë­ê·¸ë ˆí”„ì˜ ê¸°ì´ˆ ê°œë…ê³¼ ì™œ ë­ê·¸ë˜í”„ê°€ ìµœê·¼ ë­ì²´ì¸ë³´ë‹¤ ë” ê°ê´‘ë°›ê³  ìˆëŠ”ì§€ ê·¸ ì´ìœ ì— ëŒ€í•´ ìƒê°í•´ ë³¼ ìˆ˜ ìˆëŠ” ì‹œê°„ì„ ê°€ì ¸ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\\n\\nkeyword\\n\\nAI\\nì¸ê³µì§€ëŠ¥\\nì±—GPT\\n\\nBrunch Book í† ìš”ì¼ ì—°ì¬\\nì—°ì¬ ì•Œë°”íŠ¸ë¡œìŠ¤ì˜ ìƒì„±í˜• AI ì—°êµ¬ì†Œ\\n\\n09 RAGë¥¼ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ í•´ì£¼ëŠ” ì¸ë±ì‹±ê³¼ ì²­í‚¹\\n10 ë²¡í„° DBëŠ” ê¸°ì¡´ì˜ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì–´ë–»ê²Œ ë‹¤ë¥¼ê¹Œ?\\n11 ëŒ€í‘œì ì¸ ë²¡í„° DBì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆì„ê¹Œ?\\nìµœì‹ ê¸€12 ë³µì¡í•œ RAG ë¶„í•´í•˜ê¸°-Modular RAGë€?\\n13 13í™”ê°€ ê³§ ë°œí–‰ë  ì˜ˆì •ì…ë‹ˆë‹¤. 2024ë…„ 12ì›” 07ì¼ í† ìš”ì¼ ë°œí–‰ ì˜ˆì •\\n\\nì „ì²´ ëª©ì°¨ ë³´ê¸°\\nì•Œë°”íŠ¸ë¡œìŠ¤ IT ë¶„ì•¼ í¬ë¦¬ì—ì´í„° ì†Œì† ì§ì—… ì—ì„¸ì´ìŠ¤íŠ¸ \\në¬¸ê³¼ ì¶œì‹ ìœ¼ë¡œ ìƒì„±í˜• AI ì—”ì§€ë‹ˆì–´ë¡œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì±—GPTì™€ ê°™ì€ AIê°€ ë³´ë‹¤ ë” ì‚¬ëŒì˜ ë§ì„ ì˜ ì•Œì•„ë“£ê³  ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ì—°êµ¬í•˜ëŠ” NLP(ìì—°ì–´ì²˜ë¦¬) ë¶„ì•¼ì—ì„œ ì¼í•©ë‹ˆë‹¤.\\nêµ¬ë…ì 425 ì œì•ˆí•˜ê¸° êµ¬ë…\\n\\nì´ì „ 11í™” ëŒ€í‘œì ì¸ ë²¡í„° DBì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆì„ê¹Œ?\\në¸ŒëŸ°ì¹˜ ë¡œê·¸ì¸\\në¸ŒëŸ°ì¹˜\\n\\n ë¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ ì‘ê°€ë¡œ ë°ë·”í•˜ì„¸ìš”. ì§„ì†”í•œ ì—ì„¸ì´ë¶€í„° ì—…ê³„ ì „ë¬¸ ì§€ì‹ê¹Œì§€, ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ì„¸ìƒì— ì„ ë³´ì´ì„¸ìš”.\\n ë¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ë¡œ ì œì•ˆë°›ëŠ” ìƒˆë¡œìš´ ê¸°íšŒ ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ì™€ íŒŒíŠ¸ë„ˆë¥¼ í†µí•´ ì‘ê°€ë‹˜ì˜ ì‘í’ˆì´ ì±…Â·ê°•ì—° ë“±ìœ¼ë¡œ í™•ì¥ë©ë‹ˆë‹¤.\\n ê¸€ë¡œ ë§Œë‚˜ëŠ” ì‘ê°€ì˜ ê²½í—˜ ì‘ê°€ë¥¼ êµ¬ë…í•˜ê³ , ìƒˆ ê¸€ì„ ë°›ì•„ë³´ì„¸ìš”. ë‹¹ì‹ ì—ê²Œ ì˜ê°ì„ ì£¼ëŠ” ì‘í’ˆì„ ì¶”ì²œí•©ë‹ˆë‹¤.\\n\\nì´ì „\\n\\n1\\n2\\n3\\n\\në‹¤ìŒ\\në¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ ì‹œì‘í•˜ê¸° ì¹´ì¹´ì˜¤ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸\\në‚´ ë¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ ì°¾ê¸° ë‚´ ë¸ŒëŸ°ì¹˜ìŠ¤í† ë¦¬ì˜ ì¹´ì¹´ì˜¤ê³„ì •ì„ ëª¨ë¥´ê² ì–´ìš” í˜ì´ìŠ¤ë¶Â·íŠ¸ìœ„í„°ë¡œë§Œ ë¡œê·¸ì¸ í–ˆì—ˆë‚˜ìš”? ë¡œê·¸ì¸ ê´€ë ¨ ìƒì„¸ ë„ì›€ë§\\nì°½ ë‹«ê¸°\\në¸ŒëŸ°ì¹˜ëŠ” ìµœì‹  ë¸Œë¼ìš°ì €ì— ìµœì í™” ë˜ì–´ìˆìŠµë‹ˆë‹¤. IE chrome safari\\nì‘ê°€ êµ¬ë…ì„ ì·¨ì†Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?\\nì‘ê°€ì˜ ê¸€ì„ ë” ì´ìƒ êµ¬ë…í•˜ì§€ ì•Šê³ ,\\nìƒˆ ê¸€ ì•Œë¦¼ë„ ë°›ì•„ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\\nê³„ì† êµ¬ë…í•˜ê¸° êµ¬ë… ì·¨ì†Œí•˜ê¸°\"}, {\"title\": \"ëª¨ë“ˆí˜• Rag: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(Llm)ê³¼ì˜ í†µí•© ë° ì‘ë™ ë°©ì‹\", \"url\": \"https://digitalbourgeois.tistory.com/311\", \"content\": \"ì„ í˜• í”„ë¡œì„¸ìŠ¤ì˜ í•œê³„: ì „í†µì ì¸ RAG ì‹œìŠ¤í…œì€ ê²€ìƒ‰ í›„ ìƒì„±í•˜ëŠ” ë‹¨ì¼ íë¦„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ë³µì¡í•œ ì§ˆì˜ë‚˜ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“ˆí˜• RAGëŠ” RAGì˜ ì•„í‚¤í…ì²˜ë¥¼ ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ë‚˜ëˆ”ìœ¼ë¡œì¨ ì¬êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 3. ëª¨ë“ˆí˜• RAGì˜ 3ê³„ì¸µ ì•„í‚¤í…ì²˜ ì´ëŸ¬í•œ êµ¬ì¡° ë•ë¶„ì— ëª¨ë“ˆí˜• RAGëŠ” ì§€ì†ì ì¸ ì„±ëŠ¥ ê°œì„ ê³¼ í™•ì¥ì´ ê°€ëŠ¥í•˜ë©°, AI ì‘ì—…ì˜ ìš”êµ¬ ì‚¬í•­ ë³€í™”ì— ë¹ ë¥´ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „í†µì ì¸ RAGì™€ ìœ ì‚¬í•˜ì§€ë§Œ, ëª¨ë“ˆí˜• RAGëŠ” ê° ëª¨ë“ˆì´ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”ë˜ê±°ë‚˜ êµì²´ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ ì°¨ë³„í™”ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì§ˆì˜ê°€ ë³µì¡í•˜ê±°ë‚˜ ê²€ìƒ‰ëœ ë°ì´í„°ì˜ ì–‘ì´ ë§ì€ ê²½ìš°, ì‹œìŠ¤í…œì€ ì¶”ê°€ì ì¸ ì¿¼ë¦¬ ì¬ì‘ì„±ì´ë‚˜ ë°ì´í„° ì••ì¶• ëª¨ë“ˆì„ í™œì„±í™”í•˜ì—¬ ë” ì í•©í•œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ì‹œìŠ¤í…œì„ êµ¬ì„±í•¨ìœ¼ë¡œì¨, ê° ì‘ì—…ì— ë§ì¶¤í˜•ìœ¼ë¡œ ìµœì í™”ëœ RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë“ˆí˜• RAGëŠ” ê¸°ì¡´ RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , AI ì‹œìŠ¤í…œì˜ ìœ ì—°ì„± ë° í™•ì¥ì„±ì„ í¬ê²Œ ê°•í™”í•œ í˜ì‹ ì ì¸ ê¸°ìˆ ì…ë‹ˆë‹¤.\", \"score\": 0.834852, \"raw_content\": \"ëª¨ë“ˆí˜• RAG: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ì˜ í†µí•© ë° ì‘ë™ ë°©ì‹\\në³¸ë¬¸ ë°”ë¡œê°€ê¸°\\ní‰ë²”í•œ ì§ì¥ì¸ì´ ì‚¬ëŠ” ì„¸ìƒ\\në©”ë‰´\\n\\në¶„ë¥˜ ì „ì²´ë³´ê¸° (525)  \\nì¸ê³µì§€ëŠ¥ (121)  \\nTensorflow (5)\\n\\n\\në¹…ë°ì´í„° (30)\\nì•Œê³ ë¦¬ì¦˜ (32)\\nKubernetes (10)\\nAWS (14)\\nJAVA (32)\\nAPI (9)\\nMSA(ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤) (6)\\nì•„í‚¤í…ì²˜ (4)\\nSpring (50)\\nDB (17)\\në³´ì•ˆ (9)\\nPython (8)\\nDevOps (30)\\nPlatform Engineering (3)\\në¦¬ëˆ…ìŠ¤ (1)\\nì»¤í”¼ ê¸€ìêµ­ (34)\\nê²½ì œ ê¸€ìêµ­ (17)\\nì—¬í–‰ ê¸€ìêµ­ (11)\\nìœ¡ì•„ ê¸€ìêµ­ (2)\\në§›ì§‘ ê¸€ìêµ­ (39)  \\nì¡í•™ë‹¤ì‹ (36)\\nì„¸ë¯¸ë‚˜ (1)\\nì„œí‰ (15)\\nIT ì»¬ëŸ¼ (9)\\nì†Œí”„íŠ¸ì›¨ì–´ êµìœ¡ (3)\\nTools (1)\\n\\n\\nWEB (3)\\n\\n\\n\\nPOWERED BY TISTORY\\në¸”ë¡œê·¸ ë‚´ ê²€ìƒ‰  ê²€ìƒ‰\\n\\nì¸ê³µì§€ëŠ¥\\nëª¨ë“ˆí˜• RAG: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ì˜ í†µí•© ë° ì‘ë™ ë°©ì‹\\níŒŒíŒŒëˆ„ë³´ 2024. 9. 8. 22:54\\n728x90\\në°˜ì‘í˜•\\n\\n**ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì€ ìµœê·¼ ëª‡ ë…„ê°„ AI ê¸°ìˆ ì˜ ê¸‰ì†í•œ ë°œì „ì„ ì´ëŒì–´ ì™”ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ LLMì€ ì—¬ì „íˆ ëª‡ ê°€ì§€ ì¤‘ìš”í•œ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ëŒ€í‘œì ì¸ ë¬¸ì œê°€ í™˜ê°(ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒ)ê³¼ ì—…ë°ì´íŠ¸ëœ ì •ë³´ ë¶€ì¡±ì…ë‹ˆë‹¤. ì´ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ì¤‘ìš”í•œ ë„êµ¬ë¡œ **RAG(Retrieval-Augmented Generation, ê²€ìƒ‰-ìƒì„± ë°©ì‹)**ê°€ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. RAGëŠ” LLMì— ì™¸ë¶€ ì§€ì‹ì„ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ì§€ë§Œ, ê¸°ì¡´ RAG ì‹œìŠ¤í…œì€ ì—¬ì „íˆ ë³µì¡í•œ ì§ˆì˜ë‚˜ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤.\\nì—¬ê¸°ì„œ **ëª¨ë“ˆí˜• RAG(Modular RAG)**ê°€ ìƒˆë¡œìš´ í•´ê²°ì±…ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ëª¨ë“ˆí™”ë˜ì–´, ìœ ì—°í•˜ê³  ì¬êµ¬ì„± ê°€ëŠ¥í•œ êµ¬ì¡°ë¥¼ í†µí•´ AIì˜ ë³µì¡í•œ ê³¼ì œì— ì ì‘í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ëª¨ë“ˆí˜• RAGê°€ ì–´ë–»ê²Œ ì „í†µì ì¸ RAGë¥¼ ë°œì „ì‹œì¼°ëŠ”ì§€ì™€ ê·¸ ì‘ë™ ë°©ì‹ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.\\n1. ì „í†µì ì¸ RAG ì‹œìŠ¤í…œì˜ ì´í•´\\n1.1 RAGì˜ ê¸°ë³¸ ê°œë…\\n**RAG(Retrieval-Augmented Generation)**ëŠ” LLMì˜ í•œê³„ë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. RAGëŠ” ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬, ê·¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ ê°„ë‹¨í•˜ì§€ë§Œ, ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ íƒì›”í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. RAGëŠ” ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì œê³µ, ë§ì¶¤í˜• ì¶”ì²œ, ê³ ê° ì§€ì› ë“±ì— ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì „í†µì ì¸ RAG ì‹œìŠ¤í…œì€ ì‚¬ìš©ìì˜ ì§ˆì˜ì— ëŒ€í•´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ì´ˆê¸° RAG ì‹œìŠ¤í…œì€ ì£¼ë¡œ ìœ ì‚¬ì„± ì¸¡ì •ì— ì˜ì¡´í•˜ì—¬ ì§ˆì˜ì™€ í…ìŠ¤íŠ¸ ì¡°ê° ê°„ì˜ ì¼ì¹˜ ì—¬ë¶€ë¥¼ íŒë‹¨í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì€ ê°„ë‹¨í•œ ì§ˆì˜ì—ëŠ” ì í•©í–ˆì§€ë§Œ, ë°ì´í„°ì˜ ì–‘ê³¼ ë³µì¡ì„±ì´ ì¦ê°€í•˜ë©´ì„œ í•œê³„ê°€ ë“œëŸ¬ë‚˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤.\\n1.2 ì „í†µì  RAG ì‹œìŠ¤í…œì˜ ë¬¸ì œì \\nì „í†µì ì¸ RAG ì‹œìŠ¤í…œì€ ì—¬ëŸ¬ ê°€ì§€ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nì–•ì€ ì§ˆì˜ ì´í•´: ì „í†µì ì¸ RAGëŠ” ì§ˆì˜ì™€ ë¬¸ì„œ ì¡°ê° ê°„ì˜ ë‹¨ìˆœí•œ ìœ ì‚¬ì„± ë§¤ì¹­ì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì—, ì§ˆì˜ì˜ ë¯¸ë¬˜í•œ ì°¨ì´ë¥¼ ì´í•´í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ëŠ” ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë¶€ì •í™•í•œ ì‘ë‹µì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nê²€ìƒ‰ ì¤‘ë³µì„±ê³¼ ì¡ìŒ: ëª¨ë“  ê²€ìƒ‰ëœ ì •ë³´ë¥¼ LLMì— ë°”ë¡œ ì œê³µí•˜ëŠ” ê²½ìš°, ì¤‘ë³µë˜ê±°ë‚˜ ê´€ë ¨ì„±ì´ ë‚®ì€ ì •ë³´ê°€ ë§ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì—°ì‚° ìì›ì˜ ë‚­ë¹„ë¿ë§Œ ì•„ë‹ˆë¼ ì˜ëª»ëœ ì‘ë‹µì„ ìƒì„±í•  ìœ„í—˜ë„ ë†’ì…ë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ ì œê±°í•˜ê³  ì¤‘ìš”í•œ ë°ì´í„°ë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒì´ í° ê³¼ì œê°€ ë©ë‹ˆë‹¤.\\nì„ í˜• í”„ë¡œì„¸ìŠ¤ì˜ í•œê³„: ì „í†µì ì¸ RAG ì‹œìŠ¤í…œì€ ê²€ìƒ‰ í›„ ìƒì„±í•˜ëŠ” ë‹¨ì¼ íë¦„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ë³µì¡í•œ ì§ˆì˜ë‚˜ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¼ë¶€ ê³ ê¸‰ RAG ë°©ë²•ì€ ì¿¼ë¦¬ ì¬ì‘ì„±ì´ë‚˜ ì¬ë­í‚¹ ê¸°ìˆ ì„ ë„ì…í–ˆì§€ë§Œ, ì—¬ì „íˆ ìœ ì—°ì„±ì´ ë¶€ì¡±í•œ êµ¬ì¡°ë¡œ ì¸í•´ í•œê³„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\\n\\në°˜ì‘í˜•\\n2. ëª¨ë“ˆí˜• RAGì˜ ì¶œí˜„\\n2.1 ëª¨ë“ˆí˜• RAGì˜ ë„ì…\\nAI ì‘ìš© í”„ë¡œê·¸ë¨ì´ ë”ìš± ë³µì¡í•´ì§ì— ë”°ë¼ ì „í†µì ì¸ \\\"ê²€ìƒ‰ í›„ ìƒì„±\\\" ë°©ì‹ì˜ í•œê³„ê°€ ë¶„ëª…í•´ì¡ŒìŠµë‹ˆë‹¤. í˜„ëŒ€ AI ì‘ìš© í”„ë¡œê·¸ë¨ì€ ë”ìš± ìœ ì—°í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ìš”êµ¬í•˜ê²Œ ë˜ì—ˆìœ¼ë©°, ì´ ìš”êµ¬ì— ë§ì¶° ë“±ì¥í•œ ê²ƒì´ ë°”ë¡œ ëª¨ë“ˆí˜• RAGì…ë‹ˆë‹¤.\\nëª¨ë“ˆí˜• RAGëŠ” RAGì˜ ì•„í‚¤í…ì²˜ë¥¼ ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ë‚˜ëˆ”ìœ¼ë¡œì¨ ì¬êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆì¹˜ ë ˆê³  ë¸”ë¡ì²˜ëŸ¼ ê° ëª¨ë“ˆì´ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”ë˜ë©°, í•„ìš”ì— ë”°ë¼ ê²°í•©í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ëŠ” ë³µì¡í•œ ì‘ì—…ì—ì„œë„ ê³ ì •ëœ êµ¬ì¡°ì— ì–½ë§¤ì´ì§€ ì•Šê³  íš¨ìœ¨ì ìœ¼ë¡œ ì ì‘í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.\\n3. ëª¨ë“ˆí˜• RAGì˜ 3ê³„ì¸µ ì•„í‚¤í…ì²˜\\nëª¨ë“ˆí˜• RAGì˜ í•µì‹¬ì€ 3ê³„ì¸µ ì•„í‚¤í…ì²˜ë¡œ êµ¬ì„±ëœ êµ¬ì¡°ì…ë‹ˆë‹¤. ì´ êµ¬ì¡°ëŠ” ì‹œìŠ¤í…œì„ ë³´ë‹¤ ìœ ì—°í•˜ê³  ì„¸ë¶€ì ìœ¼ë¡œ ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\\n3.1 ëª¨ë“ˆ ê³„ì¸µ\\nëª¨ë“ˆí˜• RAGì˜ ìµœìƒìœ„ ê³„ì¸µì—ì„œëŠ” ëª¨ë“ˆì´ ë…ë¦½ì ì¸ ë‹¨ê³„ë¡œ ë‚˜ë‰˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë“ˆë“¤ì€ ê²€ìƒ‰, ìƒì„±, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ê³¼ ê°™ì€ ì£¼ìš” í”„ë¡œì„¸ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ë©°, ê° ë‹¨ê³„ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì œì–´ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n3.2 í•˜ìœ„ ëª¨ë“ˆ ê³„ì¸µ\\nëª¨ë“  ëª¨ë“ˆì—ëŠ” í•˜ìœ„ ëª¨ë“ˆì´ ì¡´ì¬í•˜ì—¬ ë” êµ¬ì²´ì ì¸ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê²€ìƒ‰ ëª¨ë“ˆ ë‚´ì—ëŠ” ì¿¼ë¦¬ í™•ì¥, ì¬ë­í‚¹, í•„í„°ë§ì„ ë‹´ë‹¹í•˜ëŠ” í•˜ìœ„ ëª¨ë“ˆë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì´ í•˜ìœ„ ëª¨ë“ˆë“¤ì„ í†µí•´ RAG í”„ë¡œì„¸ìŠ¤ëŠ” ë”ìš± ì •êµí•˜ê²Œ ì œì–´ë©ë‹ˆë‹¤.\\n3.3 ì—°ì‚°ì ê³„ì¸µ\\nì—°ì‚°ìëŠ” ëª¨ë“ˆ ë‚´ì—ì„œ ê°€ì¥ ê¸°ë³¸ì ì¸ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë‹¨ìœ„ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì„ë² ë”© ìƒì„±, ìœ ì‚¬ì„± ê³„ì‚°, ë¬¸ì„œ ì¡°ê°í™” ë“±ì˜ ì‘ì—…ì´ ì—°ì‚°ì ë‹¨ìœ„ì—ì„œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì—°ì‚°ì ê³„ì¸µ ë•ë¶„ì— ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì„±ëŠ¥ì„ ê°œì„ í•  ë•Œ ì „ì²´ ì‹œìŠ¤í…œì„ ìˆ˜ì •í•  í•„ìš” ì—†ì´ ê°œë³„ì ìœ¼ë¡œ ì¡°ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n4. ëª¨ë“ˆê³¼ ì—°ì‚°ìì˜ ìƒí˜¸ì‘ìš©\\nëª¨ë“ˆê³¼ ì—°ì‚°ìì˜ ìƒí˜¸ì‘ìš©ì€ ëª¨ë“ˆí˜• RAGì˜ í•µì‹¬ ê°•ì ì…ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ê° ëª¨ë“ˆì´ ë…ë¦½ì ì´ë©´ì„œë„ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆì–´ ë³µì¡í•œ ì‘ì—…ì— ëŒ€í•´ ë†’ì€ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì‘ì—…ì´ ë” ì„¸ë°€í•œ ê²€ìƒ‰ì„ ìš”êµ¬í•˜ëŠ” ê²½ìš°, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ëª¨ë“ˆì€ ì¬ë­í‚¹ì´ë‚˜ ì¿¼ë¦¬ ë³€í™˜ ì—°ì‚°ìë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\në˜í•œ, ìƒˆë¡œìš´ ì—°ì‚°ìê°€ ë“±ì¥í•˜ë©´ ê¸°ì¡´ ì‹œìŠ¤í…œì„ ì™„ì „íˆ ê°œí¸í•˜ì§€ ì•Šê³ ë„ ì†ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ì¡° ë•ë¶„ì— ëª¨ë“ˆí˜• RAGëŠ” ì§€ì†ì ì¸ ì„±ëŠ¥ ê°œì„ ê³¼ í™•ì¥ì´ ê°€ëŠ¥í•˜ë©°, AI ì‘ì—…ì˜ ìš”êµ¬ ì‚¬í•­ ë³€í™”ì— ë¹ ë¥´ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n728x90\\n5. ëª¨ë“ˆí˜• RAGì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íë¦„ íŒ¨í„´\\n5.1 ì„ í˜• íŒ¨í„´\\nì„ í˜• íŒ¨í„´ì€ ê°€ì¥ ê¸°ë³¸ì ì¸ RAG íë¦„ì…ë‹ˆë‹¤. ëª¨ë“ˆë“¤ì´ ê³ ì •ëœ ìˆœì„œë¡œ ë°°ì¹˜ë˜ì–´ ìˆì–´, ê²€ìƒ‰ í›„ ìƒì„± ê³¼ì •ì„ ì°¨ë¡€ëŒ€ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. ì „í†µì ì¸ RAGì™€ ìœ ì‚¬í•˜ì§€ë§Œ, ëª¨ë“ˆí˜• RAGëŠ” ê° ëª¨ë“ˆì´ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”ë˜ê±°ë‚˜ êµì²´ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ ì°¨ë³„í™”ë©ë‹ˆë‹¤.\\n5.2 ì¡°ê±´ë¶€ íŒ¨í„´\\nì¡°ê±´ë¶€ íŒ¨í„´ì€ íŠ¹ì • ì¡°ê±´ì— ë”°ë¼ RAG íë¦„ì„ ë¶„ê¸°ì‹œí‚¤ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì§ˆì˜ê°€ ë³µì¡í•˜ê±°ë‚˜ ê²€ìƒ‰ëœ ë°ì´í„°ì˜ ì–‘ì´ ë§ì€ ê²½ìš°, ì‹œìŠ¤í…œì€ ì¶”ê°€ì ì¸ ì¿¼ë¦¬ ì¬ì‘ì„±ì´ë‚˜ ë°ì´í„° ì••ì¶• ëª¨ë“ˆì„ í™œì„±í™”í•˜ì—¬ ë” ì í•©í•œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n5.3 ë°˜ë³µ íŒ¨í„´\\në°˜ë³µ íŒ¨í„´ì€ ë³µì¡í•œ ì§ˆì˜ì— ëŒ€í•´ ì—¬ëŸ¬ ë²ˆì˜ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ë°˜ë³µí•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ë” ì •í™•í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì´ˆê¸° ì‘ë‹µì´ ì¶©ë¶„í•˜ì§€ ì•Šì„ ê²½ìš°, ë‹¤ì‹œ ê²€ìƒ‰ ëª¨ë“ˆë¡œ ëŒì•„ê°€ ì¶”ê°€ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µì„ ê°œì„ í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\\n6. ëª¨ë“ˆí˜• RAGì˜ ì¥ì ê³¼ ë„ì „ ê³¼ì œ\\n6.1 ëª¨ë“ˆí˜• RAGì˜ ì¥ì \\nëª¨ë“ˆí˜• RAGì˜ ê°€ì¥ í° ì¥ì ì€ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì…ë‹ˆë‹¤. ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ì‹œìŠ¤í…œì„ êµ¬ì„±í•¨ìœ¼ë¡œì¨, ê° ì‘ì—…ì— ë§ì¶¤í˜•ìœ¼ë¡œ ìµœì í™”ëœ RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„° ìœ í˜•ì— ë§ì¶° ëª¨ë“ˆì„ êµì²´í•˜ê±°ë‚˜ ìƒˆë¡­ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆì–´, ë‹¤ì–‘í•œ AI ì‘ìš© í”„ë¡œê·¸ë¨ì— ì í•©í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\\n6.2 ë„ì „ ê³¼ì œ\\nëª¨ë“ˆí˜• RAGì˜ ë„ì…ì—ëŠ” ëª‡ ê°€ì§€ ë„ì „ ê³¼ì œê°€ ë”°ë¦…ë‹ˆë‹¤. ë³µì¡í•œ ë°ì´í„° í†µí•©ì´ ê·¸ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì „í†µì ì¸ RAGëŠ” ì£¼ë¡œ ë¹„ì •í˜• í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë‹¤ë£¨ì§€ë§Œ, ëª¨ë“ˆí˜• RAGëŠ” í‘œ í˜•ì‹ì˜ ë°ì´í„°ë‚˜ ì§€ì‹ ê·¸ë˜í”„ì™€ ê°™ì€ ë°˜êµ¬ì¡°í™” ë° êµ¬ì¡°í™”ëœ ë°ì´í„°ë„ í†µí•©í•´ì•¼ í•©ë‹ˆë‹¤. ì´ì™€ í•¨ê»˜ ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ë„ í° ê³¼ì œì…ë‹ˆë‹¤. ê° ëª¨ë“ˆ ê°„ì˜ ë°ì´í„° íë¦„ê³¼ ì‘ì—… ê´€ë¦¬ê°€ ë”ìš± ë³µì¡í•´ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\\nëª¨ë“ˆí˜• RAGëŠ” ê¸°ì¡´ RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , AI ì‹œìŠ¤í…œì˜ ìœ ì—°ì„± ë° í™•ì¥ì„±ì„ í¬ê²Œ ê°•í™”í•œ í˜ì‹ ì ì¸ ê¸°ìˆ ì…ë‹ˆë‹¤. ë°ì´í„° í†µí•©, ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, ëª¨ë“ˆ ìƒí˜¸ì‘ìš© ìµœì í™” ë“±ì˜ ê³¼ì œê°€ ìˆì§€ë§Œ, ì´ë¥¼ í•´ê²°í•¨ìœ¼ë¡œì¨ AI ê¸°ìˆ ì˜ ë¯¸ë˜ë¥¼ ë”ìš± ë°ê²Œ ì—´ì–´ê°ˆ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\\n728x90\\në°˜ì‘í˜•\\nê³µìœ í•˜ê¸°\\nê²Œì‹œê¸€ ê´€ë¦¬\\ní‰ë²”í•œ ì§ì¥ì¸ì´ ì‚¬ëŠ” ì„¸ìƒ\\nì €ì‘ìí‘œì‹œ ë¹„ì˜ë¦¬ ë³€ê²½ê¸ˆì§€\\n'ì¸ê³µì§€ëŠ¥' ì¹´í…Œê³ ë¦¬ì˜ ë‹¤ë¥¸ ê¸€\\nAIê°€ 'ìƒê°'í•˜ê¸° ì‹œì‘í–ˆë‹¤? OpenAI o1ì˜ í˜ì‹ Â Â (0)2024.09.14Langchainìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ ë§Œë“¤ê¸°: ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìœ ì§€ ë¹„ë²•Â Â (0)2024.09.09íš¨ìœ¨ì ì¸ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ ì†”ë£¨ì…˜, Langchainì˜ Retrieverë€?Â Â (0)2024.09.05Langchain Document Transformers: AI ë¬¸ì„œ ì²˜ë¦¬ì˜ í•µì‹¬ ê¸°ìˆ  ì•Œì•„ë³´ê¸°Â Â (0)2024.09.04Hugging Face: ì¸ê³µì§€ëŠ¥ ê°œë°œìë“¤ì˜ í•„ìˆ˜ ë„êµ¬, ì™œ ì£¼ëª©ë°›ê³  ìˆì„ê¹Œ?Â Â (0)2024.09.04\\níƒœê·¸\\nllm, Modular, modular rag, modular ragë€ ë¬´ì—‡ì¸ê°€?, rag íŠ¸ë Œë“œ, ragë€, ëª¨ë“ˆí˜• rag\\n'ì¸ê³µì§€ëŠ¥' Related Articles\\n\\nAIê°€ 'ìƒê°'í•˜ê¸° ì‹œì‘í–ˆë‹¤? OpenAI o1ì˜ í˜ì‹ \\nLangchainìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ ë§Œë“¤ê¸°: ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìœ ì§€ ë¹„ë²•\\níš¨ìœ¨ì ì¸ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ ì†”ë£¨ì…˜, Langchainì˜ Retrieverë€?\\nLangchain Document Transformers: AI ë¬¸ì„œ ì²˜ë¦¬ì˜ í•µì‹¬ ê¸°ìˆ  ì•Œì•„ë³´ê¸°\\n\\n\\nDESIGN BY TISTORY ê´€ë¦¬ì\\ní‹°ìŠ¤í† ë¦¬íˆ´ë°”\"}, {\"title\": \"ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸(Llm)ì˜ í™˜ê°í˜„ìƒì„ ì¤„ì´ëŠ” Rag(ê²€ìƒ‰ì¦ê°•ìƒì„±) ëª¨ë¸ì˜ ë™ì‘ì›ë¦¬ì™€ 3ê°€ì§€ íŒ¨ëŸ¬ë‹¤ì„\", \"url\": \"https://m.blog.naver.com/buksamfight/223388544425\", \"content\": \"RAGì˜ í™œìš© . ìƒì„±í˜• AI ì‹œìŠ¤í…œì´ ì™¸ë¶€ ì†ŒìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•œ ìƒí™© ì¸ì‹ ì‘ë‹µì„ ë§Œë“¦ ... ì¥ì . ë‹¨ì . ìˆœìœ„ ë‹¤ì‹œ ë§¤ê¸°ê¸° ... ë‹¤. ëª¨ë“ˆí˜•(Modular) RAG - ë‹¤ì–‘í•œ ëª¨ë“ˆê³¼ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì™€ ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì—¬ëŸ¬ ìƒˆë¡œìš´\", \"score\": 0.82895297, \"raw_content\": \"ë¸”ë¡œê·¸\\nì¹´í…Œê³ ë¦¬ ì´ë™\\nì •ë³´ì²˜ë¦¬ê¸°ìˆ ì‚¬/ì •ë³´ê´€ë¦¬ê¸°ìˆ ì‚¬/ë¹…ë°ì´í„°ë¶„ì„/ADSP\\nëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸(LLM)ì˜ í™˜ê°í˜„ìƒì„ ì¤„ì´ëŠ” RAG(ê²€ìƒ‰ì¦ê°•ìƒì„±) ëª¨ë¸ì˜ ë™ì‘ì›ë¦¬ì™€ 3ê°€ì§€ íŒ¨ëŸ¬ë‹¤ì„\\n2024. 3. 19. 20:20\\nì •ë³´ ê²€ìƒ‰(Information Retrieval, IR)ì´ë€!?\\nì§€ì‹ ì†ŒìŠ¤ë‚˜ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì¡°íšŒí•˜ê³  ì¶”ì¶œí•˜ëŠ” í”„ë¡œì„¸ìŠ¤\\nì˜ˆ) ê²€ìƒ‰ ì—”ì§„ì„ ì´ìš©í•˜ì—¬ ì¸í„°ë„·ì—ì„œ ì •ë³´ë¥¼ ì°¾ëŠ” ê²ƒ\\nâ€‹\\nì‚¬ìš©ìê°€ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ë©´ ì‹œìŠ¤í…œì€ ì‚¬ìš©ìê°€ ì°¾ê³  ìˆëŠ” ì •ë³´ë¥¼ í¬í•¨í•  ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ì€ ë¬¸ì„œë‚˜ ì›¹ í˜ì´ì§€ë¥¼ ì§ˆì˜í•˜ì—¬ ì‘ë‹µ\\n- ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ì€ ì´ëŸ¬í•œ ì •ë³´ì§ˆì˜ë¥¼ ì´ìš©í•´ í•™ìŠµ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ë° í•™ìŠµì— ì ìš©\\nâ€‹\\nëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ì˜ í•œê³„ì™€ RAGì˜ ì˜ì˜\\nëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸(Large Language Model, LLM)ì˜ ê°œë…\\nì‚¬ëŒë“¤ì˜ ì–¸ì–´(ìì—°ì–´)ë¥¼ í•™ìŠµí•˜ì—¬ ì‹¤ì œì¸ê°„ê³¼ ìœ ì‚¬í•œ ë¬¸ì¥ì„ ìƒì„± í•˜ê¸° ìœ„í•œ ì–¸ì–´ëª¨ë¸\\nì ì°¨ ê·œëª¨ê°€ ì»¤ì§€ë©° ì´ˆê±°ëŒ€ AIë¡œ ì§„í™”\\nìˆœì°¨ ë°ì´í„°ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì‹ ê²½ë§ì¸ íŠ¸ëœìŠ¤í¬ë¨¸(Transformer)ë¥¼ í†µí•´ ë¹„ì•½ì ì¸ ì„±ëŠ¥ ë°œì „\\nâ€‹\\nëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ì˜ í•œê³„\\ní™˜ê°ì´ë‚˜ ëŠë¦° ì§€ì‹ì˜ ì—…ë°ì´íŠ¸, ë‹µë³€ì˜ íˆ¬ëª…ì„± ë¶€ì¡± ë“±ê³¼ ê°™ì€ ë¬¸ì œì  ì¡´ì¬\\nì§€ì‹ì˜ ì‹œëŒ€ì— ë’¤ë–¨ì–´ì§, íŠ¹ì • ì˜ì—­ì— ëŒ€í•œ ì§€ì‹ ë¶€ì¡±, ê·¸ë¦¬ê³  ì‘ë‹µì˜ íˆ¬ëª…ì„± ë¶€ì¡±\\nâ€‹\\n- RAGë¥¼ ì´ìš©í•´ ë‹µë³€ì˜ ì •í™•ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¤ê³ , íŠ¹íˆ ì§€ì‹ ì§‘ì•½ì ì¸ ì‘ì—…ì—ì„œ ëª¨ë¸ì˜ í™˜ê°ì„ ì¤„ì—¬ì£¼ë©°, ì‚¬ìš©ìê°€ ì¶œì²˜ë¥¼ ì¸ìš©í•˜ì—¬ ë‹µë³€ì˜ ì •í™•ì„±ì„ ê²€ì¦í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ê²°ê³¼ ì¶œë ¥ì— ëŒ€í•œ ì‹ ë¢°ë¥¼ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŒ\\nâ€‹\\nâ€‹\\nëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ì˜ í•œê³„ ê·¹ë³µ, RAGì˜ ì •ì˜ì™€ í™œìš©\\nRAGì˜ ì •ì˜\\nëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ê¸° ì „ì— ê´‘ë²”ìœ„í•œ ë¬¸ì„œ ì§‘í•©ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì§ˆì˜í•˜ê³ , ì´ë¥¼ ì´ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ë²•\\nê²€ìƒ‰ê¸°ë°˜ê³¼ ìƒì„±ëª¨ë¸, ì´ ë‘ ì ‘ê·¼ ë°©ì‹ì„ ë³‘í•©í•˜ì—¬ íŠ¹ì •í•˜ë©´ì„œë„ ë™ì ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•˜ë©°, ìì—°ì–´ ì²˜ë¦¬(NLP) ë¶„ì•¼ì—ì„œ ì‹ ê²½ë§ ì •ë³´ ê²€ìƒ‰ê³¼ ì‹ ê²½ë§ í…ìŠ¤íŠ¸ ìƒì„±ì„ ê²°í•©í•œ ê³ ê¸‰ ê¸°ìˆ \\nâ€‹\\nRAGì˜ í™œìš©\\nìƒì„±í˜• AI ì‹œìŠ¤í…œì´ ì™¸ë¶€ ì†ŒìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•œ ìƒí™© ì¸ì‹ ì‘ë‹µì„ ë§Œë“¦\\nì§ˆë¬¸ ë‹µë³€ ë° ì½˜í…ì¸ ë¥¼ ìƒˆë¡œì´ ë§Œë“œëŠ” ì‘ì—…ì— ìœ ìš©\\nì‹œë§¨í‹± ì´ë‚˜ í•˜ì´ë¸Œë¦¬ë“œì™€ ê°™ì€ ë°©ë²•ì„ êµ¬í˜„í•˜ì—¬ ì˜ë„ì— ì‘ë‹µí•˜ê³  ë³´ë‹¤ ì •í™•í•œ ê²°ê³¼ë¥¼ ì œê³µ\\nâ€‹\\n-\\níŒŒì¸íŠœë‹(fine-tuning)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ì´ íŠ¹ì • ì§€ì‹ì— ì§‘ì¤‘ í•  ìˆ˜ ìˆë„ë¡ êµ¬í˜„ ê°€ëŠ¥ í•˜ë‚˜, ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ì •ë³´ë¥¼ ë°˜ì˜í•˜ëŠ”ë° ì‹œê°„ì´ ê±¸ë¦¬ë©°, ìƒˆë¡œ í•™ìŠµì‹œí‚¤ëŠ”ë° ì¶”ê°€ì ì¸ ìì›ì´ ì†Œëª¨ ë¨\\nâ€‹\\nRAGì˜ ë™ì‘ ì›ë¦¬ì™€ í•µì‹¬ ìš”ì†Œ\\në™ì‘ ì›ë¦¬ ìƒì„¸ ì„¤ëª…\\n- ì´ë¯¸ í•™ìŠµëœ ìƒì„±í˜• AIì˜ í•œê³„ë¥¼ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì´ìš©í•˜ì—¬ ê´€ë ¨ì„±ì´ ë†’ì€ Dataë¥¼ ì¦ê°•í•´ ë” ì í™•í•œ ì •ë³´ë¥¼ ì œì‹œ í•˜ê¸° ìœ„í•´ ì—°ê´€ ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì—°ê²°í•˜ê³ ,\\n- ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ì— ëŒ€í•œ íŠ¹ì • Dataë¥¼ í™œìš©í•´ ë²”ìš© LLMì„ ë‹¨ë…ìœ¼ë¡œ ì“°ëŠ” ê²ƒë³´ë‹¤ ë” ì •í™•í•œ ë‹µë³€ì„ ì–»ëŠ” ê²Œ ëª©ì \\nâ€‹\\nRAGì˜ 3ê°€ì§€ ì£¼ìš” íŒ¨ëŸ¬ë‹¤ì„\\nê¸°ë³¸/ê³ ê¸‰/ëª¨ë“ˆí˜• ìœ í˜• ì¡´ì¬\\nê°€. ê¸°ë³¸ RAG\\ní•µì‹¬ ìš”ì†Œ ì„¤ëª…\\nì¸ë±ì‹±(Indexing) : ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì–»ê³  ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •(ë°ì´í„° ì •ì œ, ì²­í¬ ë¶„í• , ë²¡í„° ì¸ì½”ë”© ë° ì¸ë±ìŠ¤ë¥¼ í¬í•¨)\\nê²€ìƒ‰ ëª¨ë¸(Retriever Model): ì£¼ì–´ì§„ ì¿¼ë¦¬ë‚˜ ì‘ì—…ê³¼ ë§¤ì¹˜ë˜ëŠ” ë¬¸ë§¥ì ìœ¼ë¡œ ì—°ê´€ëœ Data ì°¾ê¸° ìœ„í•´ í° í…ìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤(ì˜ˆ: ë¬¸ì„œ, ë¬¸ë‹¨, ë˜ëŠ” ë¬¸ì¥)ë¥¼ ì§ˆì˜í•˜ëŠ” ì»´í¬ë„ŒíŠ¸\\nìƒì„± ëª¨ë¸(Generator Model): ëª¨ë¸ì´ Dataë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ìƒì„±\\nâ€‹\\n- ì—°ê´€ëœ ì™¸ë¶€ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ ê²°í•© í•¨\\n- ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì²­í¬(ì‘ì€ ë‹¨ìœ„)ë¡œ ë¶„í• í•˜ì—¬ ì„ë² ë”©í›„ Vector DBì— ì €ì¥\\në‹¨ê³„\\ní™œë™\\nì„¤ëª…\\n1\\ní”„ë¡¬í”„íŠ¸\\n- ì‚¬ìš©ìê°€ AI ëª¨ë¸ì— ì„¤ëª…ê³¼ ì‘ë‹µ ìš”ì²­\\n2\\nìƒí™©ë³„ ê²€ìƒ‰\\n- ì¿¼ë¦¬ë‚˜ ì‘ì—…ì´ ì…ë ¥ë˜ë©´, í™œìš© ê°€ëŠ¥í•œ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì¡°íšŒí•˜ì—¬ ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë¬¸ë‹¨, ë¬¸ì„œë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì§ˆì˜\\n3\\ní”„ë¡¬í”„íŠ¸ ì¦ê°•\\n(ë¬¸ë§¥ì œê³µ)\\n- ì¶œë ¥ ëœ ë¬¸ë‹¨ë“¤ì€ ì¶”ê°€ì ì¸ ë¬¸ë§¥ì´ë‚˜ Dataë¡œ ëª¨ë¸ì— ì œê³µ\\n4\\nì¶”ë¡ \\n(í…ìŠ¤íŠ¸ ìƒì„±)\\n- ì¶”ê°€ ë¬¸ë§¥ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì€ ë” ì •í™•í•˜ê³  ì—°ê´€ëœ ì‚¬ì‹¤ê³¼ ì§€ì‹ì— ê¸°ë°˜í•œ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ ìƒì„±\\n5\\nì‘ë‹µ\\n- LLMì€ ì‹¤ì œë¡œ ì •í™•í•œ ì •ë³´ì™€ í•¨ê»˜ ì‘ë‹µì„ ì‚¬ìš©ìì—ê²Œ ì œê³µ\\nâ€‹\\në‚˜. ê³ ê¸‰(Advanced) RAG\\n- ê¸°ë³¸ RAGì˜ ë¶€ì¡±í•œ ì ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ê°œë°œëœ íŒ¨ëŸ¬ë‹¤ì„(3ë‹¨ê³„ë¡œ ìˆ˜í–‰)\\n1) ê²€ìƒ‰ ì „ ì ˆì°¨(Pre-Retrieval Process)\\n-\\në°ì´í„° ì¸ë±ì‹± ìµœì í™” ë° ì„ë² ë”©ì„ í†µí•´ì„œ ê²°ê³¼ì˜ ì—°ê´€ì„±ê³¼ ì •í™•ì„±ì„ ë†’ì´ëŠ” ë° ì¤‘ì ì„ ë‘ \\në°ì´í„° ì¸ë±ì‹± ìµœì í™”(Optimizing Data Indexing)\\nì „ëµ\\nì„¤ëª…\\nì˜ˆì‹œ\\në°ì´í„° ì„¸ë¶„í™” ê°•í™”\\ní…ìŠ¤íŠ¸ í‘œì¤€í™”, ì¼ê´€ì„±, ì •í™•ì„±, ë¬¸ë§¥ í’ë¶€í™”\\në¶ˆí•„ìš” Data ì œê±°, íŠ¹ìˆ˜ ë¬¸ì ì œê±°, ì—”í‹°í‹° ë° ìš©ì–´ ëª¨í˜¸ì„± ì œê±°\\nì¸ë±ìŠ¤ êµ¬ì¡° ìµœì í™”\\nì •í™•ì„± ë° ê´€ë ¨ì„± í–¥ìƒ\\nì²­í¬ í¬ê¸° ì¡°ì •, ì¸ë±ìŠ¤ ê²½ë¡œ ë³€ê²½, ê·¸ë˜í”„ êµ¬ì¡° ë„ì…\\në©”íƒ€ Data ì¶”ê°€\\níš¨ìœ¨ì„± ë° ê´€ë ¨ì„± í–¥ìƒ\\në‚ ì§œ, ëª©ì  ë“± ë©”íƒ€ Data ì¶”ê°€, í•„í„°ë§ ì ìš©\\nì •ë ¬ ìµœì í™”\\në¬¸ì„œ ê°„ ë¶ˆì¼ì¹˜ í•´ê²°\\nê°€ìƒ ì§ˆë¬¸ ë° ë¬¸ì„œì™€ ê²°í•©\\ní˜¼í•© ê²€ìƒ‰\\nê¸°ìˆ  ê°•ì  í™œìš©\\ní‚¤ì›Œë“œ ê¸°ë°˜, ì˜ë¯¸, ë²¡í„° ê²€ìƒ‰ ê²°í•©\\nì„ë² ë”©(Embedding)\\n- ì§ˆì˜ëœ ë‚´ìš©ê³¼ ì§ˆë¬¸ ê°„ì˜ ì—°ê´€ì„±ì„ ê°•í™”í•˜ê³  ìµœì¢… ì¶œë ¥ì— ëŒ€í•œ ì˜í–¥ì„ ìµœì í™”\\n- ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê°„ì˜ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ê³  ì´ë¥¼ ê°œì„ \\nì „ëµ\\nì„¤ëª…\\nì˜ˆì‹œ\\nì •ë°€ ì¡°ì • ì„ë² ë”©\\në‚´ìš©ê³¼ ì§ˆë¬¸ ê°„ ì—°ê´€ì„± í–¥ìƒ\\nBGE(BAAI 2023)\\në™ì  ì„ë² ë”©\\në‹¨ì–´ ë§¥ë½ ê³ ë ¤\\nBERT\\n2) ê²€ìƒ‰ í›„ ì ˆì°¨ (Post-Retrieval Process)\\n- ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¤‘ìš”í•œ ë¬¸ë§¥ì„ ì§ˆì˜ì™€ ê²°í•©í•˜ì—¬ LLMì— ì…ë ¥í•˜ëŠ” ê³¼ì •\\nì „ëµ\\nì„¤ëª…\\nì¥ì \\në‹¨ì \\nìˆœìœ„ ë‹¤ì‹œ ë§¤ê¸°ê¸°\\nê´€ë ¨ ì •ë³´ í”„ë¡¬í”„íŠ¸ ì•ë¶€ë¶„ ë°°ì¹˜\\nì—°ê´€ì„± ë†’ì€ Dataì— ìš°ì„  ì œê³µ\\nLLM ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸° ì´ˆê³¼ ê°€ëŠ¥ì„±\\ní”„ë¡¬í”„íŠ¸ ì••ì¶•\\nì¤‘ìš” ë§¥ë½ ê°•ì¡°, ì „ì²´ ê¸¸ì´ ì¤„ì„\\nLLM íš¨ìœ¨ì„± í–¥ìƒ, ë§¥ë½ì Data ì§‘ì¤‘\\nì •ë³´ ì†ì‹¤ ê°€ëŠ¥ì„±\\n3) RAG íŒŒì´í”„ë¼ì¸ ìµœì í™” (Pipeline Optimization)\\n- Retrieval ë‹¨ê³„ë¥¼ ìµœì í™”í•˜ë©°, ë‹¤ì–‘í•œ ì§ˆì˜ ì „ëµì„ ìœ ì—°í•˜ê²Œ ì ìš©í•˜ë©°, ì„ë² ë”© ìœ ì‚¬ë„ë¥¼ í™œìš©í•˜ëŠ” ë° ì´ˆì \\nì „ëµ\\nì„¤ëª…\\nì˜ˆì‹œ\\ní•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\\në‹¤ì–‘í•œ ê¸°ìˆ  ê²°í•©\\ní‚¤ì›Œë“œ ê¸°ë°˜, ì˜ë¯¸ë¡ ì , ë²¡í„° ê²°í•©\\nì¬ê·€ì  ê²€ìƒ‰ ë° ì¿¼ë¦¬ ì—”ì§„\\níš¨ìœ¨ì„±ê³¼ ë§¥ë½ì  í’ë¶€í•¨ ê· í˜•\\nì´ˆê¸° ë‹¨ê³„: ì‘ì€ ë¬¸ì„œ ë¸”ë¡, í›„ë°˜ ë‹¨ê³„: í° ë¬¸ì„œ ë¸”ë¡\\nì—­ì¶”ì  í”„ë¡¬í”„íŠ¸\\nLLM ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ\\në‹µë³€ ë° ì§ˆë¬¸-ì‘ë‹µ ê³¼ì • ì ìš©\\nì„œë¸Œì¿¼ë¦¬\\në‹¤ì–‘í•œ ì§ˆì˜ ì „ëµ ì ìš©\\níŠ¸ë¦¬ ì¿¼ë¦¬, ë²¡í„° ì¿¼ë¦¬, ìˆœì°¨ì  ì²­í¬ ì¿¼ë¦¬\\nHyDE\\n(Hypothetical Document Embeddings)\\nLLM ë‹µë³€ ê¸°ë°˜ í™•ì¸\\në‹µë³€ ë° ì„ë² ë”© í›„ ì‹¤ì œ ë¬¸ì„œ í™•ì¸\\në‹¤. ëª¨ë“ˆí˜•(Modular) RAG\\n- ë‹¤ì–‘í•œ ëª¨ë“ˆê³¼ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì™€ ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì—¬ëŸ¬ ìƒˆë¡œìš´ ëª¨ë“ˆê³¼ íŒ¨í„´ì„ í¬í•¨\\n1) ìƒˆë¡œìš´ ëª¨ë“ˆë“¤(New Modules)\\nëª¨ë“ˆ ì¢…ë¥˜\\nì„¤ëª…\\nì˜ˆì‹œ\\nê²€ìƒ‰\\nLLM ê¸°ë°˜ ì§ì ‘ ìˆ˜í–‰\\nLLM ê¸°ë°˜ ì½”ë“œ/SQL ë“± ë„êµ¬ í™œìš©\\në©”ëª¨ë¦¬\\nLLM ë©”ëª¨ë¦¬ í™œìš©\\nSelf-mem: ê°•í™” ê°œë°œê¸° ë° ë¬´ì œí•œ ë©”ëª¨ë¦¬ í’€ ì‚¬ìš©\\nì¶”ê°€ ìƒì„±\\nLLM ê¸°ë°˜ ë¬¸ì„œ\\nLLM ê¸°ë°˜ ë¬¸ì„œ, ì‚¬ìš©ì ì§ˆë¬¸ ì§ì ‘ ì§ˆì˜ ë³´ë‹¤ Data ì¦ê°€ ê°€ëŠ¥ì„±\\níƒœìŠ¤í¬ ì ì‘\\në‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—… ì ì‘\\nUPRISE: í•„ìš”í•œ ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ ì§ˆì˜\\nPROMPTAGATOR: ì œë¡œìƒ· ì¿¼ë¦¬ ê°œë°œ LLM\\nì •ë ¬\\nì§ˆì˜-í…ìŠ¤íŠ¸ ì •ë ¬ ë¬¸ì œ í•´ê²°\\nPRCA, AAR, RRR ë“± ë°©ë²•ë¡ \\nê²€ì¦\\nData ì‹ ë¢°ì„± í‰ê°€\\nì‹¤ì œ ë¬¸ì„œ-ì§ˆë¬¸ ê´€ë ¨ì„± í‰ê°€ ëª¨ë“ˆ ë„ì…\\n2) ìƒˆë¡œìš´ íŒ¨í„´ë“¤(New Patterns)\\níŒ¨í„´\\nì„¤ëª…\\nì˜ˆì‹œ\\nëª¨ë“ˆ ì¶”ê°€ ë˜ëŠ” êµì²´\\níŠ¹ì • ê¸°ëŠ¥ í–¥ìƒ ìœ„í•œ ëª¨ë“ˆ ë„ì…\\nRRR: ì¬ì‘ì„±-ê²€ìƒ‰-ì½ê¸° í”„ë¡œì„¸ìŠ¤, ì¿¼ë¦¬ ì¡°ì‘, ì½ê¸° ëª¨ë“ˆ ì„±ëŠ¥ í–¥ìƒ\\nëª¨ë“ˆ ê°„ ì¡°ì§ì  íë¦„ ì¡°ì •\\nì–¸ì–´ì™€ ê²€ìƒ‰ ìƒí˜¸ì‘ìš© ê°•í™”\\níŠ¹ì • ë¬¸ì œ ë§¥ë½ ê¸°ë°˜ ëª¨ë“ˆ ë‚´ ëŒ€ì²´ ë˜ëŠ” ì¬êµ¬ì„±\\n-->\\në” ë§ì€ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê·¼ê±°í•œ ì‘ë‹µì„ ë§Œë“œëŠ” ê²ƒì„ í†µí•´ ê¸°ì¡´ì˜ LLMsë³´ë‹¤ í° ë°œì „ì— ê¸°ì—¬\\nâ€‹\\nì‚¬ë¡€ ê¸°ë°˜, ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ì—ì„œì˜ RAGì˜ ê°€ì¹˜\\n- ê°œì¸í™”ëœ ì§€ì›: ì§€ì‹ë² ì´ìŠ¤ì™€ ê³ ê° ì´ë ¥ì— ì ‘ê·¼í•˜ì—¬ ì¼ë°˜ì ì¸ ë¬¸ì˜ì— ëŒ€í•œ ë§ì¶¤í˜• ì‘ë‹µì„ ì œê³µ\\n- ë¹„ìš© íš¨ìœ¨ì„±: ìë™í™”ëŠ” ëŒ€ëŸ‰ì˜ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ ì¸ë ¥ ë¹„ìš© ê°ì†Œ\\n- 24/7 ì§€ì›: íœ´ì‹ì´ë‚˜ êµëŒ€ ê·¼ë¬´ê°€ í•„ìš” ì—†ëŠ” ì‹œìŠ¤í…œì€ í•˜ë£¨ ì¢…ì¼ ê³ ê° ì§€ì›ì„ ì œê³µ\\në“±\\nâ€‹\\nâ€‹\\n[ì°¸ê³ ] AI í™˜ê° ë§‰ê³  ì •í™•ë„ ë†’ì´ëŠ” 'AIë ˆë“œíŒ€'\\nìƒì„±í˜• AI í™œìš©ì´ ëŠ˜ì–´ë‚˜ë©´ì„œ ìš•ì„¤ì´ë‚˜ í™˜ê° í˜„ìƒ ë“±ì˜ ë¬¸ì œì ì„ ì˜ˆë°©í•˜ê³  ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ '...\\nblog.naver.com\\nâ€‹\\nì •ë³´ê´€ë¦¬ ê¸°ìˆ ì‚¬(ITPE), ì•„ì´ë¦¬í¬ êµìœ¡ì„¼í„° ì •ë³´ì²˜ë¦¬ê¸°ìˆ ì‚¬ ì •ê·œê³¼ì • ë©˜í† , ë°ì´í„° ë¶„ì„/ì¸ê³µì§€ëŠ¥ ë“± ì¸ì¬ ì–‘ì„± ê³¼ì • ê°•ì‚¬, ë¹…ë°ì´í„° ë¶„ì„ê¸°ì‚¬ ì§‘í•„, ë°ì´í„° ë¶„ì„ ì¤€ì „ë¬¸ê°€(ADSP) ì§‘í•„\\nN-001377\\nì¹´í…Œê³ ë¦¬\"}]\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ëª¨ë“ˆí˜• RAG(Modular RAG)ì™€ ë‹¨ìˆœ RAG(Naive RAG)ì˜ ì£¼ìš” ì°¨ì´ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **êµ¬ì¡°ì  ìœ ì—°ì„±**:\n",
      "   - **ëª¨ë“ˆí˜• RAG**ëŠ” ì‹œìŠ¤í…œì„ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ë‚˜ëˆ„ì–´ ê° ëª¨ë“ˆì„ í•„ìš”ì— ë”°ë¼ êµì²´í•˜ê±°ë‚˜ ì¡°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‹œìŠ¤í…œì˜ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì—¬ì¤ë‹ˆë‹¤.\n",
      "   - **ë‹¨ìˆœ RAG**ëŠ” ê³ ì •ëœ êµ¬ì¡°ë¡œ, ê²€ìƒ‰ í›„ ìƒì„±í•˜ëŠ” ë‹¨ì¼ íë¦„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ë³µì¡í•œ ì§ˆì˜ë‚˜ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ëª¨ë“ˆí™”**:\n",
      "   - **ëª¨ë“ˆí˜• RAG**ëŠ” ê° ëª¨ë“ˆì´ íŠ¹ì • ì—­í• ì„ ë‹´ë‹¹í•˜ë©°, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê²€ìƒ‰ ëª¨ë“ˆ, ë©”ëª¨ë¦¬ ëª¨ë“ˆ, ìƒì„± ëª¨ë“ˆ ë“±ì´ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n",
      "   - **ë‹¨ìˆœ RAG**ëŠ” ì´ëŸ¬í•œ ëª¨ë“ˆí™”ê°€ ì—†ìœ¼ë©°, ëª¨ë“  ê³¼ì •ì´ í•˜ë‚˜ì˜ íë¦„ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì„±ëŠ¥ ìµœì í™”**:\n",
      "   - **ëª¨ë“ˆí˜• RAG**ëŠ” ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆì–´, ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë°©ë²•ë¡ ì„ ì‰½ê²Œ ë„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìµœì‹  ì„ë² ë”© ëª¨ë¸ì´ë‚˜ ë²¡í„° DBë¥¼ êµì²´í•˜ëŠ” ê²ƒì´ ìš©ì´í•©ë‹ˆë‹¤.\n",
      "   - **ë‹¨ìˆœ RAG**ëŠ” ì„±ëŠ¥ ê°œì„ ì´ ì–´ë ¤ì›Œ, ì‹œìŠ¤í…œ ì „ì²´ë¥¼ ìˆ˜ì •í•´ì•¼ í•  ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ì ì‘ì„±**:\n",
      "   - **ëª¨ë“ˆí˜• RAG**ëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆì–´, íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„° ì†ŒìŠ¤ì— ë§ëŠ” ëª¨ë“ˆì„ ì„ íƒí•˜ê³  ì¡°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "   - **ë‹¨ìˆœ RAG**ëŠ” ì´ëŸ¬í•œ ì ì‘ì„±ì´ ë¶€ì¡±í•˜ì—¬, ë³µì¡í•œ ì‘ì—…ì— ëŒ€í•œ ìœ ì—°í•œ ëŒ€ì‘ì´ ì–´ë µìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ì°¨ì´ì ë“¤ ë•ë¶„ì— ëª¨ë“ˆí˜• RAGëŠ” ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ AI ì‘ìš© í”„ë¡œê·¸ë¨ì— ì í•©í•œ ì†”ë£¨ì…˜ìœ¼ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mexecute\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Modular RAGì™€ Naive RAGì˜ ì£¼ìš” ì°¨ì´ì ì„ ë¹„êµí•œë‹¤.', 'ëª¨ë“ˆí˜• RAG(Modular RAG)ì™€ ë‹¨ìˆœ RAG(Naive RAG)ì˜ ì£¼ìš” ì°¨ì´ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n1. **êµ¬ì¡°ì  ìœ ì—°ì„±**:\\n   - **ëª¨ë“ˆí˜• RAG**ëŠ” ì‹œìŠ¤í…œì„ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ë‚˜ëˆ„ì–´ ê° ëª¨ë“ˆì„ í•„ìš”ì— ë”°ë¼ êµì²´í•˜ê±°ë‚˜ ì¡°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‹œìŠ¤í…œì˜ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì—¬ì¤ë‹ˆë‹¤.\\n   - **ë‹¨ìˆœ RAG**ëŠ” ê³ ì •ëœ êµ¬ì¡°ë¡œ, ê²€ìƒ‰ í›„ ìƒì„±í•˜ëŠ” ë‹¨ì¼ íë¦„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ë³µì¡í•œ ì§ˆì˜ë‚˜ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.\\n\\n2. **ëª¨ë“ˆí™”**:\\n   - **ëª¨ë“ˆí˜• RAG**ëŠ” ê° ëª¨ë“ˆì´ íŠ¹ì • ì—­í• ì„ ë‹´ë‹¹í•˜ë©°, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê²€ìƒ‰ ëª¨ë“ˆ, ë©”ëª¨ë¦¬ ëª¨ë“ˆ, ìƒì„± ëª¨ë“ˆ ë“±ì´ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\\n   - **ë‹¨ìˆœ RAG**ëŠ” ì´ëŸ¬í•œ ëª¨ë“ˆí™”ê°€ ì—†ìœ¼ë©°, ëª¨ë“  ê³¼ì •ì´ í•˜ë‚˜ì˜ íë¦„ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\\n\\n3. **ì„±ëŠ¥ ìµœì í™”**:\\n   - **ëª¨ë“ˆí˜• RAG**ëŠ” ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆì–´, ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë°©ë²•ë¡ ì„ ì‰½ê²Œ ë„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìµœì‹  ì„ë² ë”© ëª¨ë¸ì´ë‚˜ ë²¡í„° DBë¥¼ êµì²´í•˜ëŠ” ê²ƒì´ ìš©ì´í•©ë‹ˆë‹¤.\\n   - **ë‹¨ìˆœ RAG**ëŠ” ì„±ëŠ¥ ê°œì„ ì´ ì–´ë ¤ì›Œ, ì‹œìŠ¤í…œ ì „ì²´ë¥¼ ìˆ˜ì •í•´ì•¼ í•  ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\\n\\n4. **ì ì‘ì„±**:\\n   - **ëª¨ë“ˆí˜• RAG**ëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆì–´, íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„° ì†ŒìŠ¤ì— ë§ëŠ” ëª¨ë“ˆì„ ì„ íƒí•˜ê³  ì¡°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - **ë‹¨ìˆœ RAG**ëŠ” ì´ëŸ¬í•œ ì ì‘ì„±ì´ ë¶€ì¡±í•˜ì—¬, ë³µì¡í•œ ì‘ì—…ì— ëŒ€í•œ ìœ ì—°í•œ ëŒ€ì‘ì´ ì–´ë µìŠµë‹ˆë‹¤.\\n\\nì´ëŸ¬í•œ ì°¨ì´ì ë“¤ ë•ë¶„ì— ëª¨ë“ˆí˜• RAGëŠ” ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ AI ì‘ìš© í”„ë¡œê·¸ë¨ì— ì í•©í•œ ì†”ë£¨ì…˜ìœ¼ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mreplan\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Modular RAGê°€ production levelì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì„ ì •ë¦¬í•œë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_qKVnhGoYYVK7Gg2qwqVktxZY)\n",
      " Call ID: call_qKVnhGoYYVK7Gg2qwqVktxZY\n",
      "  Args:\n",
      "    query: Modular RAG production level advantages\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Modular RAG using LLMs: What is it and how does it work?\", \"url\": \"https://medium.com/@sahin.samia/modular-rag-using-llms-what-is-it-and-how-does-it-work-d482ebb3d372\", \"content\": \"These sub-modules allow for more granular control over the RAG process, enabling the system to fine-tune its operations based on the specific requirements of the taskâ€‹. This pattern closely resembles the traditional RAG process but benefits from the modular approach by allowing individual modules to be optimized or replaced without altering the overall flow. For example, a linear RAG flow might begin with a query expansion module to refine the userâ€™s input, followed by the retrieval module, which fetches the most relevant data chunks. The Modular RAG framework embraces this need through various tuning patterns that enhance the systemâ€™s ability to adapt to specific tasks and datasets. Managing these different data types and ensuring seamless integration within the RAG system can be difficult, requiring sophisticated data processing and retrieval strategiesâ€‹(modular rag paper).\", \"score\": 0.6439794, \"raw_content\": \"Modular RAG using LLMs: What is it and how does it work? | by Sahin Ahmed, Data Scientist | Medium\\nOpen in app\\nSign up\\nSign in\\n\\nWrite\\n\\nSign up\\nSign in\\n\\nMastodon\\nModular RAG using LLMs: What is it and how does it work?\\n\\nSahin Ahmed, Data Scientist\\nÂ·Follow\\n17 min read\\nÂ·\\nAug 14, 2024\\n\\n--\\n1\\n\\nListen\\nShare\\nIntroduction\\nLarge Language Models (LLMs) have taken AI to new heights, but they still stumble on challenges like hallucinations and outdated information. Retrieval-Augmented Generation (RAG) has been a game-changer, adding external knowledge to boost LLM performance. However, traditional RAG systems, with their rigid â€œretrieve-then-generateâ€ process, often struggle with complex queries and diverse data sources.\\nThis is where Modular RAG steps in. Imagine building with LEGO blocks â€” each piece independent yet part of a bigger, more flexible system. Modular RAG rethinks RAG systems by breaking them down into reconfigurable modules, offering the adaptability needed for todayâ€™s AI challenges. In this post, weâ€™ll explore how Modular RAG works and why itâ€™s set to reshape the future of AI.\\nSection 1: Understanding Traditional RAG Systems\\n1.1 The Basics of RAG\\nRetrieval-Augmented Generation (RAG) has significantly enhanced the capabilities of Large Language Models (LLMs) by providing access to external knowledge sources. This process allows LLMs to perform better in tasks that require in-depth knowledge, such as answering complex questions, making recommendations, and supporting customer service applications. The basic idea is simple: retrieve relevant information from a vast database and then use that information to generate a response. This â€œretrieve-then-generateâ€ process has been the backbone of RAG systems since their inception.\\nInitially, RAG systems were fairly straightforward, relying on basic indexing, retrieval, and generation processes. This approach, often referred to as â€œNaive RAG,â€ focused primarily on matching the semantic similarity between a userâ€™s query and chunks of text from a database. However, as the complexity of tasks and the volume of data increased, the limitations of this simplistic approach became apparent.\\n1.2 Challenges with Traditional RAG\\nDespite the success of traditional RAG systems, they face several key challenges that limit their effectiveness in more demanding scenarios:\\n\\nShallow Query Understanding: Traditional RAG systems often struggle to fully grasp the nuances of complex queries. The reliance on basic similarity measures between a query and document chunks can result in superficial matches that fail to capture the deeper relationships within the dataâ€‹.\\nRetrieval Redundancy and Noise: Feeding all retrieved chunks directly into LLMs can overwhelm the system with redundant or irrelevant information. This not only wastes computational resources but also increases the risk of generating incorrect or hallucinated responses. The challenge is to filter out noise while preserving the most relevant dataâ€‹.\\nLinear Process Limitations: The linear â€œretrieve-then-generateâ€ flow of traditional RAG systems doesnâ€™t always align well with the needs of complex applications. For example, handling multifaceted queries or integrating diverse data sources often requires a more flexible, non-linear approach. Advanced RAG methods have attempted to address these issues through techniques like query rewriting and reranking, but the rigid structure still imposes significant constraintsâ€‹.\\n\\nAs RAG technology continues to evolve, the growing complexity of tasks has driven the need for a more sophisticated and adaptable system â€” one that can break free from the limitations of a linear process and better handle the demands of real-world applications. This need has led to the development of the Modular RAG framework, which weâ€™ll explore in the next section.\\nSection 2: The Emergence of Modular RAG\\n2.1 Introducing Modular RAG\\nAs RAG systems grew more complex, the traditional â€œretrieve-then-generateâ€ approach began to show its limitations. The increasing demands of modern AI applications called for a more flexible and scalable framework â€” one that could adapt to the complexities of real-world tasks without being bogged down by the rigidities of a linear process. This is where Modular RAG comes in.\\nModular RAG reimagines the RAG architecture by breaking it down into independent, yet interconnected modules. Think of it as building with LEGO blocks â€” each module can be independently developed, optimized, and then combined with others to create a highly adaptable system. This modular design allows for a much more flexible approach, where different modules can be reconfigured or swapped out depending on the specific needs of the task at handâ€‹.\\n2.2 The Three-Tiered Architecture of Modular RAG\\n\\nimage source:https://arxiv.org/html/2407.21059v1\\nThe Modular RAG framework is organized into a three-tiered architecture, each tier serving a distinct role in the overall system:\\n\\nModules: At the top level, the system is divided into high-level stages such as indexing, retrieval, and generation. Each of these stages is treated as a standalone module, which can be independently controlled and orchestrated. This approach not only inherits the main processes from traditional RAG systems but also introduces an orchestration module that manages the coordination of these processesâ€‹.\\nSub-modules: Within each module, there are sub-modules that handle more specific tasks. For example, within the retrieval module, sub-modules might handle query expansion, reranking, or filtering. These sub-modules allow for more granular control over the RAG process, enabling the system to fine-tune its operations based on the specific requirements of the taskâ€‹.\\nOperators: At the most granular level, Modular RAG includes operators, which are the basic functional units within each sub-module. These operators carry out specific functions like embedding generation, similarity computation, and document chunking. By modularizing these operators, the system can be easily reconfigured or extended with new functionality as neededâ€‹.\\n\\nSection 3: Modules and Operators in Modular RAG\\n\\n3.1 Understanding Modules in Modular RAG\\nIn the Modular RAG framework, the concept of â€œmodulesâ€ is central to how the system is structured and operates. Each module represents a high-level stage in the RAG process, handling specific tasks that are essential for the systemâ€™s overall functionality. The key modules within this framework include:\\n\\nIndexing Module: This module is responsible for organizing and structuring the vast amounts of data that the RAG system will retrieve from. It involves breaking down documents into manageable chunks, creating embeddings, and storing these in a way that allows for efficient retrieval. One of the challenges addressed by this module is the accurate representation of content, ensuring that the system can effectively match queries with the most relevant chunksâ€‹.\\nRetrieval Module: The retrieval module plays a critical role in selecting the most relevant data chunks based on the userâ€™s query. This module can include sub-modules for tasks like query expansion, reranking of retrieved chunks, and filtering out noise. By refining the retrieval process, this module ensures that the system returns the most useful and contextually appropriate information for subsequent generationâ€‹.\\nGeneration Module: Once the relevant data has been retrieved, the generation module comes into play. This module utilizes the retrieved data to generate the final output, whether itâ€™s a response to a query, a summary, or any other type of content. The generation module may also include sub-modules for fine-tuning the output, ensuring that it is accurate, coherent, and aligned with the userâ€™s needsâ€‹.\\nOrchestration Module: Perhaps the most innovative aspect of Modular RAG is the orchestration module, which manages the coordination between different modules. This module controls the flow of data and tasks within the system, deciding which modules to activate based on the specific requirements of the query. By orchestrating the process, this module allows the system to adapt dynamically to different scenarios, making it more versatile and efficientâ€‹.\\n\\n3.2 The Role of Operators in Modular RAG\\nAt a finer level of granularity, the Modular RAG framework is built on â€œoperators,â€ which are the basic functional units within each module. Operators are essentially the building blocks of the system, performing specific tasks that contribute to the larger goals of each module. Hereâ€™s how operators function within the Modular RAG system:\\n\\nEmbedding Operators: Within the indexing module, embedding operators are responsible for converting document chunks into vector representations. These embeddings capture the semantic essence of the text, enabling the retrieval module to efficiently match queries with the most relevant dataâ€‹.\\nSimilarity Computation Operators: In the retrieval module, similarity computation operators calculate how closely a query matches with different document chunks. This process often involves comparing the embeddings of the query and the document chunks using methods like cosine similarity or dot product. The results of these computations are crucial for determining which chunks are most relevant and should be passed on to the generation moduleâ€‹.\\nQuery Expansion and Transformation Operators: These operators work within the pre-retrieval process to refine and enhance the userâ€™s query. Query expansion operators might generate multiple versions of a query to improve retrieval coverage, while query transformation operators can rewrite or adjust queries to better align with the systemâ€™s retrieval capabilities. This step is vital for improving the accuracy and relevance of the retrieved dataâ€‹.\\nChunk Compression and Selection Operators: After retrieval, the system often needs to manage large volumes of data. Chunk compression operators help reduce the size of the retrieved data without losing important information, making it easier for the generation module to process. Meanwhile, chunk selection operators filter out irrelevant or redundant information, ensuring that only the most pertinent data is used in the final outputâ€‹.\\n\\n3.3 Interplay Between Modules and Operators\\nThe real power of Modular RAG lies in how these modules and operators interact. By breaking down the RAG process into discrete, reconfigurable components, Modular RAG allows for greater flexibility and adaptability. For example, if a particular task requires more detailed retrieval, the orchestration module can prioritize operators that enhance retrieval precision, such as reranking and query transformation operators.\\nMoreover, this modularity facilitates easier updates and maintenance. If a new method for similarity computation becomes available, it can be integrated as a new operator within the existing retrieval module without overhauling the entire system. This ability to adapt and evolve makes Modular RAG a forward-looking approach to handling complex, knowledge-intensive tasks in AIâ€‹\\nSection 4: Common Flow Patterns in Modular RAG\\nThe Modular RAG frameworkâ€™s flexibility and scalability come to life through its ability to support a variety of RAG flow patterns. These patterns determine how different modules and operators interact, allowing the system to adapt to a wide range of tasks and complexities. By breaking free from the traditional linear â€œretrieve-then-generateâ€ model, Modular RAG introduces several innovative patterns that cater to different scenarios.\\n4.1 The Linear Pattern\\n\\nimage source:https://arxiv.org/html/2407.21059v1\\nThe linear pattern is the most straightforward RAG flow, where modules are arranged in a fixed, sequential order. This pattern closely resembles the traditional RAG process but benefits from the modular approach by allowing individual modules to be optimized or replaced without altering the overall flow.\\nFor example, a linear RAG flow might begin with a query expansion module to refine the userâ€™s input, followed by the retrieval module, which fetches the most relevant data chunks. These chunks are then passed through a post-retrieval reranking module to prioritize the most useful information, and finally, the generation module produces the output. This pattern is ideal for tasks where the process can be clearly defined from start to finish without needing dynamic adjustmentsâ€‹.\\n4.2 The Conditional Pattern\\n\\nimage source:https://arxiv.org/html/2407.21059v1\\nThe conditional pattern adds flexibility by allowing the RAG flow to branch based on specific conditions. This means that depending on the nature of the query or the retrieved data, different modules can be activated or bypassed.\\nFor instance, a routing module might analyze a query and determine whether it requires standard retrieval or more complex processing involving additional modules like query rewriting or chunk compression. This pattern is particularly useful for handling diverse queries that may require different levels of processing complexity. The systemâ€™s ability to conditionally route tasks ensures that resources are used efficiently, and the most appropriate processing path is followedâ€‹\\n4.3 The Branching Pattern\\n\\nimage source:https://arxiv.org/html/2407.21059v1\\nIn the branching pattern, multiple RAG processes run in parallel, each handling different aspects of a query or processing different types of data. After each branch completes its task, the results are merged to form a comprehensive final output.\\nThis pattern is especially useful in scenarios where a query might need to pull in information from various sources or when the system needs to explore multiple hypotheses simultaneously. For example, in a multi-faceted query, one branch could focus on retrieving data related to the primary query, while another branch might retrieve background information or context from different data sources. The results from these branches are then combined, providing a richer and more nuanced responseâ€‹.\\n4.4 The Looping Pattern\\n\\nimage source:https://arxiv.org/html/2407.21059v1\\nThe looping pattern introduces iterative processes where the system can revisit earlier steps in the RAG flow to refine its output. This pattern is particularly powerful when dealing with complex queries that require multiple rounds of retrieval and generation to fully address the userâ€™s needs.\\nIn a looping RAG flow, the system might generate an initial response, then evaluate whether additional retrieval is necessary. If the response is incomplete or could benefit from more information, the system loops back to the retrieval module to fetch additional data, which is then incorporated into a revised output. This iterative approach allows the system to gradually build up a more accurate and detailed response, making it well-suited for complex tasks that cannot be fully resolved in a single passâ€‹\\n4.5 Adaptive (Active) Retrieval\\nOne of the most advanced patterns in Modular RAG is adaptive or active retrieval. This pattern allows the system to dynamically decide when and how to perform additional retrieval based on the ongoing generation process.\\nFor example, during the generation phase, the system might encounter a gap in the information that it cannot resolve with the data at hand. Instead of proceeding with an incomplete response, the system can trigger a new round of retrieval, fetching the necessary data to fill in the gaps before continuing with the generation. This adaptability ensures that the system can handle unexpected complexities and provide more accurate and relevant outputsâ€‹\\n4.6 Fusion and Integration Patterns\\nFinally, the fusion pattern is crucial for integrating multiple branches or different types of data into a single, cohesive output. After data from various branches or retrieval rounds has been processed, the fusion module merges these results, ensuring that the final output is both comprehensive and coherent.\\nFor instance, in a scenario where a query has been processed by several parallel branches, each focusing on different aspects of the query, the fusion module would combine the results from these branches, eliminating redundancies and resolving any conflicts to present a unified response. This pattern is essential for complex queries that require a broad range of information to be synthesized into a single, actionable outputâ€‹.\\n4.7 Choosing the Right Pattern\\nThe choice of pattern in Modular RAG depends on the specific needs of the task at hand. Simple tasks may benefit from the linear pattern, while more complex scenarios might require conditional branching, looping, or adaptive retrieval. The modular nature of the framework means that different patterns can be combined or adjusted as needed, providing a tailored approach that maximizes efficiency and effectiveness in handling diverse queries.\\nSection 5: Tuning Patterns in Modular RAG\\nAs Retrieval-Augmented Generation (RAG) systems become increasingly complex and diverse, fine-tuning the individual components â€” such as retrievers and generators â€” has become essential for optimizing performance. The Modular RAG framework embraces this need through various tuning patterns that enhance the systemâ€™s ability to adapt to specific tasks and datasets. These tuning patterns focus on refining the systemâ€™s components to achieve better alignment, accuracy, and efficiency.\\n5.1 Retriever Fine-Tuning\\n\\nimage source:https://arxiv.org/html/2407.21059v1\\nThe retriever is a crucial component in any RAG system, responsible for selecting the most relevant data chunks from a vast repository based on the userâ€™s query. Fine-tuning the retriever is essential to improve retrieval accuracy, particularly when dealing with specialized domains or tasks that require a deep understanding of nuanced information.\\nSeveral methods are employed for retriever fine-tuning within the Modular RAG framework:\\n\\nSupervised Fine-Tuning (SFT): This involves training the retriever using a labeled dataset specific to the domain or task at hand. By reducing the distance between positive samples (relevant chunks) and increasing the distance from negative samples (irrelevant chunks), SFT enhances the retrieverâ€™s ability to distinguish between valuable and non-valuable informationâ€‹.\\nLM-Supervised Retrieval (LSR): In this approach, the retriever is fine-tuned based on feedback from a language model (LM). The LM generates supervisory signals during the RAG process, guiding the retriever to prioritize chunks that are most likely to contribute to a high-quality final outputâ€‹.\\nAdapter Modules: Sometimes, fine-tuning large retrievers directly can be resource-intensive. Instead, adding an adapter module â€” a smaller, trainable component â€” can enhance the retrieverâ€™s performance with less computational overhead. This approach is particularly useful when dealing with domain-specific tasks where full retriever fine-tuning may not be feasibleâ€‹.\\n\\n5.2 Generator Fine-Tuning\\n\\nimage source:https://arxiv.org/html/2407.21059v1\\nThe generator, which produces the final output based on the retrieved data, also benefits from fine-tuning. Fine-tuning the generator helps align its outputs with the specific requirements of the task, whether itâ€™s generating text that follows a particular style or ensuring that the content is factually accurate.\\nKey methods for generator fine-tuning in Modular RAG include:\\n\\nInstruct-Tuning: This method involves fine-tuning the generator using domain-specific datasets or task-specific instructions. By providing additional knowledge or adjusting the input-output formats, instruct-tuning ensures that the generator produces outputs that are better suited to the taskâ€™s needsâ€‹.\\nReinforcement Learning from Human or LM Feedback (RLHF): This approach uses reinforcement learning to align the generatorâ€™s outputs with human preferences or feedback from a more advanced language model. By iteratively refining the generator based on feedback, this method ensures that the final outputs are not only accurate but also aligned with desired quality standardsâ€‹.\\nDual Fine-Tuning: In some scenarios, itâ€™s beneficial to fine-tune both the retriever and the generator simultaneously. This approach ensures that both components are aligned in terms of their preferences and outputs, leading to a more cohesive and effective RAG system. A typical method involves aligning the scoring functions between the retriever and the generator using techniques like KL-Divergence, ensuring that both components are working towards the same goalâ€‹\\n\\n5.3 Benefits of Tuning Patterns in Modular RAG\\nThe tuning patterns in Modular RAG offer several advantages:\\n\\nImproved Accuracy: By fine-tuning the retriever and generator, the system can more accurately match queries with relevant data and produce higher-quality outputs. This is especially important in specialized domains where precision is criticalâ€‹.\\nTask-Specific Optimization: Tuning allows the system to be customized for specific tasks, ensuring that both the retrieval and generation processes are tailored to the unique requirements of each application. This results in more relevant and useful outputsâ€‹.\\nEnhanced System Cohesion: Dual fine-tuning ensures that the retriever and generator are well-aligned, reducing the likelihood of disjointed or incoherent outputs. This leads to a more seamless and integrated RAG systemâ€‹.\\n\\n5.4 Application of Tuning Patterns\\nThe choice of tuning pattern depends on the specific needs of the task. For instance, if the task involves handling highly specialized queries, supervised fine-tuning of the retriever may be necessary. If the goal is to produce outputs that adhere to specific stylistic or factual standards, instruct-tuning or RLHF for the generator might be more appropriate.\\nIn some cases, a combination of these tuning methods may be required. For example, a RAG system deployed in a legal context might use supervised fine-tuning to enhance the retrieverâ€™s ability to identify relevant case law, while also applying instruct-tuning to ensure that the generated legal summaries are accurate and appropriately formatted.\\nSection 6: Challenges and Opportunities in Modular RAG\\nAs promising as the Modular RAG framework is, implementing it effectively in real-world scenarios comes with its own set of challenges. However, these challenges also present unique opportunities for innovation and further development in the field of Retrieval-Augmented Generation.\\n6.1 Challenges in Implementing Modular RAG\\n\\nComplex Data Integration: One of the primary challenges in Modular RAG is integrating complex and diverse data sources. Traditional RAG systems often rely on a single type of unstructured text data, but Modular RAG expands this to include semi-structured data like tables and structured data such as knowledge graphs. Managing these different data types and ensuring seamless integration within the RAG system can be difficult, requiring sophisticated data processing and retrieval strategiesâ€‹(modular rag paper).\\nSystem Orchestration and Workflow Management: The modularity of the RAG framework introduces a new layer of complexity in orchestrating and managing workflows. Unlike traditional linear RAG systems, Modular RAG involves routing, scheduling, and decision-making processes that require precise control over how modules interact. Designing an effective orchestration module that can dynamically adjust workflows based on the taskâ€™s requirements is critical, but also challengingâ€‹.\\nComponent Selection and Optimization: With the introduction of multiple modules and operators, selecting the right components for a specific task becomes crucial. Each module or operator must be optimized not only to perform well individually but also to work efficiently with other components in the system. Ensuring that these components are well-integrated and collectively enhance system performance requires careful design and continuous optimization.\\nMaintenance and Debugging: As Modular RAG systems grow in complexity, maintaining and debugging them can become more difficult. Isolating issues within a highly modular system requires sophisticated monitoring and diagnostic tools that can pinpoint problems at the module or operator level. Additionally, as new modules or operators are added, ensuring compatibility and maintaining system stability becomes an ongoing challengeâ€‹.\\n\\n6.2 Opportunities for Innovation in Modular RAG\\n\\nScalability and Flexibility: The modular nature of RAG systems offers significant opportunities for scalability. As tasks become more complex or as new data sources become available, additional modules or operators can be introduced without overhauling the entire system. This flexibility allows Modular RAG to scale with the growing demands of AI applications, making it a future-proof solutionâ€‹.\\nEnhanced Personalization and Customization: Modular RAG allows for highly personalized and customized solutions tailored to specific use cases. By selecting and configuring modules to meet the unique needs of a task or domain, developers can create RAG systems that are more effective and efficient than one-size-fits-all solutions. This customization potential opens up new avenues for specialized applications in fields like healthcare, finance, and lawâ€‹.\\nInnovation in Operator Design: The introduction of operators as basic functional units within modules provides a fertile ground for innovation. New operators can be developed to handle emerging challenges in data retrieval and generation, such as handling more complex queries, improving the accuracy of embeddings, or optimizing query transformation. As the field of AI evolves, the ability to innovate at the operator level ensures that Modular RAG remains at the cutting edge of technologyâ€‹.\\nIntegration with Emerging Technologies: Modular RAGâ€™s compatibility with emerging technologies such as knowledge graphs, reinforcement learning, and adaptive retrieval processes offers significant opportunities for advancement. By integrating these technologies into the RAG framework, developers can create more intelligent and adaptive systems that can better handle the complexities of real-world applicationsâ€‹.\\nResearch and Development: The modular approach of RAG systems encourages experimentation and research, particularly in optimizing the interaction between modules and operators. Researchers can explore new configurations, develop novel algorithms for specific modules, and refine orchestration strategies to push the boundaries of what RAG systems can achieve. This opens up vast opportunities for academic research and industry innovationâ€‹.\\n\\nConclusion\\nModular RAG represents a significant leap forward in the evolution of Retrieval-Augmented Generation systems. By breaking down complex processes into independent, reconfigurable modules and operators, it offers unparalleled flexibility, scalability, and adaptability. While challenges such as data integration, workflow orchestration, and system maintenance present obstacles, they also pave the way for innovation. As AI continues to advance, Modular RAG provides a robust framework that is well-equipped to meet the growing demands of knowledge-intensive tasks, making it a key player in the future of AI-driven solutions.\\nReferences:\\n\\nGao, Yunfan, et al. â€œModular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks.â€ arXiv preprint arXiv:2407.21059 (2024).\\nhttps://medium.com/@yufan1602/modular-rag-and-rag-flow-part-%E2%85%B0-e69b32dc13a3\\n\\n\\nSign up to discover human stories that deepen your understanding of the world.\\nFree\\nDistraction-free reading. No ads.\\nOrganize your knowledge with lists and highlights.\\nTell your story. Find your audience.\\nSign up for free\\nMembership\\nRead member-only stories\\nSupport writers you read most\\nEarn money for your writing\\nListen to audio narrations\\nRead offline with the Medium app\\nTry for $5/month\\nArtificial Intelligence\\nLlm\\nAI\\nChatGPT\\nNLP\\n\\n--\\n\\n--\\n1\\n\\n\\nFollow\\n\\nWritten by Sahin Ahmed, Data Scientist --------------------------------------\\n324 Followers\\nData Scientist | MSc Data science|Lifelong Learner | Making an Impact through Data Science | Machine Learning| Deep Learning |NLP| Statistical Modeling\\nFollow\\n\\nHelp\\nStatus\\nAbout\\nCareers\\nPress\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams\"}, {\"title\": \"How does Modular RAG improve upon Naive RAG?\", \"url\": \"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\", \"content\": \"Modular RAG. Modular RAG introduces a more sophisticated and flexible approach to Retrieval-Augmented Generation. By adopting a modular architecture, this version of RAG allows for the independent development and integration of various components, each responsible for specific tasks. The core components of Modular RAG typically include:\", \"score\": 0.6364215, \"raw_content\": \"How does Modular RAG improve upon Naive RAG? - Association of Data Scientists\\nSkip to content\\n\\n\\n\\nMemberships Close Memberships Open Memberships\\n\\nIndividual Membership\\nJoin the worldâ€™s leading Data Science professional community. You can access both General & Premium Memberships.\\nLearn More\\n\\nCorporate Membership\\nAny corporate, organization or academic institution having common interests in the AI field can become a member of ADaSci.\\nLearn More\\n\\n\\nAccreditations Close Accreditations Open Accreditations\\nChartered Data Scientistâ„¢\\nThe Chartered Data Scientist (CDS) credential gives a strong understanding of advanced data science profession and in-depth, applied analytics skills.\\nLearn More\\nCertified Data Scientist - Associate Level\\nBest suitable for the aspirants who want to start their career in the data science field, this certification.\\nLearn More\\nCertified Generative AI Engineer\\nAn upskilling-linked certification initiative designed to recognize talent in generative AI and large language models.\\nLearn More\\n\\n\\nContinuous Learning Close Continuous Learning Open Continuous Learning\\nOur Latest Courses\\n\\nBuilding Generative AI Applications with Amazon Bedrock\\nâ‚¹5,191.00\\nAdd to cart\\n\\nMastering Prompt Engineering for LLMs\\nâ‚¹5,191.00\\nAdd to cart\\n\\nThe LLMops : Streamlining the GenAI & LLM Operations\\nâ‚¹3,460.00\\nAdd to cart\\n\\nMastering Feature Engineering Essentials\\nâ‚¹2,163.00\\nAdd to cart\\nHi, Welcome back!\\nKeep me signed in\\nForgot?\\nSign In\\nDon't have an account?Â  Register Now\\nAccess all Courses\\n\\n\\nCorporate Trainings\\n\\n\\nContact\\n\\n\\nâ‚¹0.00 0 Cart\\nMembers Area\\n\\nDeep Dives\\n\\nHow does Modular RAG improve upon Naive RAG?\\nModular RAG enhances flexibility, scalability, and accuracy compared to Naive RAG.\\n\\nBy Sourabh Mehta\\nPublished on August 5, 2024\\n\\n\\nExplore more from ADaSci\\nGenerative AI Through the Lens of an AI Scientist: Navigating the Technological Tsunami\\nMastering Lightweight AI with Falcon 3 : A Hands-On Guide\\nA Guide to Running LLMs Locally with No-Code Framework Dify\\nLLMFlows for Building Flow-Based Chat Application: A Hands-on Guide\\nBreast cancer histopathological images classification using deep learning\\nCode Search with Vector Embeddings using Qdrant Vector Database\\nQuarkus: Java Development for Modern Applications.\\nImplementing RAG Pipelines using LightRAG and GPT-4o mini\\nColpali: Hands-On Guide to PDF Analysis with Qwen2VL\\nModelling Approach for enhanced market expansion in Digital Marketing in B2B space\\nRetrieval-augmented generation (RAG) has emerged as a powerful technique that combines the strengths of information retrieval and natural language generation. However, not all RAG implementations are created equal. The traditional or â€œNaiveâ€ RAG, while groundbreaking, often struggles with limitations such as inflexibility and inefficiencies in handling diverse and dynamic datasets. Enter Modular RAGâ€”a sophisticated, next-generation approach that significantly enhances the capabilities of Naive RAG by introducing modularity and flexibility into the system.\\nTable of content\\n\\nOverview of Naive RAG and Modular RAG\\nLimitations of Naive RAG\\nWhat is Modular RAG?\\nCase Study: Customer Support Chatbot\\n\\nLetâ€™s start with an overview of Navie and Modular RAG followed by limitations and benefits.\\nOverview of Naive RAG and Modular RAG\\nRetrieval-Augmented Generation (RAG) represents a significant advancement in the field of artificial intelligence by combining the strengths of information retrieval and natural language generation. This hybrid approach leverages vast external knowledge sources to enhance the generation capabilities of models like GPT-4, resulting in more accurate and contextually relevant outputs.\\nNaive RAG\\nNaive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. This method involves two main steps:\\n\\nRetrieval: The system retrieves a set of relevant documents or passages from a predefined database based on the input query.\\nGeneration: Using the retrieved information, the generative model produces a response that is informed by external knowledge.\\n\\nWhile Naive RAG marked a breakthrough in enhancing the capabilities of generative models by providing them access to extensive external knowledge, it has its limitations. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. Additionally, customization and scalability can be challenging, limiting its effectiveness in diverse and dynamic environments.\\nModular RAG\\nModular RAG introduces a more sophisticated and flexible approach to Retrieval-Augmented Generation. By adopting a modular architecture, this version of RAG allows for the independent development and integration of various components, each responsible for specific tasks. The core components of Modular RAG typically include:\\n\\nCustomizable Retrievers: Advanced retrieval mechanisms that can be tailored to specific use cases, allowing for more efficient and relevant information retrieval.\\nAdaptive Generators: Generative models that can seamlessly integrate with different retrievers, enhancing the overall performance and accuracy.\\nPlug-and-Play Modules: Additional components that can be easily added or replaced, providing greater flexibility and adaptability to changing requirements.\\n\\nThe modular design of this RAG variant addresses many of the shortcomings of Naive RAG. It enables more efficient retrieval processes, better integration with generative models, and the ability to customize and scale the system according to specific needs. As a result, Modular RAG offers significant improvements in performance, accuracy, and flexibility, making it a more robust solution for a wide range of applications.\\nLimitations of Naive RAG\\nWhile Naive Retrieval-Augmented Generation (RAG) brought significant advancements by combining retrieval and generation, it also presents several limitations that restrict its effectiveness and efficiency. Understanding these limitations is crucial to appreciate the improvements brought by Modular RAG.\\nInflexibility and Static Nature\\nOne of the primary drawbacks of Naive RAG is its inflexibility. The retrieval component in Naive RAG is often designed to follow a static approach, retrieving information based on predefined rules or simplistic algorithms. This rigidity can lead to several issues:\\n\\nLimited Adaptability: Naive RAG struggles to adapt to new or evolving information needs, making it less effective in dynamic environments where the context or required information may change rapidly.\\nSuboptimal Responses: The static retrieval mechanism may not always retrieve the most relevant or up-to-date information, leading to generative outputs that are less accurate or contextually appropriate.\\n\\nInefficiencies in Retrieval Processes\\nThe retrieval process in Naive RAG can be inefficient due to its reliance on basic retrieval strategies. These inefficiencies manifest in several ways:\\nHigh Latency: The process of retrieving and integrating external information can introduce significant latency, slowing down the overall response time.\\nResource Intensity: Basic retrieval methods may require extensive computational resources, especially when dealing with large datasets, making the system less scalable and more costly to operate.\\nRelevance Issues: The simplicity of the retrieval algorithms can lead to the retrieval of irrelevant or low-quality information, which negatively impacts the quality of the generated responses.\\nChallenges in Customization and Integration\\nNaive RAG systems often face difficulties in customization and integration, limiting their utility across diverse applications:\\n\\nLack of Custom Modules: The rigid architecture of Naive RAG makes it challenging to incorporate custom modules tailored to specific tasks or industries. This lack of customization restricts the applicability of the system to more generalized use cases.\\nIntegration Problems: Integrating Naive RAG with other systems or technologies can be cumbersome, as the tightly coupled components are not designed for seamless interoperability. This can hinder the ability to leverage complementary technologies or data sources.\\n\\nScalability Constraints\\nAs data and usage grow, scalability becomes a critical concern for Naive RAG:\\n\\nPerformance Degradation: As the volume of data increases, the performance of Naive RAG systems can degrade significantly. The static nature of the retrieval process struggles to maintain efficiency with growing datasets.\\nLimited Parallelism: The monolithic design of Naive RAG often limits its ability to parallelize tasks effectively, further impacting scalability and performance.\\n\\nWhat is Modular RAG?\\nModular Retrieval-Augmented Generation (RAG) represents an evolution in the design and implementation of RAG systems. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. In this section, we will delve into the core concepts, key components, and benefits of Modular RAG.\\nModular RAG is an advanced form of Retrieval-Augmented Generation that leverages a modular design to separate and optimize various components of the system. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. This modularity allows for:\\n\\nIndependent Development: Each module can be developed and improved independently, enabling rapid innovation and iteration.\\nCustomizability: Modules can be tailored to specific tasks, industries, or use cases, providing greater versatility.\\nInteroperability: Modular components can be easily integrated with other systems or technologies, enhancing overall functionality.\\n\\nKey Components and Architecture\\nThe architecture of Modular RAG typically comprises several key components, each responsible for a specific function. These components include:\\nCustomizable Retrievers\\n\\nAdvanced Retrieval Mechanisms: Unlike the static retrieval strategies of Naive RAG, Modular RAG employs sophisticated algorithms such as hybrid search (combining keyword and semantic search) and machine learning-based retrieval. This results in more accurate and relevant information retrieval.\\nDynamic Adaptation: Retrievers can adapt to changing data and requirements, ensuring that the most pertinent information is always accessible.\\n\\nAdaptive Generators\\n\\nSeamless Integration: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\\nContextual Awareness: These generators can better understand and incorporate the context provided by retrieved information, leading to more accurate and meaningful outputs.\\n\\nPlug-and-Play Modules\\n\\nEase of Customization: Modular RAG supports the addition and replacement of modules without disrupting the overall system. This allows for easy customization based on specific needs or improvements in technology.\\nScalability: The plug-and-play nature of the modules ensures that the system can scale efficiently, handling increasing volumes of data and user interactions.\\n\\nOrchestration Layer\\nAn orchestration layer manages the interactions between different modules, ensuring smooth communication and data flow. This layer optimizes the overall performance and maintains system coherence.\\n\\nImage Source\\nCase Study: Customer Support Chatbot\\nA large e-commerce company implements a customer support chatbot to handle frequently asked questions and support queries. Initially, the company used Naive RAG and later transitioned to Modular RAG to improve performance.\\nKey Metrics for Comparison:\\n\\nResponse Relevance\\nResponse Time\\nScalability\\nCustomer Satisfaction\\n\\nResponse Relevance\\n\\nResponse Time\\n\\nScalability\\n\\nCustomer Satisfaction\\n\\nThe consolidated table demonstrates that Modular RAG outperforms Naive RAG across all key metrics, making it a more effective and reliable solution for customer support chatbots. By adopting a modular approach, organizations can achieve better relevance, faster response times, greater scalability, and higher customer satisfaction.\\nConclusion\\nModular RAG, with its advanced architecture and dynamic components, addresses these challenges head-on. By allowing for independent development, customization, and seamless integration of various modules, Modular RAG provides a more robust, efficient, and scalable solution. This is evident in key metrics such as response relevance, response time, scalability, and customer satisfaction.\\nReferences\\n\\nPrompt Engineering Guide\\n\\n\\nSourabh Mehta\\nThe Chartered Data Scientist Designation\\nAchieve the highest distinction in the data science profession.\\nRegister\\nElevate Your Team's AI Skills with our Proven Training Programs\\nStrengthen Critical AI Skills with Trusted Generative AI Training by Association of Data Scientists.\\nFind Out More\\nOur AI Courses\\nVisit AI Academy\\n\\n\\n Generative AI-Powered Software Engineering with AI Coding Assistants -------------------------------------------------------------------- â‚¹5,191.00\\nAdd to cart\\n\\n\\n Building Knowledge Graph Solutions with LangGraph ------------------------------------------------- â‚¹3,028.00\\nAdd to cart\\n\\n\\n Generative AI Application Development with Azure ------------------------------------------------ â‚¹5,191.00\\nAdd to cart\\n\\n\\nOur Accreditations\\nGet global recognition for AI skills\\n\\nChartered Data Scientist (CDSâ„¢)\\nThe highest distinction in the data science profession. Not just earn a charter, but use it as a designation.\\nLearn more\\n\\nCertified Data Scientist - Associate Level\\nGlobal recognition of data science skills at the beginner level.\\nLearn more\\n\\nCertified Generative AI Engineer\\nAn upskilling-linked certification initiative designed to recognize talent in generative AI and large language models\\nLearn more\\nJoin thousands of members and receive all benefits.\\nBecome Our Member\\nWe offer both Individual & Institutional Membership.\\nFind out more\\nNot a member, but still want to know what we are upto? Subscribe to our Newsletter\\nEmail \\nStart Free Trial\\nThe power of intelligence to propel humanity and make a difference\\nOur Accrediations\\n\\nChartered Data Scientistâ„¢ (CDS)\\nCertified Data Scientist - Associate Level\\nCertified Generative AI Engineer\\n\\nCDS Program\\n\\nAbout CDS\\nExam Information\\nCandidate Body of Knowledge (CBOK)\\nExam Structure\\nExam Cost and Registration Fees\\nEthical & Standards for Chartered Data Scientists (CDS)\\nHow to Earn the CDS Charter\\nTerms & Conditions For CDSâ„¢\\n\\nMembership\\n\\nIndividual Membership\\nInstitutional Membership\\n\\nAbout\\n\\nAbout ADaSci\\nContinuous Learning\\nTeam\\nPrivacy Policy\\nTerms and Conditions\\nChapters\\nBlogs\\nContact\\n\\nFor Organizations\\n\\nCorporate Trainings\\nCDS for Organizations\\nCorporate Membership\\n\\nJournal\\n\\nLattice\\nAbout\\nReview Committee\\n\\nTwitter Facebook-f Linkedin\\nÂ© 2024 All rights reserved Association of Data Scientists\\n\\nWe noticed you're visiting from India. We've updated our prices to Indian rupee for your shopping convenience. Use United States (US) dollar instead. Dismiss\"}, {\"title\": \"Modular Rag in Multi-Agent Systems - Restackio\", \"url\": \"https://www.restack.io/p/multi-agent-systems-answer-modular-rag-cat-ai\", \"content\": \"Explore the role of modular rag in enhancing the efficiency of multi-agent systems through structured interactions. The Modular RAG framework introduces additional specialized components to enhance retrieval and processing capabilities: By utilizing the Modular RAG framework, developers can create more robust and adaptable systems that meet the evolving demands of data retrieval and processing. Multimodal Retrieval-Augmented Generation (MM-RAG) represents a significant advancement in the capabilities of language models by integrating both text and image retrieval into the generation process. This approach enhances the traditional Retrieval-Augmented Generation (RAG) by allowing models to utilize a broader range of data types, thereby improving the quality and relevance of generated outputs. The Modular RAG framework is designed to allow for module substitution or reconfiguration, addressing specific challenges in retrieval and processing.\", \"score\": 0.59344494, \"raw_content\": \"Modular Rag in Multi-Agent Systems | Restackio\\nRestack\\nDocsSign up\\nOpen menu\\nDocsUse casesPricingCompanyEnterpriseContactCommunity\\n\\nLog inSign up\\n\\nMulti-Agent Systems/\\n\\nModular Rag in Multi-Agent Systems\\n\\n\\nMulti-Agent Systems\\n\\n\\nModular Rag in Multi-Agent Systems\\nLast updated on 12/17/24\\nExplore the role of modular rag in enhancing the efficiency of multi-agent systems through structured interactions.\\nOn this page\\n\\nUnderstanding Modular RAG Framework\\nAdvantages of Multimodal Retrieval-Augmented Generation\\nImplementing Modular RAG in Real-World Applications\\n\\nSources\\n github.com griptape-ai/griptape/dev/docs/griptape-tools/official-tools/structure-run-tool.md arxiv.org Retrieval-Augmented Generation for Large Language Models: A Survey\\nUnderstanding Modular RAG Framework -----------------------------------\\nModular Retrieval-Augmented Generation (RAG) is an advanced approach that enhances adaptability and versatility beyond traditional RAG paradigms. This framework incorporates diverse strategies to improve its components by adding specialized modules for retrieval and processing capabilities.\\nNew Modules\\nThe Modular RAG framework introduces additional specialized components to enhance retrieval and processing capabilities:\\n\\nSearch Module: Adapts to specific scenarios, enabling direct searches across various data sources like search engines, databases, and knowledge graphs. It utilizes LLM-generated code and query languages to optimize search efficiency.\\nRAG-Fusion: Addresses traditional search limitations by employing a multi-query strategy. This strategy expands user queries into diverse perspectives, utilizing parallel vector searches and intelligent re-ranking to uncover both explicit and transformative knowledge.\\nMemory Module: Leverages the LLMâ€™s memory to guide retrieval, creating an unbounded memory pool that enhances the system's ability to recall and utilize past interactions effectively.\\n\\nProcessing Flexibility\\nThe Modular RAG framework allows for module substitution or reconfiguration to address specific challenges. This flexibility is crucial for integrating new modules or adjusting the interaction flow among existing ones. The framework supports both sequential processing and integrated end-to-end training across its components, illustrating progression and refinement within the RAG family.\\nConclusion\\nBy utilizing the Modular RAG framework, developers can create more robust and adaptable systems that meet the evolving demands of data retrieval and processing. This approach not only enhances the capabilities of RAG but also ensures that it remains relevant in a rapidly changing technological landscape.\\nRelated answers\\n\\nMulti-Agent Systems Foundations Explore the algorithmic game-theoretic and logical foundations of multi-agent systems, enhancing understanding and application.\\nJade For Multi-Agent Systems Explore how Jade enhances multi-agent systems, facilitating communication and coordination among agents effectively.\\nMulti-Agent Systems Llm Overview Explore the intricacies of multi-agent systems and their applications in LLM technology, enhancing collaboration and efficiency.\\n\\nBuildReplayFunctions\\nRestack AI SDK\\nThe framework for autonomous intelligence\\nBuild autonomous AI products in code, capable of running and persisting month-lasting processes in the background.\\nLearn more ->\\n\\nSources\\n arxiv.org Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks weaviate.io weaviate.io\\nAdvantages of Multimodal Retrieval-Augmented Generation -------------------------------------------------------\\nMultimodal Retrieval-Augmented Generation (MM-RAG) represents a significant advancement in the capabilities of language models by integrating both text and image retrieval into the generation process. This approach enhances the traditional Retrieval-Augmented Generation (RAG) by allowing models to utilize a broader range of data types, thereby improving the quality and relevance of generated outputs.\\nKey Advantages of MM-RAG\\n\\nScalability: MM-RAG reduces the model size and training costs while enabling easy expansion of knowledge. By leveraging external knowledge bases, it allows for the integration of new information without the need for extensive retraining.\\nAccuracy: By grounding the model in factual data, MM-RAG minimizes the risk of hallucinations, ensuring that the generated content is more reliable and contextually appropriate.\\nControllability: Users can easily update or customize the knowledge base through simple CRUD operations in a vector database, allowing for dynamic adjustments to the model's knowledge.\\nInterpretability: The retrieved items serve as references for the model's predictions, providing transparency and a basis for understanding the generated outputs.\\n\\nEnhanced Performance Metrics\\nRecent studies have shown that MM-RAG significantly outperforms baseline multimodal models such as DALL-E and CM3 in various tasks, including:\\n\\nImage and Caption Generation: MM-RAG excels in generating high-quality images and captions that are closely aligned with the retrieved context.\\nComputational Efficiency: It requires substantially less computational power, achieving performance with less than 30% of the resources needed for DALL-E.\\nContextual Fidelity: The images generated by MM-RAG are more faithful to the context from which they were retrieved, enhancing the overall quality of the outputs.\\nIn-Context Learning: MM-RAG supports multimodal in-context learning, allowing the model to generate images based on demonstration images and text, thus adapting to the visual characteristics of the input data.\\n\\nConclusion\\nThe integration of multimodal capabilities into retrieval-augmented generation systems marks a pivotal shift in how we can utilize large language models. By effectively combining text and image data, MM-RAG not only enhances the generative capabilities of these models but also opens up new avenues for applications across various industries, making it a powerful tool for developers and researchers alike.\\nRelated answers\\n\\nWhat Is Multi Level Planning in Multi-Agent Systems Explore the concept of multi-level planning in multi-agent systems, focusing on its structure and applications in complex environments.\\nMulti-Agent Systems for Complex Problem Solving Explore how multi-agent AI systems tackle complex problems through collaboration and intelligent decision-making.\\nMulti-Agent Systems And Multi-Linguality Explore how multi-agent systems enhance multi-linguality, enabling seamless communication across diverse languages and cultures.\\n\\nSources\\n github.com griptape-ai/griptape/dev/docs/griptape-tools/official-tools/structure-run-tool.md weaviate.io\\nImplementing Modular RAG in Real-World Applications ---------------------------------------------------\\nModular Retrieval-Augmented Generation (RAG) is an advanced approach that enhances traditional RAG paradigms by offering improved adaptability and versatility. This framework incorporates various strategies to enhance its components through the addition of specialized modules for retrieval and processing capabilities.\\nCore Components of Modular RAG\\nThe Modular RAG framework is designed to allow for module substitution or reconfiguration, addressing specific challenges in retrieval and processing. This flexibility is crucial for integrating new modules or adjusting the interaction flow among existing ones. The core components include:\\n\\nRetrieval Module: Responsible for fetching relevant data from a knowledge base.\\nAugmentation Module: Enhances the retrieved data to improve the quality of the output.\\nGeneration Module: Generates responses based on the augmented data.\\nRewrite and Rerank Modules: These advanced components refine the output further, ensuring higher relevance and accuracy.\\n\\nAdvantages of Modular RAG\\nThe modular approach supports both sequential processing and integrated end-to-end training across its components. This illustrates the progression and refinement within the RAG family, allowing for:\\n\\nAdaptability: Modules can be tailored to specific tasks, enhancing performance.\\nFlexibility: New modules can be integrated seamlessly, allowing for continuous improvement.\\nEfficiency: The ability to reconfigure modules can lead to optimized processing times and resource usage.\\n\\nPractical Applications\\nIn real-world applications, Modular RAG can be utilized in various domains, such as:\\n\\nCustomer Support: By integrating modules that specialize in understanding customer queries and generating accurate responses.\\nContent Creation: Utilizing the generation module to produce high-quality content based on retrieved data.\\nData Analysis: Employing the retrieval and augmentation modules to analyze large datasets effectively.\\n\\nConclusion\\nThe Modular RAG framework represents a significant advancement in the RAG domain, providing a robust structure for developing applications that require sophisticated retrieval and generation capabilities. By leveraging its modular nature, developers can create tailored solutions that meet specific needs while maintaining high performance and adaptability.\\nRelated answers\\n\\nAi Architecture For Multi-Agent Systems Explore the intricacies of AI architecture tailored for multi-agent systems, enhancing collaboration and efficiency in complex environments.\\nOntology Multi-Agent Systems Development Explore the development of ontology multi-agent systems, focusing on design, implementation, and integration techniques.\\nInternational Conference on Multi-Agent Systems Explore the latest advancements in practical applications of agents and multi-agent systems at this international conference.\\n\\nBuildReplayFunctions\\nRestack AI SDK\\nThe framework for autonomous intelligence\\nBuild autonomous AI products in code, capable of running and persisting month-lasting processes in the background.\\nLearn more ->\\n\\nOn this page\\n\\nUnderstanding Modular RAG Framework\\nAdvantages of Multimodal Retrieval-Augmented Generation\\nImplementing Modular RAG in Real-World Applications\\n\\nFooter\\nJoin us to build the framework for autonomous intelligence.\\nFramework\\n\\nDocs\\nExamples\\nUse cases\\n\\nCloud\\n\\nSign up\\nLog in\\nPricing\\n\\nAbout\\n\\nCompany\\nEnterprise\\nContact\\n\\nLegal\\n\\nLegal notice\\nPrivacy\\nTerms\\n\\nABCDEFGHIJKLMNOPQRSTUVWXYZ\"}]\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mexecute\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Modular RAG(ëª¨ë“ˆí˜• RAG)ëŠ” ì „í†µì ì¸ RAG ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë” ìœ ì—°í•˜ê³  íš¨ìœ¨ì ì¸ ì •ë³´ ê²€ìƒ‰ ë° ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ìŒì€ Modular RAGê°€ í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **ìœ ì—°ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´, ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ê°œë°œí•˜ê³  ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„° ìš”êµ¬ì— ë§ê²Œ ì‹œìŠ¤í…œì„ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª¨ë“ˆì´ë‚˜ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•˜ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆì–´, ì‹œìŠ¤í…œì´ ì„±ì¥í•˜ëŠ” ë°ì´í„°ì™€ ìš”êµ¬ì— ë§ì¶° í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ì— ë§¤ìš° ìœ ë¦¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **íš¨ìœ¨ì„±**: ê° ëª¨ë“ˆì´ íŠ¹ì • ì‘ì—…ì— ìµœì í™”ë˜ì–´ ìˆì–´, ì „ì²´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê²€ìƒ‰ ëª¨ë“ˆì€ ë” ì •êµí•œ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ë” ì •í™•í•˜ê²Œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ê°œì„ ëœ ì •í™•ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ ë³µì¡í•œ ì¿¼ë¦¬ë‚˜ ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜•ì„ ì²˜ë¦¬í•  ë•Œ ìœ ë¦¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "5. **ëª¨ë“ˆí™”ëœ ì„¤ê³„**: ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë¯€ë¡œ, íŠ¹ì • ëª¨ë“ˆì— ë¬¸ì œê°€ ë°œìƒí•˜ë”ë¼ë„ ì „ì²´ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìœ ì§€ë³´ìˆ˜ì™€ ë””ë²„ê¹…ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ì ì‘ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ì‘ì—… ìš”êµ¬ì— ë§ì¶° ëª¨ë“ˆì„ ì¬êµ¬ì„±í•˜ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆì–´, ë³€í™”í•˜ëŠ” í™˜ê²½ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ì´ì ë“¤ì€ Modular RAGê°€ ë³µì¡í•œ ì •ë³´ ê²€ìƒ‰ ë° ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ ë§¤ìš° ìœ ìš©í•œ ë„êµ¬ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mexecute\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Modular RAGê°€ production levelì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì„ ì •ë¦¬í•œë‹¤.', 'Modular RAG(ëª¨ë“ˆí˜• RAG)ëŠ” ì „í†µì ì¸ RAG ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë” ìœ ì—°í•˜ê³  íš¨ìœ¨ì ì¸ ì •ë³´ ê²€ìƒ‰ ë° ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ìŒì€ Modular RAGê°€ í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì…ë‹ˆë‹¤:\\n\\n1. **ìœ ì—°ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´, ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ê°œë°œí•˜ê³  ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„° ìš”êµ¬ì— ë§ê²Œ ì‹œìŠ¤í…œì„ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\\n\\n2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª¨ë“ˆì´ë‚˜ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•˜ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆì–´, ì‹œìŠ¤í…œì´ ì„±ì¥í•˜ëŠ” ë°ì´í„°ì™€ ìš”êµ¬ì— ë§ì¶° í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ì— ë§¤ìš° ìœ ë¦¬í•©ë‹ˆë‹¤.\\n\\n3. **íš¨ìœ¨ì„±**: ê° ëª¨ë“ˆì´ íŠ¹ì • ì‘ì—…ì— ìµœì í™”ë˜ì–´ ìˆì–´, ì „ì²´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê²€ìƒ‰ ëª¨ë“ˆì€ ë” ì •êµí•œ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ë” ì •í™•í•˜ê²Œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n4. **ê°œì„ ëœ ì •í™•ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ ë³µì¡í•œ ì¿¼ë¦¬ë‚˜ ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜•ì„ ì²˜ë¦¬í•  ë•Œ ìœ ë¦¬í•©ë‹ˆë‹¤.\\n\\n5. **ëª¨ë“ˆí™”ëœ ì„¤ê³„**: ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë¯€ë¡œ, íŠ¹ì • ëª¨ë“ˆì— ë¬¸ì œê°€ ë°œìƒí•˜ë”ë¼ë„ ì „ì²´ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìœ ì§€ë³´ìˆ˜ì™€ ë””ë²„ê¹…ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.\\n\\n6. **ì ì‘ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ì‘ì—… ìš”êµ¬ì— ë§ì¶° ëª¨ë“ˆì„ ì¬êµ¬ì„±í•˜ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆì–´, ë³€í™”í•˜ëŠ” í™˜ê²½ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\nì´ëŸ¬í•œ ì´ì ë“¤ì€ Modular RAGê°€ ë³µì¡í•œ ì •ë³´ ê²€ìƒ‰ ë° ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ ë§¤ìš° ìœ ìš©í•œ ë„êµ¬ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mreplan\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[94mresponse\u001b[0m:\n",
      "No more steps needed.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mfinal_report\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[94mresponse\u001b[0m:\n",
      "# ìµœì¢… ë³´ê³ ì„œ: Modular RAGì™€ Naive RAGì˜ ë¹„êµ ë° í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œì˜ ì´ì \n",
      "\n",
      "## 1. ì„œë¡ \n",
      "ë³¸ ë³´ê³ ì„œëŠ” Modular RAG(ëª¨ë“ˆí˜• RAG)ì™€ Naive RAG(ë‹¨ìˆœ RAG)ì˜ ì •ì˜, êµ¬ì¡°, ì‘ë™ ë°©ì‹, ì£¼ìš” ì°¨ì´ì  ë° Modular RAGê°€ í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œ ì œê³µí•˜ëŠ” ì´ì ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‘ ì‹œìŠ¤í…œì˜ íŠ¹ì„±ê³¼ Modular RAGì˜ ì¥ì ì„ ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## 2. RAGì˜ ì •ì˜\n",
      "\n",
      "### 2.1 Modular RAG\n",
      "- **ì •ì˜**: Modular RAGëŠ” RAG ì‹œìŠ¤í…œì„ ëª¨ë“ˆí™”í•˜ì—¬ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì¸ êµ¬ì¡°ì…ë‹ˆë‹¤. ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\n",
      "- **íŠ¹ì§•**:\n",
      "  - **ëª¨ë“ˆí™”**: ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì¡°í•©í•˜ì—¬ ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ìœ ì—°ì„±**: í•„ìš”ì— ë”°ë¼ ëª¨ë“ˆì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ í•˜ìœ„ ëª¨ë“ˆì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 2.2 Naive RAG\n",
      "- **ì •ì˜**: Naive RAGëŠ” ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "- **íŠ¹ì§•**:\n",
      "  - **ë‹¨ìˆœì„±**: êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì…ë‹ˆë‹¤.\n",
      "  - **ì •ë³´ ê²€ìƒ‰**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
      "  - **ì‘ë‹µ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 3. êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "\n",
      "### 3.1 Modular RAGì˜ êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "- **êµ¬ì¡°**:\n",
      "  1. **ëª¨ë“ˆí™”ëœ êµ¬ì„± ìš”ì†Œ**: ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆê³¼ ìƒì„± ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
      "  2. **ë°ì´í„° íë¦„**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆì´ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ ë°ì´í„°ë¥¼ ìƒì„± ëª¨ë“ˆì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "- **ì‘ë™ ë°©ì‹**:\n",
      "  1. ì¿¼ë¦¬ ì…ë ¥\n",
      "  2. ì •ë³´ ê²€ìƒ‰\n",
      "  3. ì •ë³´ í•„í„°ë§\n",
      "  4. ì‘ë‹µ ìƒì„±\n",
      "  5. ê²°ê³¼ ì¶œë ¥\n",
      "\n",
      "### 3.2 Naive RAGì˜ êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "- **êµ¬ì¡°**:\n",
      "  1. ì§ˆë¬¸ ì…ë ¥\n",
      "  2. ì •ë³´ ê²€ìƒ‰\n",
      "  3. ë¬¸ì„œ ì„ íƒ\n",
      "  4. ìƒì„± ëª¨ë¸\n",
      "\n",
      "- **ì‘ë™ ë°©ì‹**:\n",
      "  - ê²€ìƒ‰ ë‹¨ê³„ì™€ ìƒì„± ë‹¨ê³„ë¡œ ë‚˜ë‰˜ë©°, ì „í†µì ì¸ ì •ë³´ ê²€ìƒ‰ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 4. ì£¼ìš” ì°¨ì´ì  ë¹„êµ\n",
      "\n",
      "1. **êµ¬ì¡°ì  ìœ ì—°ì„±**: Modular RAGëŠ” ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ì œê³µí•˜ë©°, Naive RAGëŠ” ê³ ì •ëœ êµ¬ì¡°ë¡œ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "2. **ëª¨ë“ˆí™”**: Modular RAGëŠ” ê° ëª¨ë“ˆì´ íŠ¹ì • ì—­í• ì„ ë‹´ë‹¹í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆì§€ë§Œ, Naive RAGëŠ” ë‹¨ì¼ íë¦„ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n",
      "3. **ì„±ëŠ¥ ìµœì í™”**: Modular RAGëŠ” ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆì–´ ì„±ëŠ¥ ê°œì„ ì´ ìš©ì´í•©ë‹ˆë‹¤.\n",
      "4. **ì ì‘ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆëŠ” ë°˜ë©´, Naive RAGëŠ” ì ì‘ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 5. Modular RAGì˜ í”„ë¡œë•ì…˜ ë ˆë²¨ ì´ì \n",
      "\n",
      "1. **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ì‹œìŠ¤í…œì„ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª¨ë“ˆì´ë‚˜ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•˜ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "3. **íš¨ìœ¨ì„±**: ê° ëª¨ë“ˆì´ íŠ¹ì • ì‘ì—…ì— ìµœì í™”ë˜ì–´ ì „ì²´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
      "4. **ê°œì„ ëœ ì •í™•ì„±**: ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "5. **ëª¨ë“ˆí™”ëœ ì„¤ê³„**: íŠ¹ì • ëª¨ë“ˆì— ë¬¸ì œê°€ ë°œìƒí•˜ë”ë¼ë„ ì „ì²´ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "6. **ì ì‘ì„±**: ë³€í™”í•˜ëŠ” í™˜ê²½ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## 6. ê²°ë¡ \n",
      "Modular RAGëŠ” Naive RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ ì œê³µí•˜ëŠ” ì •ë³´ ê²€ìƒ‰ ë° ìƒì„± ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì„± ë•ë¶„ì— Modular RAGëŠ” ë‹¤ì–‘í•œ AI ì‘ìš© í”„ë¡œê·¸ë¨ì— ì í•©í•œ ì†”ë£¨ì…˜ìœ¼ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_print import invoke_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=50, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "inputs = {\n",
    "    \"input\": \"Modular RAG ê°€ ê¸°ì¡´ì˜ Naive RAG ì™€ ì–´ë–¤ ì°¨ì´ê°€ ìˆëŠ”ì§€ì™€ production level ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ì„ ì„¤ëª…í•´ì¤˜\"\n",
    "}\n",
    "\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ìµœì¢… ë³´ê³ ì„œ: Modular RAGì™€ Naive RAGì˜ ë¹„êµ ë° í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œì˜ ì´ì \n",
      "\n",
      "## 1. ì„œë¡ \n",
      "ë³¸ ë³´ê³ ì„œëŠ” Modular RAG(ëª¨ë“ˆí˜• RAG)ì™€ Naive RAG(ë‹¨ìˆœ RAG)ì˜ ì •ì˜, êµ¬ì¡°, ì‘ë™ ë°©ì‹, ì£¼ìš” ì°¨ì´ì  ë° Modular RAGê°€ í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œ ì œê³µí•˜ëŠ” ì´ì ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‘ ì‹œìŠ¤í…œì˜ íŠ¹ì„±ê³¼ Modular RAGì˜ ì¥ì ì„ ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## 2. RAGì˜ ì •ì˜\n",
      "\n",
      "### 2.1 Modular RAG\n",
      "- **ì •ì˜**: Modular RAGëŠ” RAG ì‹œìŠ¤í…œì„ ëª¨ë“ˆí™”í•˜ì—¬ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì¸ êµ¬ì¡°ì…ë‹ˆë‹¤. ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\n",
      "- **íŠ¹ì§•**:\n",
      "  - **ëª¨ë“ˆí™”**: ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì¡°í•©í•˜ì—¬ ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ìœ ì—°ì„±**: í•„ìš”ì— ë”°ë¼ ëª¨ë“ˆì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ í•˜ìœ„ ëª¨ë“ˆì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 2.2 Naive RAG\n",
      "- **ì •ì˜**: Naive RAGëŠ” ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "- **íŠ¹ì§•**:\n",
      "  - **ë‹¨ìˆœì„±**: êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì…ë‹ˆë‹¤.\n",
      "  - **ì •ë³´ ê²€ìƒ‰**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
      "  - **ì‘ë‹µ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 3. êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "\n",
      "### 3.1 Modular RAGì˜ êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "- **êµ¬ì¡°**:\n",
      "  1. **ëª¨ë“ˆí™”ëœ êµ¬ì„± ìš”ì†Œ**: ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆê³¼ ìƒì„± ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
      "  2. **ë°ì´í„° íë¦„**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆì´ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ ë°ì´í„°ë¥¼ ìƒì„± ëª¨ë“ˆì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "- **ì‘ë™ ë°©ì‹**:\n",
      "  1. ì¿¼ë¦¬ ì…ë ¥\n",
      "  2. ì •ë³´ ê²€ìƒ‰\n",
      "  3. ì •ë³´ í•„í„°ë§\n",
      "  4. ì‘ë‹µ ìƒì„±\n",
      "  5. ê²°ê³¼ ì¶œë ¥\n",
      "\n",
      "### 3.2 Naive RAGì˜ êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "- **êµ¬ì¡°**:\n",
      "  1. ì§ˆë¬¸ ì…ë ¥\n",
      "  2. ì •ë³´ ê²€ìƒ‰\n",
      "  3. ë¬¸ì„œ ì„ íƒ\n",
      "  4. ìƒì„± ëª¨ë¸\n",
      "\n",
      "- **ì‘ë™ ë°©ì‹**:\n",
      "  - ê²€ìƒ‰ ë‹¨ê³„ì™€ ìƒì„± ë‹¨ê³„ë¡œ ë‚˜ë‰˜ë©°, ì „í†µì ì¸ ì •ë³´ ê²€ìƒ‰ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 4. ì£¼ìš” ì°¨ì´ì  ë¹„êµ\n",
      "\n",
      "1. **êµ¬ì¡°ì  ìœ ì—°ì„±**: Modular RAGëŠ” ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ì œê³µí•˜ë©°, Naive RAGëŠ” ê³ ì •ëœ êµ¬ì¡°ë¡œ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "2. **ëª¨ë“ˆí™”**: Modular RAGëŠ” ê° ëª¨ë“ˆì´ íŠ¹ì • ì—­í• ì„ ë‹´ë‹¹í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆì§€ë§Œ, Naive RAGëŠ” ë‹¨ì¼ íë¦„ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n",
      "3. **ì„±ëŠ¥ ìµœì í™”**: Modular RAGëŠ” ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆì–´ ì„±ëŠ¥ ê°œì„ ì´ ìš©ì´í•©ë‹ˆë‹¤.\n",
      "4. **ì ì‘ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆëŠ” ë°˜ë©´, Naive RAGëŠ” ì ì‘ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 5. Modular RAGì˜ í”„ë¡œë•ì…˜ ë ˆë²¨ ì´ì \n",
      "\n",
      "1. **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ì‹œìŠ¤í…œì„ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª¨ë“ˆì´ë‚˜ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•˜ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "3. **íš¨ìœ¨ì„±**: ê° ëª¨ë“ˆì´ íŠ¹ì • ì‘ì—…ì— ìµœì í™”ë˜ì–´ ì „ì²´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
      "4. **ê°œì„ ëœ ì •í™•ì„±**: ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "5. **ëª¨ë“ˆí™”ëœ ì„¤ê³„**: íŠ¹ì • ëª¨ë“ˆì— ë¬¸ì œê°€ ë°œìƒí•˜ë”ë¼ë„ ì „ì²´ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "6. **ì ì‘ì„±**: ë³€í™”í•˜ëŠ” í™˜ê²½ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## 6. ê²°ë¡ \n",
      "Modular RAGëŠ” Naive RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ ì œê³µí•˜ëŠ” ì •ë³´ ê²€ìƒ‰ ë° ìƒì„± ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì„± ë•ë¶„ì— Modular RAGëŠ” ë‹¤ì–‘í•œ AI ì‘ìš© í”„ë¡œê·¸ë¨ì— ì í•©í•œ ì†”ë£¨ì…˜ìœ¼ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "snapshot = app.get_state(config).values\n",
    "print(snapshot[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ìµœì¢… ë³´ê³ ì„œ: Modular RAGì™€ Naive RAGì˜ ë¹„êµ ë° í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œì˜ ì´ì \n",
       "\n",
       "## 1. ì„œë¡ \n",
       "ë³¸ ë³´ê³ ì„œëŠ” Modular RAG(ëª¨ë“ˆí˜• RAG)ì™€ Naive RAG(ë‹¨ìˆœ RAG)ì˜ ì •ì˜, êµ¬ì¡°, ì‘ë™ ë°©ì‹, ì£¼ìš” ì°¨ì´ì  ë° Modular RAGê°€ í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œ ì œê³µí•˜ëŠ” ì´ì ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‘ ì‹œìŠ¤í…œì˜ íŠ¹ì„±ê³¼ Modular RAGì˜ ì¥ì ì„ ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "## 2. RAGì˜ ì •ì˜\n",
       "\n",
       "### 2.1 Modular RAG\n",
       "- **ì •ì˜**: Modular RAGëŠ” RAG ì‹œìŠ¤í…œì„ ëª¨ë“ˆí™”í•˜ì—¬ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì¸ êµ¬ì¡°ì…ë‹ˆë‹¤. ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\n",
       "- **íŠ¹ì§•**:\n",
       "  - **ëª¨ë“ˆí™”**: ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì¡°í•©í•˜ì—¬ ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "  - **ìœ ì—°ì„±**: í•„ìš”ì— ë”°ë¼ ëª¨ë“ˆì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "  - **ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ í•˜ìœ„ ëª¨ë“ˆì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "### 2.2 Naive RAG\n",
       "- **ì •ì˜**: Naive RAGëŠ” ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
       "- **íŠ¹ì§•**:\n",
       "  - **ë‹¨ìˆœì„±**: êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì…ë‹ˆë‹¤.\n",
       "  - **ì •ë³´ ê²€ìƒ‰**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
       "  - **ì‘ë‹µ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
       "\n",
       "## 3. êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
       "\n",
       "### 3.1 Modular RAGì˜ êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
       "- **êµ¬ì¡°**:\n",
       "  1. **ëª¨ë“ˆí™”ëœ êµ¬ì„± ìš”ì†Œ**: ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆê³¼ ìƒì„± ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
       "  2. **ë°ì´í„° íë¦„**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆì´ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ ë°ì´í„°ë¥¼ ìƒì„± ëª¨ë“ˆì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
       "\n",
       "- **ì‘ë™ ë°©ì‹**:\n",
       "  1. ì¿¼ë¦¬ ì…ë ¥\n",
       "  2. ì •ë³´ ê²€ìƒ‰\n",
       "  3. ì •ë³´ í•„í„°ë§\n",
       "  4. ì‘ë‹µ ìƒì„±\n",
       "  5. ê²°ê³¼ ì¶œë ¥\n",
       "\n",
       "### 3.2 Naive RAGì˜ êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
       "- **êµ¬ì¡°**:\n",
       "  1. ì§ˆë¬¸ ì…ë ¥\n",
       "  2. ì •ë³´ ê²€ìƒ‰\n",
       "  3. ë¬¸ì„œ ì„ íƒ\n",
       "  4. ìƒì„± ëª¨ë¸\n",
       "\n",
       "- **ì‘ë™ ë°©ì‹**:\n",
       "  - ê²€ìƒ‰ ë‹¨ê³„ì™€ ìƒì„± ë‹¨ê³„ë¡œ ë‚˜ë‰˜ë©°, ì „í†µì ì¸ ì •ë³´ ê²€ìƒ‰ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
       "\n",
       "## 4. ì£¼ìš” ì°¨ì´ì  ë¹„êµ\n",
       "\n",
       "1. **êµ¬ì¡°ì  ìœ ì—°ì„±**: Modular RAGëŠ” ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ì œê³µí•˜ë©°, Naive RAGëŠ” ê³ ì •ëœ êµ¬ì¡°ë¡œ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.\n",
       "2. **ëª¨ë“ˆí™”**: Modular RAGëŠ” ê° ëª¨ë“ˆì´ íŠ¹ì • ì—­í• ì„ ë‹´ë‹¹í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆì§€ë§Œ, Naive RAGëŠ” ë‹¨ì¼ íë¦„ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n",
       "3. **ì„±ëŠ¥ ìµœì í™”**: Modular RAGëŠ” ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆì–´ ì„±ëŠ¥ ê°œì„ ì´ ìš©ì´í•©ë‹ˆë‹¤.\n",
       "4. **ì ì‘ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆëŠ” ë°˜ë©´, Naive RAGëŠ” ì ì‘ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\n",
       "\n",
       "## 5. Modular RAGì˜ í”„ë¡œë•ì…˜ ë ˆë²¨ ì´ì \n",
       "\n",
       "1. **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ì‹œìŠ¤í…œì„ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
       "2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª¨ë“ˆì´ë‚˜ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•˜ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "3. **íš¨ìœ¨ì„±**: ê° ëª¨ë“ˆì´ íŠ¹ì • ì‘ì—…ì— ìµœì í™”ë˜ì–´ ì „ì²´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
       "4. **ê°œì„ ëœ ì •í™•ì„±**: ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "5. **ëª¨ë“ˆí™”ëœ ì„¤ê³„**: íŠ¹ì • ëª¨ë“ˆì— ë¬¸ì œê°€ ë°œìƒí•˜ë”ë¼ë„ ì „ì²´ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "6. **ì ì‘ì„±**: ë³€í™”í•˜ëŠ” í™˜ê²½ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "## 6. ê²°ë¡ \n",
       "Modular RAGëŠ” Naive RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ ì œê³µí•˜ëŠ” ì •ë³´ ê²€ìƒ‰ ë° ìƒì„± ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì„± ë•ë¶„ì— Modular RAGëŠ” ë‹¤ì–‘í•œ AI ì‘ìš© í”„ë¡œê·¸ë¨ì— ì í•©í•œ ì†”ë£¨ì…˜ìœ¼ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(snapshot[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ìµœì¢… ë³´ê³ ì„œ: Modular RAGì™€ Naive RAGì˜ ë¹„êµ ë° í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œì˜ ì´ì \n",
      "\n",
      "## 1. ì„œë¡ \n",
      "ë³¸ ë³´ê³ ì„œëŠ” Modular RAG(ëª¨ë“ˆí˜• RAG)ì™€ Naive RAG(ë‹¨ìˆœ RAG)ì˜ ì •ì˜, êµ¬ì¡°, ì‘ë™ ë°©ì‹, ì£¼ìš” ì°¨ì´ì  ë° Modular RAGê°€ í”„ë¡œë•ì…˜ ë ˆë²¨ì—ì„œ ì œê³µí•˜ëŠ” ì´ì ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‘ ì‹œìŠ¤í…œì˜ íŠ¹ì„±ê³¼ Modular RAGì˜ ì¥ì ì„ ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## 2. RAGì˜ ì •ì˜\n",
      "\n",
      "### 2.1 Modular RAG\n",
      "- **ì •ì˜**: Modular RAGëŠ” RAG ì‹œìŠ¤í…œì„ ëª¨ë“ˆí™”í•˜ì—¬ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì¸ êµ¬ì¡°ì…ë‹ˆë‹¤. ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\n",
      "- **íŠ¹ì§•**:\n",
      "  - **ëª¨ë“ˆí™”**: ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì¡°í•©í•˜ì—¬ ì‹œìŠ¤í…œì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ìœ ì—°ì„±**: í•„ìš”ì— ë”°ë¼ ëª¨ë“ˆì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ í•˜ìœ„ ëª¨ë“ˆì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 2.2 Naive RAG\n",
      "- **ì •ì˜**: Naive RAGëŠ” ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "- **íŠ¹ì§•**:\n",
      "  - **ë‹¨ìˆœì„±**: êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì…ë‹ˆë‹¤.\n",
      "  - **ì •ë³´ ê²€ìƒ‰**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
      "  - **ì‘ë‹µ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 3. êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "\n",
      "### 3.1 Modular RAGì˜ êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "- **êµ¬ì¡°**:\n",
      "  1. **ëª¨ë“ˆí™”ëœ êµ¬ì„± ìš”ì†Œ**: ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆê³¼ ìƒì„± ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
      "  2. **ë°ì´í„° íë¦„**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì •ë³´ ê²€ìƒ‰ ëª¨ë“ˆì´ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ ë°ì´í„°ë¥¼ ìƒì„± ëª¨ë“ˆì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "- **ì‘ë™ ë°©ì‹**:\n",
      "  1. ì¿¼ë¦¬ ì…ë ¥\n",
      "  2. ì •ë³´ ê²€ìƒ‰\n",
      "  3. ì •ë³´ í•„í„°ë§\n",
      "  4. ì‘ë‹µ ìƒì„±\n",
      "  5. ê²°ê³¼ ì¶œë ¥\n",
      "\n",
      "### 3.2 Naive RAGì˜ êµ¬ì¡° ë° ì‘ë™ ë°©ì‹\n",
      "- **êµ¬ì¡°**:\n",
      "  1. ì§ˆë¬¸ ì…ë ¥\n",
      "  2. ì •ë³´ ê²€ìƒ‰\n",
      "  3. ë¬¸ì„œ ì„ íƒ\n",
      "  4. ìƒì„± ëª¨ë¸\n",
      "\n",
      "- **ì‘ë™ ë°©ì‹**:\n",
      "  - ê²€ìƒ‰ ë‹¨ê³„ì™€ ìƒì„± ë‹¨ê³„ë¡œ ë‚˜ë‰˜ë©°, ì „í†µì ì¸ ì •ë³´ ê²€ìƒ‰ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 4. ì£¼ìš” ì°¨ì´ì  ë¹„êµ\n",
      "\n",
      "1. **êµ¬ì¡°ì  ìœ ì—°ì„±**: Modular RAGëŠ” ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ì œê³µí•˜ë©°, Naive RAGëŠ” ê³ ì •ëœ êµ¬ì¡°ë¡œ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "2. **ëª¨ë“ˆí™”**: Modular RAGëŠ” ê° ëª¨ë“ˆì´ íŠ¹ì • ì—­í• ì„ ë‹´ë‹¹í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆì§€ë§Œ, Naive RAGëŠ” ë‹¨ì¼ íë¦„ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n",
      "3. **ì„±ëŠ¥ ìµœì í™”**: Modular RAGëŠ” ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆì–´ ì„±ëŠ¥ ê°œì„ ì´ ìš©ì´í•©ë‹ˆë‹¤.\n",
      "4. **ì ì‘ì„±**: Modular RAGëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë§ì¶° ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆëŠ” ë°˜ë©´, Naive RAGëŠ” ì ì‘ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\n",
      "\n",
      "## 5. Modular RAGì˜ í”„ë¡œë•ì…˜ ë ˆë²¨ ì´ì \n",
      "\n",
      "1. **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ì‹œìŠ¤í…œì„ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª¨ë“ˆì´ë‚˜ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•˜ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "3. **íš¨ìœ¨ì„±**: ê° ëª¨ë“ˆì´ íŠ¹ì • ì‘ì—…ì— ìµœì í™”ë˜ì–´ ì „ì²´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
      "4. **ê°œì„ ëœ ì •í™•ì„±**: ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "5. **ëª¨ë“ˆí™”ëœ ì„¤ê³„**: íŠ¹ì • ëª¨ë“ˆì— ë¬¸ì œê°€ ë°œìƒí•˜ë”ë¼ë„ ì „ì²´ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "6. **ì ì‘ì„±**: ë³€í™”í•˜ëŠ” í™˜ê²½ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## 6. ê²°ë¡ \n",
      "Modular RAGëŠ” Naive RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ ì œê³µí•˜ëŠ” ì •ë³´ ê²€ìƒ‰ ë° ìƒì„± ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì„± ë•ë¶„ì— Modular RAGëŠ” ë‹¤ì–‘í•œ AI ì‘ìš© í”„ë¡œê·¸ë¨ì— ì í•©í•œ ì†”ë£¨ì…˜ìœ¼ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(snapshot[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-note-2024-PFhCXHTX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
