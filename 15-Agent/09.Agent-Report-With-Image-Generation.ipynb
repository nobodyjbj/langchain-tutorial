{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../common\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith 추적이 활성화되었습니다. [프로젝트명: 15.Agent, Agent-Report-With-Image-Generation]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langsmith_tracker import set_tracking\n",
    "from langchain_print import stream_response\n",
    "from multimodal import MultiModal\n",
    "from tools_news import GoogleNews\n",
    "\n",
    "# 인스턴스를 생성할 때 필요한 매개변수를 전달합니다.\n",
    "set_tracking(project_name=\"15.Agent, Agent-Report-With-Image-Generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG + Image Generator Agent(보고서 작성)\n",
    "\n",
    "웹 검색(Web Search), PDF 문서 기반 검색(RAG), 이미지 생성(Image Generation), 파일 관리 도구(File Management) 등을 통해 보고서를 작성하는 에이전트를 구현합니다.\n",
    "\n",
    "#### 도구 정의\n",
    "\n",
    "- 웹 검색(Web Search) : Tavily Search\n",
    "- PDF 문서 기반 검색(RAG) : Retriever\n",
    "- 이미지 생성(Image Generation) : Dalle-E\n",
    "- 파일 관리 도구(File Management) : agent_tools.FileManagement\n",
    "- 보고서 작성(Report Generation) Agent : 위의 도구들을 모두 통합\n",
    "\n",
    "모든 도구에 대한 API Key는 환경 변수에 정의되어 있습니다.(없으면, 직접 추가. 방법은 15-Agent/01.Tools.ipynb 참고)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 도구 정의\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "\n",
    "search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 문서 기반 검색 도구 정의\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "\n",
    "# PDF 로드\n",
    "loader = PyMuPDFLoader(\"./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf\")\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# 문서 로드 및 분할\n",
    "documents = loader.load_and_split(text_splitter)\n",
    "# FAISS 벡터 저장소 생성\n",
    "vectorstore = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "\n",
    "# retriever 정의\n",
    "retriever = vectorstore.as_retriever()\n",
    "document_template = PromptTemplate.from_template(\n",
    "    \"<document><content>{page_content}</content><page>{page}</page><filename>{source}</filename></document>\"\n",
    ")\n",
    "\n",
    "# 도구 정의\n",
    "rag_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_pdf\",\n",
    "    description=\"use this tool to search for information in the PDF file\",\n",
    "    document_prompt=document_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<document><content>체계를 구축하고 있는 만큼, 한국도 관련 지원 정책을 마련해야 함\n",
      "∙과기정통부와 TTA는 ‘신뢰할 수 있는 인공지능 개발 안내서’ 8종* 개발, ‘인공지능 시스템 신뢰성 제고를 위한 \n",
      "요구사항’ 표준 수립, AI 제품 등에 대한 신뢰성 인증 등을 추진하고 있음\n",
      "* 일반, 의료, 공공사회, 자율주행(2023.7), 일반, 생성 AI 기반 서비스, 스마트 치안, 채용(2024.3) \n",
      "47 과학기술정보통신부 (2024.10), “AI안전연구소 설립·운영계획”, 보도자료</content><page>28</page><filename>./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf</filename></document>\n",
      "\n",
      "<document><content>∙현재 국내에서는 여러 인공지능 관련 법안에서도 안전성 보장을 위한 규제 위주의 입법안과 기술의 혁신을 통한 \n",
      "산업 진흥을 중점으로 하는 입법안이 함께 논의 중\n",
      "4 과학기술정보통신부 (2024.8), (보도자료) 국민 10명 중 6명, 인공지능 기술 이점이 위협보다 크다 \n",
      "5 TheAIPI (2024.8), AI vs. Public Opinion: Catching you up on the latest from AIPI</content><page>6</page><filename>./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf</filename></document>\n",
      "\n",
      "<document><content>ㅇ 엔비디아의 생성 AI 플랫폼 ‘네모’가 소설 저작권을 침해했다고 기소하는 등 데이터 \n",
      "저작권에 대한 분쟁 확대 (2024.3)\n",
      "ㅇ 미국 저작권청은 미드저니를 통해 생성한 작품인 ‘새벽의 자리야’는 작품 자체에 대한 \n",
      "저작권은 인정하지 않고, AI로 만든 이미지와 텍스트를 조정한 것에 대해서만 인정 (2023.9)\n",
      "43 Nasr 외(2023.11), Scalable Extraction of Training Data from (Production) Language Models, arXiv:2311.17035v1</content><page>23</page><filename>./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf</filename></document>\n",
      "\n",
      "<document><content>SPRi\u0001이슈리포트IS-183\n",
      "AI\u0001위험유형및사례분석\n",
      "I. 배경 \n",
      "■첨단AI\u0001모델의잠재적위험에대비하기위해안전성및신뢰성확보에대한논의가본격화\n",
      "●영국에서 2023년 11월 개최된 ‘제1회 AI 안전성 정상회의’와 2024년 5월 AI 서울 정상회의를 \n",
      "거치며 AI의 안전한 활용 및 신뢰성 보장을 위한 국제적 논의가 구체화1\n",
      "∙프론티어(Frontier) AI*의 책임 있는 개발 및 배포를 위한 국제적 협력 필요성에 따라 글로벌 AI 기업들은 \n",
      "프론티어 AI 안전 서약**에 합의하였으며, 내년 프랑스 AI 정상회의에서 안전 프레임워크 등을 논의할 예정\n",
      "*  프론티어 AI는 뛰어난 능력을 가진 범용 AI(General-purpose AI, GPAI)로, 현재 고도화된 AI와 비슷하거나 더 뛰어난 모델을 의미\n",
      "** 삼성전자, 네이버, 구글, 오픈AI, 앤트로픽, MS, 아마존 등 16개의 글로벌 기업이 참여\n",
      "●구글, 오픈AI, MS, 앤트로픽 등 주요 기업들은 2023년 7월 프론티어 모델 포럼을 창립하고 AI \n",
      "안전 관련 주요 목표를 설정하는 등 글로벌 기업 또한 AI 안전 논의에 동참\n",
      "∙세 가지 주요 목표로 △생성 AI의 잠재적 위험 완화를 위한 모범사례 발굴, △AI 안전 조치에 관한 과학적 \n",
      "연구 연계, △기업-정부 간 소통 촉진을 통한 안전 및 개발 역량 강화를 포함\n",
      "●미국은 2023년 11월, 최초로 AI 행정명령을 통해 AI 안전 및 보안에 대한 표준 확립을 위한 \n",
      "조치를 지시하는 등 AI 분야에서의 리더십 확보 강조2\n",
      "∙AI 안전 및 보안을 위해 필요한 조치사항으로 △안전 테스트 결과 등의 공유, △표준, 도구 및 테스트 개발 \n",
      "△AI 생성 콘텐츠 탐지를 위한 표준 및 모범사례 수립, △취약점 보완을 위한 도구 개발 등을 포함\n",
      "■산업계의다양한분야에서생성AI를비롯한다양한AI\u0001 기술의도입이급증함에\n",
      "따라,\u0001이로인해발생할수있는피해나사고에대한대응이중요한요인으로부상</content><page>5</page><filename>./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf</filename></document>\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_tool.invoke({\"query\": \"네이버가 개발한 AI 기술을 소개하는 문서를 찾아주세요.\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 생성 도구 설명\n",
    "\n",
    " Dall-E 이미지 생성 도구를 활용하는 예제입니다.\n",
    "\n",
    "**주요 속성**\n",
    "- model: 사용할 DALL-E 모델 이름 (기본값: \"dall-e-2\", \"dall-e-3\")\n",
    "- n: 생성할 이미지 수 (기본값: 1)\n",
    "- size: 생성할 이미지 크기\n",
    "  - \"dall-e-2\": \"1024x1024\", \"512x512\", \"256x256\"\n",
    "  - \"dall-e-3\": \"1024x1024\", \"1792x1024\", \"1024x1792\"\n",
    "- style: 생성될 이미지의 스타일 (기본값: \"natural\", \"vivid\")\n",
    "- quality: 생성될 이미지의 품질 (기본값: \"standard\", \"hd\")\n",
    "- max_retries: 생성 시 최대 재시도 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "# DALL-E 래퍼 인스턴스 생성\n",
    "dalle = DallEAPIWrapper(model=\"dall-e-3\", size=\"1024x1024\", quality=\"standard\", n=1)\n",
    "\n",
    "\n",
    "@tool\n",
    "def image_tool(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates an image based on the given text description using DALL-E.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): A text description of the image to generate\n",
    "\n",
    "    Returns:\n",
    "        str: URL of the generated image\n",
    "    \"\"\"\n",
    "    return dalle.run(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파일 관리 도구 설명\n",
    "\n",
    "'08.Agent-File-Management.ipynb' 참고\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WriteFileTool(root_dir='tmp'),\n",
       " ReadFileTool(root_dir='tmp'),\n",
       " ListDirectoryTool(root_dir='tmp')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "\n",
    "# 작업 디렉토리 경로 설정\n",
    "working_directory = \"tmp\"\n",
    "\n",
    "# 파일 관리 도구 생성\n",
    "file_tools = FileManagementToolkit(\n",
    "    root_dir=str(working_directory),\n",
    "    selected_tools=[\"write_file\", \"read_file\", \"list_directory\"],\n",
    ").get_tools()\n",
    "\n",
    "file_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 도구 모음 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TavilySearchResults(api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))),\n",
       " Tool(name='search_pdf', description='use this tool to search for information in the PDF file', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x12d594360>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x135dee0c0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page', 'page_content', 'source'], input_types={}, partial_variables={}, template='<document><content>{page_content}</content><page>{page}</page><filename>{source}</filename></document>'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x12d879da0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x135dee0c0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page', 'page_content', 'source'], input_types={}, partial_variables={}, template='<document><content>{page_content}</content><page>{page}</page><filename>{source}</filename></document>'), document_separator='\\n\\n')),\n",
       " StructuredTool(name='image_tool', description='Generates an image based on the given text description using DALL-E.\\n\\nArgs:\\n    prompt (str): A text description of the image to generate\\n\\nReturns:\\n    str: URL of the generated image', args_schema=<class 'langchain_core.utils.pydantic.image_tool'>, func=<function image_tool at 0x137f4bec0>),\n",
       " WriteFileTool(root_dir='tmp'),\n",
       " ReadFileTool(root_dir='tmp'),\n",
       " ListDirectoryTool(root_dir='tmp')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [search_tool, rag_tool, image_tool] + file_tools\n",
    "\n",
    "# 도구 목록 출력\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보고서 작성(Report Generation) Agent 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_print import AgentStreamParser\n",
    "\n",
    "# 채팅 메시지 기록 저장소 정의\n",
    "store = {}\n",
    "\n",
    "# 프롬프트 생성\n",
    "# 프롬프트는 에이전트에게 모델이 수행할 작업을 설명하는 텍스트를 제공, 도구의 이름과 역할을 입력\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\"\n",
    "            \"You are professional researcher.\"\n",
    "            \"You are use the search_pdf tool to search for information in the PDF file.\"\n",
    "            \"You can find further information from the web if you need.\"\n",
    "            \"You are use the file_management tool to manage files.\"\n",
    "            \"You are use the dalle tool to generate images based on text descriptions.\"\n",
    "            \"You are write a report based on the information you found.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# llm 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# agent 생성\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# agent executor 생성\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=False, handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "\n",
    "# session_id 를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in store:  # session_id 가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "# ChatMessageHistory 객체를 생성하여 세션 기록 가져오기\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "# 스트림 파서 생성\n",
    "agent_stream_parser = AgentStreamParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdf 검색을 유도하여 Agent를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 실행 결과:\n",
      "[도구 호출]\n",
      "Tool: search_pdf\n",
      "query: 생성형 AI 위험성\n",
      "Log: \n",
      "Invoking: `search_pdf` with `{'query': '생성형 AI 위험성'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: <document><content>SPRi\u0001이슈리포트IS-183\n",
      "AI\u0001위험유형및사례분석\n",
      "2\n",
      "●생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향\n",
      "∙위험 인식 및 완화(68%), 위험 완화 프로세스(44%), 감사·편향 검사·위험 평가를 고려한 모델 설계(43%), \n",
      "책임 있는 AI 거버넌스 구축(24%) 등 AI의 안전성 확보 업무를 수행하는 비율이 최대 2배 이상 차이\n",
      "■국내대중의AI\u0001기술의위험성에관한인식은상대적으로높지않은상황으로,\u0001정부는AI의\n",
      "이점을극대화하면서도안전성을제공할수있는정책을마련할필요\n",
      "●과기정통부의 AI 기술에 대한 대국민 설문조사(2024)4 결과에 따르면, 응답자의 절반 이상은 \n",
      "AI의 잠재적 위험보다 AI 기술이 지닌 이점이 더 많다고 인식\n",
      "∙‘AI 기술의 이점이 잠재적 위험보다 많다’고 응답한 비율은 57%이고, ‘규제보다 혁신이 중요’하다고 응답한 \n",
      "비율은 55%로 다수의 응답자들은 AI 기술의 이점*을 위험보다 더 크게 인식\n",
      "* 주요 이점으로는 일상생활의 편의성 향상(30.6%), 업무 추진의 효율성 증진(19.6%), 산업현장의 생산성 혁신(16%) 순\n",
      "∙‘AI 기술의 잠재적 위험이 이점보다 더 많다’고 응답한 비율은 19.1%로 나타났으며, 우려되는 AI 기술의 \n",
      "잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해를 꼽았음\n",
      "* 가장 우려되는 AI 기술의 잠재적 위험으로는 ‘설계/오작동 발생으로 인한 피해(18.5%)’, ‘악의적 의도로 AI 활용에 따른 피해\n",
      "(18.3%)’를 비롯하여 프라이버시 문제와 경제 격차 심화 등 응답\n",
      "∙응답자들은 AI 발전을 위한 가장 중요한 정부의 정책으로는 AI 법 제정과 윤리기준 마련을 꼽았음\n",
      "* ‘인공지능 법 제정 및 윤리기준 마련(34.6%)’외에는 ‘AI 연구·개발·사용을 위한 국가 마스터플랜 마련(18.8%)’, ‘국제협력을 통\n",
      "한 AI 표준화 등 국제 규범 마련(17.4%)’ 순으로 응답</content><page>6</page><filename>./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf</filename></document>\n",
      "\n",
      "<document><content>SPRi\u0001이슈리포트IS-183\n",
      "AI\u0001위험유형및사례분석\n",
      "14\n",
      "∙인간이 보안 취약성을 식별하고 수정하는 데 소요되는 시간을 단축시키거나, 보안 패치를 구현함에 있어 AI를 \n",
      "보조적으로 활용하는 사례도 존재25\n",
      "■(이중사용과학위험)\u0001생물학,\u0001화학,\u0001방사능및핵무기분야의AI\u0001사용으로인한위험우려\n",
      "●범용 AI는 새로운 과학자를 양성하거나 연구 워크플로우를 개선하는 등 과학적 발전을 가속화 할 \n",
      "수 있으나, 다양한 분야에서 악의적인 목적으로 활용될 가능성을 배제할 수 없음\n",
      "∙즉, 일반 사용자가 범용 AI를 통해 과학적 지식이나 지침 등 정보에 대한 접근성이 증가함에 따라, 특정 정보를 \n",
      "활용하여 악의적으로 사용할 가능성도 존재\n",
      "(사례6) 생물학적 무기 생산\n",
      "ㅇ LLM은 심각한 전염병 병원체를 생성하거나 표적화된 생물학적 무기를 빠르게 생산하는 \n",
      "데 사용됨으로써 치명적인 위험을 야기(2023.6.24)26\n",
      "ㅇ 이에, 대량 살상 무기 대리(WMDP) 벤치마크를 통해 생물 보안, 사이버 보안 및 화학 \n",
      "분야에서 LLM의 위험한 지식에 대한 평가 및 제거 노력 진행(2024.3.5)27\n",
      "3.2\u0001오작동위험\n",
      "■(제품기능문제로인한위험)\u0001제품에대해잘못된정보로오해·혼동하여발생\n",
      "●비현실적인 기대로 AI 시스템에 과도하게 의존하거나, 예상 기능을 AI가 제공하지 못함으로써 \n",
      "발생하는 잠재적 피해\n",
      "∙법조계, 의료계 등 전문 분야에서 범용 AI의 능력을 과대평가하여 실무에 적용 시 적지 않은 오류가 발생\n",
      "(사례7) 법조계에서의 AI 오류\n",
      "ㅇ GPT-4를 대상으로 변호사 시험 응시 결과, 시험 조건을 변경했을 때 불합격률이 상승하는 \n",
      "결과를 보임에 따라 전문 영역에서 생성 AI의 능력에 대해 신중할 필요(2024.3.30)28\n",
      "ㅇ 실제 법률 실무에서 AI 적용 시, 부적절한 인용이나 문구를 사용하여 심각한 오류가 있다고 \n",
      "보고된 바 있음(2023.6.19)29</content><page>18</page><filename>./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf</filename></document>\n",
      "\n",
      "<document><content>SPRi\u0001이슈리포트IS-183\n",
      "AI\u0001위험유형및사례분석\n",
      "23\n",
      "∙하지만, 위험관리 프로세스는 위험을 식별하고 평가하고, 위험성에 따라 우선순위를 지정하는 것으로 \n",
      "위험을 모니터링하고 보고하는 체계의 구축이 더욱 중요44\n",
      "∙악의적 콘텐츠 생성 위험 완화를 위한 측면에서도 명확한 AI 원칙 및 가이드라인 수립과 조직이 이를 \n",
      "수용하는 것이 중요하고, 워터마킹, 조직 내 통제된 환경 구축(예: 개인정보 관리 도구의 사용) 은 피해를 \n",
      "예방하기 위한 선결적 요구사항 필요\n",
      "∙콘텐츠 소비 위험 완화 측면에서도 기술적으로는 AI 출력 검증이나 경고 매커니즘을 수립 필요가 있으나, \n",
      "악의적 콘텐츠에 대한 소비자의 인식 개선과 리터러시 향상도 동시에 요구됨\n",
      "●종합하면, AI 기술 개발 기업뿐만 아니라 생성 AI 모델이나 서비스 개발자를 통해, 발생할 수 \n",
      "있는 위험을 사전에 방지하여 AI 안전을 확보할 수 있는 방식을 고려해야 함\n",
      "∙학습 데이터에서의 유해 콘텐츠 제거 작업을 수행 또는 생성 AI 도구의 서비스 약관을 위반하는 프롬프트를 \n",
      "제한하는 등의 보호 장치를 마련하는 위험 대응 방식이 고려되어야 함\n",
      "●최근 논의되는 위험 대응 방식으로는 사전폭로(Prebunking)을 통한 사용자의 경각심 제고 \n",
      "방식도 존재\n",
      "∙이러한 조치는 기술적 대응 방안이 아닌, 사람들로 하여금 조작적 콘텐츠에 대한 심리적 경계를 야기하여, \n",
      "조작 콘텐츠를 식별하고 저항할 수 있는 환경을 조성하는 방식\n",
      "* 인도네시아 총선을 앞두고 Jigsaw와 구글은 Prebunking 캠페인 영상을 공개하여, 유권자들이 감정 조작, 탈맥락화, 불신 또는 \n",
      "명예훼손 등의 생성 AI 기반의 잘못된 정보에 대한 위험을 사전 고지함으로써, 사용자들의 인식을 제고45\n",
      "∙사전폭로 방식을 통해 정보를 사전 고지 받은 사용자들은 AI 위험을 상대적으로 더 잘 구분하는 것을 확인\n",
      "■AI\u0001안전을위한사회적,\u0001제도적논의의글로벌협력의필요성증대\n",
      "●고성능 범용 AI가 다양한 분야에 도입되고 일상화되어 많은 긍정적 영향을 끼치고 있으나, AI에</content><page>27</page><filename>./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf</filename></document>\n",
      "\n",
      "<document><content>SPRi\u0001이슈리포트IS-183\n",
      "AI\u0001위험유형및사례분석\n",
      "7\n",
      "■\u0001(연구2)\u0001미국NIST는생성AI\u0001기술에특화된위험요인을분류하고관리방안을제시\n",
      "●미국은 NIST의 위험 관리 프레임워크(AI RMF 1.0)를 기반으로 자발적인 AI 위험 대응 환경을 \n",
      "구축하고 있으며, ‘AI RMF : 생성 AI 프로파일’13을 통해 생성 AI 특화 위험 요인을 제시 \n",
      "∙생성 AI 개발 및 사용에 의해 고유하거나 악화되는 위험을 정의하고, 원인/결과 및 대상에 따라 12가지로 구분\n",
      "구분\n",
      "내용\n",
      "CBRN 정보 또는 역량\n",
      "화학·생물학·방사능·핵무기(CBRN) 설계 또는 위험 물질 합성 등에 접근 용이성 제공\n",
      "작화 (confabulation)\n",
      "오류가 있거나 거짓된 콘텐츠 제작으로 사용자를 오도하거나 기만 (환각, 날조)\n",
      "위험·폭력·혐오적 콘텐츠\n",
      "위협적 콘텐츠의 제작 및 접근을 용이하게 하고, 자해·불법 활동을 권고하거나 혐오 및 비하 또는 고\n",
      "정관념 조장 콘텐츠의 대중 노출 통제의 어려움\n",
      "데이터 프라이버시\n",
      "생체 인식, 건강, 위치 등 민감 데이터의 유출 및 무단 사용, 공개, 익명화로 인한 영향\n",
      "환경적 영향\n",
      "생성 AI 학습 또는 운영에서의 높은 컴퓨팅 리소스 사용으로 인한 영향 등 생태계에 부정적 영향\n",
      "해로운 편향 및 균질화\n",
      "편견의 증폭 및 악화, 대표성이 부족한 학습 데이터로 인한 차별 및 편향 증폭, 잘못된 추정 등\n",
      "인간-AI 구성\n",
      "인간-AI 간 상호작용으로 부적절한 의인화, 알고리즘 혐오, 자동화 편향, 과도한 AI 의존 등\n",
      "정보 무결성\n",
      "사실, 의견 또는 허구의 구분, 불확실성, 대규모 허위 정보 및 허위 정보 캠페인에 활용될 수 \n",
      "있는 콘텐츠의 생성 등에 대한 용이성 제공\n",
      "정보 보안\n",
      "해킹, 피싱 등 사이버 공격을 용이하게 하는 취약점 발견 및 악용을 포함한 사이버 역량에 영향\n",
      "지적재산권\n",
      "저작권 등이 부여된 것으로 의심되는 콘텐츠에 대한 허가 없는 제작 및 복제, 영업 비밀 노출, \n",
      "표절, 불법 복제 용이성\n",
      "외설·모욕적 콘텐츠</content><page>11</page><filename>./data/IS-183_AI 위험 유형 및 사례 분석(최종).pdf</filename></document>\n",
      "[도구 호출]\n",
      "Tool: write_file\n",
      "file_path: report.md\n",
      "text: ## 생성형 AI의 위험성\n",
      "\n",
      "- **페이지 번호**: 6, 11, 18, 27\n",
      "- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\n",
      "\n",
      "- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\n",
      "- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\n",
      "- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\n",
      "- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\n",
      "- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\n",
      "- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\n",
      "- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.\n",
      "Log: \n",
      "Invoking: `write_file` with `{'file_path': 'report.md', 'text': '## 생성형 AI의 위험성\\n\\n- **페이지 번호**: 6, 11, 18, 27\\n- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\\n\\n- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\\n- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\\n- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\\n- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\\n- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\\n- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\\n- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: File written successfully to report.md.\n",
      "[도구 호출]\n",
      "Tool: read_file\n",
      "file_path: report.md\n",
      "Log: \n",
      "Invoking: `read_file` with `{'file_path': 'report.md'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: ## 생성형 AI의 위험성\n",
      "\n",
      "- **페이지 번호**: 6, 11, 18, 27\n",
      "- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\n",
      "\n",
      "- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\n",
      "- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\n",
      "- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\n",
      "- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\n",
      "- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\n",
      "- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\n",
      "- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.\n",
      "[최종 답변]\n",
      "아래는 생성형 AI의 위험성과 관련된 정보를 정리한 내용입니다.\n",
      "\n",
      "## 생성형 AI의 위험성\n",
      "\n",
      "- **페이지 번호**: 6, 11, 18, 27\n",
      "- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\n",
      "\n",
      "- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\n",
      "- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\n",
      "- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\n",
      "- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\n",
      "- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\n",
      "- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\n",
      "- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행\n",
    "result = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"`생성형 AI` 의 위험성과 관련된 유용한 정보들을 PDF 문서에서 찾아서 bullet point로 정리해 주세요. \"\n",
    "        \"한글로 작성해주세요.\"\n",
    "        \"다음으로는 `report.md` 파일을 새롭게 생성하여 정리한 내용을 저장해주세요. \\n\\n\"\n",
    "        \"#작성방법: \\n\"\n",
    "        \"1. markdown header 2 크기로 적절한 제목을 작성하세요. \\n\"\n",
    "        \"2. 발췌한 PDF 문서의 페이지 번호, 파일명을 기입하세요(예시: page 10, filename.pdf). \\n\"\n",
    "        \"3. 정리된 bullet point를 작성하세요. \\n\"\n",
    "        \"4. 작성이 완료되면 파일을 `report.md` 에 저장하세요. \\n\"\n",
    "        \"5. 마지막으로 저장한 `report.md` 파일을 읽어서 출력해 주세요. \\n\"\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"sessionid:agent3\"}},\n",
    ")\n",
    "\n",
    "print(\"Agent 실행 결과:\")\n",
    "for step in result:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web 검색 툴 사용을 유도하여 Agent를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 실행 결과:\n",
      "[도구 호출]\n",
      "Tool: tavily_search_results_json\n",
      "query: 생성형 AI 위험성\n",
      "Log: \n",
      "Invoking: `tavily_search_results_json` with `{'query': '생성형 AI 위험성'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: [{'url': 'https://www.hankyung.com/article/202409096811i', 'content': '생성형 AI 위험 커져…안전성 확보 시급 | 한국경제 주니어 생글생글 한경 AI! 유 대표는 \"워낙 다양한 시나리오로 AI와 대화할 수 있기 때문에 이제 필터링 방식으로 문제를 잡아내기 어려운 측면이 있다\"며 \"크게 세 가지로 구분해 생성형 AI 문제의 설명이 가능하다\"고 말했다. 그는는 \"AI 학습에 활용된 데이터의 유출, AI를 범죄에 활용하는 경우 등의 문제도 발생할 수 있다\"고 말했다. 생성형 AI 관련 위험 요소는 10개 이상으로 제시할 수 있다. 유 대표는 \"이런 생성형 AI 서비스 등의 문제를 가드레일 시스템으로 대응이 가능하다\"고 말했다. 한국경제신문의 프리미엄 스타트업 미디어 플랫폼 긱스(Geeks)가 4일 스타트업 뉴스를 브리핑합니다.태블릿 학습 앱 오르조, 대화로 학생 맞춤형 문제풀이 돕는 ‘오르조 AI 코치’ 출시에듀테크 ... 한국경제TV KED Global 한국경제매거진 마켓인사이트 아르떼 BOOK 한경아카데미 텐아시아 생글생글 주니어 생글생글 TESAT 29초영화제 교육센터 블루밍비트 키즈맘 PR Newswire'}, {'url': 'https://talkai.info/ko/blog/is_ai_dangerous/', 'content': '인공 지능의 위험성. 2018년에는 자율주행 Uber 차량이 보행자를 치어 사망하게 하는 사고가 발생했습니다. ... 또한 창작 활동에 생성형 AI를 활용하면 인간의 창의성과 감정 표현이 억제될 수 있습니다. 또한 AI 시스템과의 과도한 상호작용은 또래 간의 의사소통과'}, {'url': 'https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html', 'content': '“오류 출력 및 규제 위반 위험성 높아”··· 전문가들이 ‘생성형 AI 정책’ 수립을 강조 | CIO 홈IT 리더십“오류 출력 및 규제 위반 위험성 높아”··· 전문가들이 ‘생성형 AI 정책’ 수립을 강조 “오류 출력 및 규제 위반 위험성 높아”··· 전문가들이 ‘생성형 AI 정책’ 수립을 강조 인사이트에서 의뢰하고 여론조사기관 해리스 폴(Harris Poll)이 실시한\\xa0최신 설문조사에 의하면\\xa0비즈니스 리더가 향후 1년 동안 생성형 AI 도구를 도입하는 가장 큰 이유 2가지는 ‘매출 증대’와 ‘혁신 촉진’이다. 생성형 AI 도구를 사용하면서 사전 통보 없이 사용자 정보를 제3자(벤더 및 서비스 제공업체 등)와 공유할 수 있기 때문에 프라이버시 문제가 발생할 수도 있다. 생성형 AI 기술을 수용하면 직원들은 일하는 방식을 발전 및 향상시킬 수 있는 기회를 얻게 되며, 심지어는 새로운 커리어 경로를 발견할 수도 있다”라고 전했다. By Paul Barker Dec 01, 2024 3분 생성형 AI 인공지능 소프트웨어 개발'}, {'url': 'https://www.zendesk.kr/newsroom/articles/generative-ai/', 'content': 'Zendesk의 AI 책임자가 말하는 생성형 AI의 가능성과 위험성. Cristina Fonseca가 ChatGPT를 둘러싼 논의의 핵심을 짚고, AI가 고객 경험 환경에 가져올 변화에 관해 설명합니다.'}, {'url': 'https://www.cio.com/article/3521506/칼럼-생성형-ai에-대한-10가지-진단.html', 'content': \"하지만 안타깝게도 생성형 ai는 '뜨거운 감자'인 주제에 대해 제대로 된 답변을 내놓지 못한다. ai 환각의 위험성 . ai가 생각을 하는 걸까? 아니면\"}]\n",
      "[도구 호출]\n",
      "Tool: write_file\n",
      "file_path: report.md\n",
      "text: ## 생성형 AI의 위험성\n",
      "\n",
      "- **페이지 번호**: 6, 11, 18, 27\n",
      "- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\n",
      "\n",
      "- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\n",
      "- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\n",
      "- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\n",
      "- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\n",
      "- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\n",
      "- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\n",
      "- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.\n",
      "\n",
      "## 웹 검색 결과\n",
      "\n",
      "- **출처**: [한국경제](https://www.hankyung.com/article/202409096811i)\n",
      "  - 생성형 AI의 위험이 커지고 있으며, 안전성 확보가 시급하다는 의견이 있음. AI 학습에 활용된 데이터의 유출 및 범죄에 활용되는 경우 등의 문제도 발생할 수 있음.\n",
      "\n",
      "- **출처**: [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/)\n",
      "  - 생성형 AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있으며, AI 시스템과의 과도한 상호작용이 의사소통에 부정적인 영향을 미칠 수 있음.\n",
      "\n",
      "- **출처**: [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n",
      "  - 생성형 AI 도구의 사용으로 인해 사용자 정보가 제3자와 공유될 수 있어 프라이버시 문제가 발생할 수 있으며, 오류 출력 및 규제 위반의 위험성이 높아지고 있음.\n",
      "Log: \n",
      "Invoking: `write_file` with `{'file_path': 'report.md', 'text': '## 생성형 AI의 위험성\\n\\n- **페이지 번호**: 6, 11, 18, 27\\n- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\\n\\n- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\\n- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\\n- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\\n- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\\n- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\\n- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\\n- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.\\n\\n## 웹 검색 결과\\n\\n- **출처**: [한국경제](https://www.hankyung.com/article/202409096811i)\\n  - 생성형 AI의 위험이 커지고 있으며, 안전성 확보가 시급하다는 의견이 있음. AI 학습에 활용된 데이터의 유출 및 범죄에 활용되는 경우 등의 문제도 발생할 수 있음.\\n\\n- **출처**: [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/)\\n  - 생성형 AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있으며, AI 시스템과의 과도한 상호작용이 의사소통에 부정적인 영향을 미칠 수 있음.\\n\\n- **출처**: [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\\n  - 생성형 AI 도구의 사용으로 인해 사용자 정보가 제3자와 공유될 수 있어 프라이버시 문제가 발생할 수 있으며, 오류 출력 및 규제 위반의 위험성이 높아지고 있음.'}`\n",
      "\n",
      "\n",
      "\n",
      "[도구 호출]\n",
      "Tool: read_file\n",
      "file_path: report.md\n",
      "Log: \n",
      "Invoking: `read_file` with `{'file_path': 'report.md'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: File written successfully to report.md.\n",
      "[관찰 내용]\n",
      "Observation: ## 생성형 AI의 위험성\n",
      "\n",
      "- **페이지 번호**: 6, 11, 18, 27\n",
      "- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\n",
      "\n",
      "- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\n",
      "- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\n",
      "- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\n",
      "- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\n",
      "- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\n",
      "- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\n",
      "- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.\n",
      "\n",
      "## 웹 검색 결과\n",
      "\n",
      "- **출처**: [한국경제](https://www.hankyung.com/article/202409096811i)\n",
      "  - 생성형 AI의 위험이 커지고 있으며, 안전성 확보가 시급하다는 의견이 있음. AI 학습에 활용된 데이터의 유출 및 범죄에 활용되는 경우 등의 문제도 발생할 수 있음.\n",
      "\n",
      "- **출처**: [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/)\n",
      "  - 생성형 AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있으며, AI 시스템과의 과도한 상호작용이 의사소통에 부정적인 영향을 미칠 수 있음.\n",
      "\n",
      "- **출처**: [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n",
      "  - 생성형 AI 도구의 사용으로 인해 사용자 정보가 제3자와 공유될 수 있어 프라이버시 문제가 발생할 수 있으며, 오류 출력 및 규제 위반의 위험성이 높아지고 있음.\n",
      "[최종 답변]\n",
      "아래는 `report.md` 파일의 내용입니다.\n",
      "\n",
      "## 생성형 AI의 위험성\n",
      "\n",
      "- **페이지 번호**: 6, 11, 18, 27\n",
      "- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\n",
      "\n",
      "- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\n",
      "- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\n",
      "- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\n",
      "- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\n",
      "- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\n",
      "- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\n",
      "- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.\n",
      "\n",
      "## 웹 검색 결과\n",
      "\n",
      "- **출처**: [한국경제](https://www.hankyung.com/article/202409096811i)\n",
      "  - 생성형 AI의 위험이 커지고 있으며, 안전성 확보가 시급하다는 의견이 있음. AI 학습에 활용된 데이터의 유출 및 범죄에 활용되는 경우 등의 문제도 발생할 수 있음.\n",
      "\n",
      "- **출처**: [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/)\n",
      "  - 생성형 AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있으며, AI 시스템과의 과도한 상호작용이 의사소통에 부정적인 영향을 미칠 수 있음.\n",
      "\n",
      "- **출처**: [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n",
      "  - 생성형 AI 도구의 사용으로 인해 사용자 정보가 제3자와 공유될 수 있어 프라이버시 문제가 발생할 수 있으며, 오류 출력 및 규제 위반의 위험성이 높아지고 있음.\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행\n",
    "result = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"이번에는 `생성형 AI` 의 위험성과 관련된 유용한 정보들을 웹에서 검색한 결과를 정리해주세요.\"\n",
    "        \"한글로 작성해주세요.\"\n",
    "        \"다음으로는 `report.md` 파일을 열어서 기존의 내용을 읽고, 웹 검색하여 찾은 정보를 이전에 작성한 형식에 맞춰 뒷 부분에 추가해 주세요. \\n\\n\"\n",
    "        \"#작성방법: \\n\"\n",
    "        \"1. markdown header 2 크기로 적절한 제목을 작성하세요. \\n\"\n",
    "        \"2. 정보의 출처(url)를 기입하세요(예시: 출처: 네이버 지식백과). \\n\"\n",
    "        \"3. 정리된 웹검색 내용을 작성하세요. \\n\"\n",
    "        \"4. 작성이 완료되면 파일을 `report.md` 에 저장하세요. \\n\"\n",
    "        \"5. 마지막으로 저장한 `report.md` 파일을 읽어서 출력해 주세요. \\n\"\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"sessionid:agent3\"}},\n",
    ")\n",
    "\n",
    "print(\"Agent 실행 결과:\")\n",
    "for step in result:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제대로된 보고서 작성을 요청하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 실행 결과:\n",
      "[도구 호출]\n",
      "Tool: read_file\n",
      "file_path: report.md\n",
      "Log: \n",
      "Invoking: `read_file` with `{'file_path': 'report.md'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: ## 생성형 AI의 위험성\n",
      "\n",
      "- **페이지 번호**: 6, 11, 18, 27\n",
      "- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf\n",
      "\n",
      "- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.\n",
      "- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.\n",
      "- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.\n",
      "- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.\n",
      "- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.\n",
      "- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.\n",
      "- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.\n",
      "\n",
      "## 웹 검색 결과\n",
      "\n",
      "- **출처**: [한국경제](https://www.hankyung.com/article/202409096811i)\n",
      "  - 생성형 AI의 위험이 커지고 있으며, 안전성 확보가 시급하다는 의견이 있음. AI 학습에 활용된 데이터의 유출 및 범죄에 활용되는 경우 등의 문제도 발생할 수 있음.\n",
      "\n",
      "- **출처**: [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/)\n",
      "  - 생성형 AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있으며, AI 시스템과의 과도한 상호작용이 의사소통에 부정적인 영향을 미칠 수 있음.\n",
      "\n",
      "- **출처**: [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n",
      "  - 생성형 AI 도구의 사용으로 인해 사용자 정보가 제3자와 공유될 수 있어 프라이버시 문제가 발생할 수 있으며, 오류 출력 및 규제 위반의 위험성이 높아지고 있음.\n",
      "[도구 호출]\n",
      "Tool: write_file\n",
      "file_path: report-2.md\n",
      "text: # 생성형 AI의 위험성 보고서\n",
      "\n",
      "## 1. 개요\n",
      "생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.\n",
      "\n",
      "## 2. 핵심내용\n",
      "| 위험 요인 | 설명 |\n",
      "|------------|------|\n",
      "| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |\n",
      "| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |\n",
      "| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |\n",
      "| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |\n",
      "| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |\n",
      "| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |\n",
      "\n",
      "## 3. 최종결론\n",
      "생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.\n",
      "\n",
      "**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n",
      "append: False\n",
      "Log: \n",
      "Invoking: `write_file` with `{'file_path': 'report-2.md', 'text': '# 생성형 AI의 위험성 보고서\\n\\n## 1. 개요\\n생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.\\n\\n## 2. 핵심내용\\n| 위험 요인 | 설명 |\\n|------------|------|\\n| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |\\n| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |\\n| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |\\n| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |\\n| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |\\n| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |\\n\\n## 3. 최종결론\\n생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.\\n\\n**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)', 'append': False}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: File written successfully to report-2.md.\n",
      "[도구 호출]\n",
      "Tool: read_file\n",
      "file_path: report-2.md\n",
      "Log: \n",
      "Invoking: `read_file` with `{'file_path': 'report-2.md'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: # 생성형 AI의 위험성 보고서\n",
      "\n",
      "## 1. 개요\n",
      "생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.\n",
      "\n",
      "## 2. 핵심내용\n",
      "| 위험 요인 | 설명 |\n",
      "|------------|------|\n",
      "| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |\n",
      "| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |\n",
      "| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |\n",
      "| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |\n",
      "| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |\n",
      "| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |\n",
      "\n",
      "## 3. 최종결론\n",
      "생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.\n",
      "\n",
      "**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n",
      "[최종 답변]\n",
      "아래는 생성형 AI의 위험성에 대한 보고서입니다.\n",
      "\n",
      "# 생성형 AI의 위험성 보고서\n",
      "\n",
      "## 1. 개요\n",
      "생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.\n",
      "\n",
      "## 2. 핵심내용\n",
      "| 위험 요인 | 설명 |\n",
      "|------------|------|\n",
      "| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |\n",
      "| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |\n",
      "| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |\n",
      "| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |\n",
      "| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |\n",
      "| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |\n",
      "\n",
      "## 3. 최종결론\n",
      "생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.\n",
      "\n",
      "**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n"
     ]
    }
   ],
   "source": [
    "# 보고서 작성 요청\n",
    "result = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"`report.md` 파일을 열어서 안의 내용을 출력하세요. \"\n",
    "        \"출력된 내용을 바탕으로, 전문적인 수준의 보고서를 작성하세요. \"\n",
    "        \"보고서는 총 3개의 섹션으로 구성되어야 합니다:\\n\"\n",
    "        \"1. 개요: 보고서 abstract 를 300자 내외로 작성하세요.\\n\"\n",
    "        \"2. 핵심내용: 보고서의 핵심 내용을 작성하세요. 정리된 표를 markdown 형식으로 작성하여 추가하세요. \"\n",
    "        \"3. 최종결론: 보고서의 최종 결론을 작성하세요. 출처(파일명, url 등)을 표시하세요.\"\n",
    "        \"마지막으로 작성된 결과물을 `report-2.md` 파일에 저장하세요.\"\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"sessionid:agent3\"}},\n",
    ")\n",
    "\n",
    "print(\"Agent 실행 결과:\")\n",
    "for step in result:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보고서의 내용을 기반으로 이미지를 생성하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 실행 결과:\n",
      "[도구 호출]\n",
      "Tool: read_file\n",
      "file_path: report-2.md\n",
      "Log: \n",
      "Invoking: `read_file` with `{'file_path': 'report-2.md'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: # 생성형 AI의 위험성 보고서\n",
      "\n",
      "## 1. 개요\n",
      "생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.\n",
      "\n",
      "## 2. 핵심내용\n",
      "| 위험 요인 | 설명 |\n",
      "|------------|------|\n",
      "| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |\n",
      "| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |\n",
      "| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |\n",
      "| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |\n",
      "| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |\n",
      "| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |\n",
      "\n",
      "## 3. 최종결론\n",
      "생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.\n",
      "\n",
      "**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n",
      "[도구 호출]\n",
      "Tool: image_tool\n",
      "prompt: A conceptual illustration representing the risks of generative AI. The image should depict elements like malfunctioning technology, data privacy issues, and societal impacts. Include visual metaphors for creativity suppression and regulatory challenges, with a futuristic and cautionary tone.\n",
      "Log: \n",
      "Invoking: `image_tool` with `{'prompt': 'A conceptual illustration representing the risks of generative AI. The image should depict elements like malfunctioning technology, data privacy issues, and societal impacts. Include visual metaphors for creativity suppression and regulatory challenges, with a futuristic and cautionary tone.'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: https://oaidalleapiprodscus.blob.core.windows.net/private/org-SD76VRjKZn7BhpAtD6EB27g3/user-3UowxZ06VqNttUO7RMIoAsi7/img-uW59MQYV75v9ASlZqPbZpvhx.png?st=2024-12-05T00%3A42%3A42Z&se=2024-12-05T02%3A42%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-05T00%3A12%3A58Z&ske=2024-12-06T00%3A12%3A58Z&sks=b&skv=2024-08-04&sig=xqtXaRSks8g5pQtIIXre6UKTwrfD/ECEHkxyFeANEKo%3D\n",
      "[도구 호출]\n",
      "Tool: write_file\n",
      "file_path: report-3.md\n",
      "text: ![Generative AI Risks](https://oaidalleapiprodscus.blob.core.windows.net/private/org-SD76VRjKZn7BhpAtD6EB27g3/user-3UowxZ06VqNttUO7RMIoAsi7/img-uW59MQYV75v9ASlZqPbZpvhx.png?st=2024-12-05T00%3A42%3A42Z&se=2024-12-05T02%3A42%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-05T00%3A12%3A58Z&ske=2024-12-06T00%3A12%3A58Z&sks=b&skv=2024-08-04&sig=xqtXaRSks8g5pQtIIXre6UKTwrfD/ECEHkxyFeANEKo%3D)\n",
      "\n",
      "# 생성형 AI의 위험성 보고서\n",
      "\n",
      "## 1. 개요\n",
      "생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.\n",
      "\n",
      "## 2. 핵심내용\n",
      "| 위험 요인 | 설명 |\n",
      "|------------|------|\n",
      "| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |\n",
      "| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |\n",
      "| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |\n",
      "| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |\n",
      "| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |\n",
      "| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |\n",
      "\n",
      "## 3. 최종결론\n",
      "생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.\n",
      "\n",
      "**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)\n",
      "append: False\n",
      "Log: \n",
      "Invoking: `write_file` with `{'file_path': 'report-3.md', 'text': '![Generative AI Risks](https://oaidalleapiprodscus.blob.core.windows.net/private/org-SD76VRjKZn7BhpAtD6EB27g3/user-3UowxZ06VqNttUO7RMIoAsi7/img-uW59MQYV75v9ASlZqPbZpvhx.png?st=2024-12-05T00%3A42%3A42Z&se=2024-12-05T02%3A42%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-05T00%3A12%3A58Z&ske=2024-12-06T00%3A12%3A58Z&sks=b&skv=2024-08-04&sig=xqtXaRSks8g5pQtIIXre6UKTwrfD/ECEHkxyFeANEKo%3D)\\n\\n# 생성형 AI의 위험성 보고서\\n\\n## 1. 개요\\n생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.\\n\\n## 2. 핵심내용\\n| 위험 요인 | 설명 |\\n|------------|------|\\n| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |\\n| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |\\n| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |\\n| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |\\n| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |\\n| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |\\n\\n## 3. 최종결론\\n생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.\\n\\n**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)', 'append': False}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: File written successfully to report-3.md.\n",
      "[최종 답변]\n",
      "보고서의 내용을 `report-3.md` 파일에 저장하였습니다. 생성된 이미지의 URL은 다음과 같습니다:\n",
      "\n",
      "![Generative AI Risks](https://oaidalleapiprodscus.blob.core.windows.net/private/org-SD76VRjKZn7BhpAtD6EB27g3/user-3UowxZ06VqNttUO7RMIoAsi7/img-uW59MQYV75v9ASlZqPbZpvhx.png?st=2024-12-05T00%3A42%3A42Z&se=2024-12-05T02%3A42%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-05T00%3A12%3A58Z&ske=2024-12-06T00%3A12%3A58Z&sks=b&skv=2024-08-04&sig=xqtXaRSks8g5pQtIIXre6UKTwrfD/ECEHkxyFeANEKo%3D)\n",
      "\n",
      "이제 `report-3.md` 파일을 확인하실 수 있습니다. 추가로 필요한 사항이 있으시면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 이미 생성 요청\n",
    "result = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"`report-2.md` 파일을 열어서 안의 내용을 출력하세요. \"\n",
    "        \"출력된 내용에 어울리는 이미지를 생성하세요. \"\n",
    "        \"생성한 이미지의 url 을 markdown 형식으로 보고서의 가장 상단에 추가하세요. \"\n",
    "        \"마지막으로 작성된 결과물을 `report-3.md` 파일에 저장하세요.\"\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"sessionid:agent3\"}},\n",
    ")\n",
    "\n",
    "print(\"Agent 실행 결과:\")\n",
    "for step in result:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report-3.md 최종 결과입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Generative AI Risks](https://oaidalleapiprodscus.blob.core.windows.net/private/org-SD76VRjKZn7BhpAtD6EB27g3/user-3UowxZ06VqNttUO7RMIoAsi7/img-uW59MQYV75v9ASlZqPbZpvhx.png?st=2024-12-05T00%3A42%3A42Z&se=2024-12-05T02%3A42%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-05T00%3A12%3A58Z&ske=2024-12-06T00%3A12%3A58Z&sks=b&skv=2024-08-04&sig=xqtXaRSks8g5pQtIIXre6UKTwrfD/ECEHkxyFeANEKo%3D)\n",
    "\n",
    "# 생성형 AI의 위험성 보고서\n",
    "\n",
    "## 1. 개요\n",
    "생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.\n",
    "\n",
    "## 2. 핵심내용\n",
    "| 위험 요인 | 설명 |\n",
    "|------------|------|\n",
    "| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |\n",
    "| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |\n",
    "| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |\n",
    "| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |\n",
    "| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |\n",
    "| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |\n",
    "\n",
    "## 3. 최종결론\n",
    "생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.\n",
    "\n",
    "**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-note-2024-PFhCXHTX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
