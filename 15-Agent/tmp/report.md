## 생성형 AI의 위험성

- **페이지 번호**: 6, 11, 18, 27
- **파일명**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf

- 생성 AI를 기반으로 높은 성과를 내는 조직들은 상대적으로 더 많은 AI 위험 대응 활동을 수행하는 경향이 있음.
- 국내 대중의 AI 기술의 위험성에 대한 인식은 상대적으로 높지 않으며, 정부는 AI의 이점을 극대화하면서도 안전성을 제공할 수 있는 정책을 마련할 필요가 있음.
- AI 기술의 잠재적 위험으로는 오작동과 악의적 사용으로 인한 피해가 있으며, 특히 설계/오작동 발생과 악의적 의도로 AI 활용에 따른 피해가 우려됨.
- AI의 오작동 위험은 비현실적인 기대와 과도한 의존으로 인해 발생할 수 있으며, 전문 분야에서의 AI 오류가 보고되고 있음.
- AI 안전을 위한 사회적, 제도적 논의의 글로벌 협력 필요성이 증가하고 있음.
- 미국 NIST는 생성 AI 기술에 특화된 위험 요인을 분류하고 관리 방안을 제시하고 있으며, 12가지 위험 요인을 정의하고 있음.
- 생성 AI의 위험 요인으로는 CBRN 정보 접근, 오류가 있는 콘텐츠 제작, 데이터 프라이버시 문제, 환경적 영향, 해로운 편향 및 균질화, 정보 무결성 문제 등이 있음.

## 웹 검색 결과

- **출처**: [한국경제](https://www.hankyung.com/article/202409096811i)
  - 생성형 AI의 위험이 커지고 있으며, 안전성 확보가 시급하다는 의견이 있음. AI 학습에 활용된 데이터의 유출 및 범죄에 활용되는 경우 등의 문제도 발생할 수 있음.

- **출처**: [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/)
  - 생성형 AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있으며, AI 시스템과의 과도한 상호작용이 의사소통에 부정적인 영향을 미칠 수 있음.

- **출처**: [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)
  - 생성형 AI 도구의 사용으로 인해 사용자 정보가 제3자와 공유될 수 있어 프라이버시 문제가 발생할 수 있으며, 오류 출력 및 규제 위반의 위험성이 높아지고 있음.