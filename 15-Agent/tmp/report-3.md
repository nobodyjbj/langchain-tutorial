![Generative AI Risks](https://oaidalleapiprodscus.blob.core.windows.net/private/org-SD76VRjKZn7BhpAtD6EB27g3/user-3UowxZ06VqNttUO7RMIoAsi7/img-uW59MQYV75v9ASlZqPbZpvhx.png?st=2024-12-05T00%3A42%3A42Z&se=2024-12-05T02%3A42%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-05T00%3A12%3A58Z&ske=2024-12-06T00%3A12%3A58Z&sks=b&skv=2024-08-04&sig=xqtXaRSks8g5pQtIIXre6UKTwrfD/ECEHkxyFeANEKo%3D)

# 생성형 AI의 위험성 보고서

## 1. 개요
생성형 AI는 다양한 분야에서 혁신을 가져오고 있지만, 그에 따른 위험성도 증가하고 있다. 본 보고서는 생성형 AI의 위험성을 분석하고, 이를 해결하기 위한 방안을 모색한다. 특히, AI의 오작동, 데이터 프라이버시 문제, 그리고 사회적 영향 등을 다루며, 안전성을 확보하기 위한 정책적 접근이 필요함을 강조한다.

## 2. 핵심내용
| 위험 요인 | 설명 |
|------------|------|
| 오작동 | 비현실적인 기대와 과도한 의존으로 인한 AI의 오류 발생 |
| 악의적 사용 | AI 기술이 범죄에 악용될 가능성 |
| 데이터 유출 | AI 학습에 사용된 데이터의 유출 문제 |
| 프라이버시 문제 | 사용자 정보가 제3자와 공유될 위험 |
| 창의성 억제 | AI의 활용이 인간의 창의성과 감정 표현을 억제할 수 있음 |
| 규제 위반 | AI 도구 사용으로 인한 규제 위반 위험 |

## 3. 최종결론
생성형 AI의 위험성은 단순한 기술적 문제를 넘어 사회적, 윤리적 문제로 확장되고 있다. 따라서, 정부와 기업은 AI의 안전성을 확보하기 위한 정책과 규제를 마련해야 하며, 글로벌 협력이 필요하다. 이러한 노력이 없을 경우, 생성형 AI의 발전은 오히려 사회에 부정적인 영향을 미칠 수 있다.

**출처**: IS-183_AI 위험 유형 및 사례 분석(최종).pdf, [한국경제](https://www.hankyung.com/article/202409096811i), [TalkAI](https://talkai.info/ko/blog/is_ai_dangerous/), [CIO](https://www.cio.com/article/3506259/오류-출력-및-규제-위반-위험성-높아···-전문가.html)